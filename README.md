<p align="center">
    <br>
    <img src="./assets/apart_banner.png" width="900"/>
    <br>
<p>

## Introduction
This library support goals and uses terminology introduced in the paper [Increasing Trust in Language Models through the Reuse of Verified Circuits](https://arxiv.org/abs/2402.02619). Please read the paper. In brief:
- Given an existing transformer model with low loss, this library helps a researcher to analyze and understand the algorithm implemented by a transformer model.
- The "useful" token positions, attention heads and MLP neurons that are used in predictions are identified.  
- Various tools and techniques evaluate aspects of the model's "behavior" (e.g. attention patterns).
- The researcher can extend the tools with model-specific searches and tests - searching for hypothesised model components that perform model-specific algorithm "sub-tasks" (e.g. Base Add in the Addition model)
- Useful facts found in this way are stored as JSON (refer [Useful_Tags](./useful_tags.md) for details) and can be visualized (refer [Assets](./Assets/"Assets") for samples).
- A researcher can describe an algorithm hypothesis as a series of claims, and evaluate those claims against the facts found. The resulting insights can be used to refine and\or extend both the algorithm sub-task tests and the algorithm hypothesis description, leading to a full description of the model's algorithm.

## Installation

From source

```bash
git clone https://github.com/PhilipQuirke/verified_transformers.git
cd verified_transformers
pip install .
```

## Test bed
Much of this library is generic (can be applied to any transformer model). As a "real-world" testbed to help refine this library we use models trained to perform integer addition and subtraction (e.g. 133357+182243=+0315600 and 123450-345670=-0123230). Arithmetic-specific algorithm sub-task searches are defined (e.g. Base Add, Use Sum 9, Make Carry, Base Subtract, Borrow One). Addition and Subtraction hypothesises are described and evaluated in the Colab notebook VerifiedArithmeticAnalyse.ipynb. Arithmetic-specific python code is in files like [maths_config.py](./QuantaTools/maths_config.py).   

## Folders, Files and Classes 
This library contains files:

- **Notebooks:** Jupyter notebooks which are run in Google Colab or Jupyter: 
  - **Train:** Colab VerifiedArithmeticTrain.ipynb is used to train transformer arithmetic models. 
    - Outputs pth and json files that are (manually) stored on HuggingFace
  - **Analysis:** Colab VerifiedArithmeticAnalyse.ipynb is used to analyze the behavior and algorithm sub-tasks of transformer arithmetic models
    - Inputs pth files (generated above) from HuggingFace
    - Outputs *_behavior and *_algorithm json files that are (manually) stored on HuggingFace
  - **Algorithm:** Colab VerifiedArithmeticAlgorithm.ipynb describes/tests an overall algorithm for a model (based on behavior and algorithm sub-tasks data)
    - Inputs *_behavior and *_algorithm json files (generated above) from HuggingFace 

- **QuantaTools:** Python library code imported into the notebooks:
  - model_*.py: Contains the configuration of the transformer model being trained/analysed. Includes class ModelConfig 
  - useful_*.py: Contains data on the useful token positions and useful nodes (attention heads and MLP neurons) that the model uses in predictions. Includes class UsefulConfig derived from ModelConfig. Refer [Useful_Tags](./useful_tags.md) for more detail. 
  - algo_*.py: Contains tools to support declaring and validating a model algorithm. Includes class AlgoConfig derived from UsefulConfig.
  - quanta_*.py: Contains categorisations of model behavior (aka quanta), with ways to detect, filter and graph them. Refer [Filter](./filter.md) for more detail. 
  - ablate_*.py: Contains ways to "intervention ablate" the model and detect the impact of the ablation
  - maths_*.py: Contains specializations of the above specific to arithmetic (addition and subtraction) transformer models. Includes class MathsConfig derived from AlgoConfig.
          
- **Tests:** Unit tests 

## HuggingFace resources
The HuggingFace website permanently stores the output files generated by the "arithmetic" 'train and 'analyse' notebooks:
- VerifiedArithmeticTrain/Analyse files are stored at https://huggingface.co/PhilipQuirke/VerifiedArithmetic covering these models:
  - add_**d5_l1**_h3_t30K_s372001: Inaccurate **5-digit, 1-layer, 3-attention-head**, addition model. 
  - add_d5_**l2**_h3_t15K_s372001: **Accurate** 5-digit, **2-layers**, 3-head addition model trained for 15K epochs. Training loss is 9e-9
  - add_**d6**_l2_h3_t15K_s372001: **Accurate** **6-digit**, 2-layers, 3-head addition model trained for 15K epochs.  
  - **sub**_d6_l2_h3_t30K_s372001: Inaccurate 6-digit, 2-layers, 3-head **subtraction** model trained for 30K epochs.
  - **mix**_d6_l3_h4_t40K_s372001: Inaccurate 6-digit, **3-layers, 4-head mixed** (add and subtract) model trained for 40K epochs. Training loss is 8e-09
  - **ins1**_mix_d6_l3_h4_t40K_s372001: **Accurate** 6-digit, 3-layers, 4-head mixed **initialise with addition model**. Handles 1m Qs for Add and Sub. 
  - **ins1**_mix_d6_l3_h4_t40K_s173289: Inaccurate. AvgFinalLoss=1.6e-08. 936K for Add, 1M Qs for Sub 
  - **ins1**_mix_d6_l3_h3_t40K_s572091: Inaccurate. AvgFinalLoss=1.8e-08. Fails on 1M Qs. For 099111-099111=+0000000 gives -0000000. Improve training data.
  - **ins1**_mix_d6_l3_h4_t50K_s572091: Inaccurate. AvgFinalLoss=2.9e-08. 1M for Add. 300K for Sub. For 000041-000047=-0000006 gives +0000006. Improve training data.
  - **ins2**_mix_d6_l4_h4_t40K_s372001: Inaccurate 6-digit, 3-layers, 4-head mixed initialise with addition model. **Reset useful heads every 100 epochs**. Training loss is 7e-09. Fails 1m Qs
  - **ins3**_mix_d6_l4_h3_t40K_s372001: Inaccurate 6-digit, 3-layers, 4-head mixed initialise with addition model. **Reset useful heads and MLP every 100 epochs**. 

## Papers
The papers associated with this content are:
- Understanding Addition in Transformers: https://arxiv.org/abs/2310.13121 . Aka Paper1. Model add_d5_l1_h3_t30K is very similar to the one in this paper. 
- Increasing Trust in Language Models through the Reuse of Verified Circuits. https://arxiv.org/abs/2402.02619 . Aka Paper2. Uses many of these models mostly focusing on add_d5_l2_h3_t15K, add_d6_l2_h3_t15K and ins1_mix_d6_l3_h4_t40K

## Environment
Most exploratory work is done in a Google Colab in the 'train and 'analyse' notebooks. 
After a new 'search' is sucessfully developed and tested in the notebook, the code is migrated to the QuantaTools code folder. 

The files in the QuantaTools code folder have better version control and are easier to maintain than code blocks in a notebook.  
Using QuantaTools files also reduces version change conflicts between multiple people working to improve the library.

## Abbreviations
- Pn : Model (input or output) token position. Zero-based
- Ln : Model layer n. Zero-based
- Hn : Attention head n. Zero-based
- Mn : MLP neuron n. Zero-based
- PnLnHn : Location / name of a single attention head, at a specified layer, at a specific token position
- PnLnMn : Location / name of a single MLP neuron, at a specified layer, at a specific token position
- D : First number of the pair question numbers
- Dn : nth numeric token in the first question number. Zero-based. D0 is the units value
- D' : Second number of the pair question numbers
- D'n : nth token in the second question number. Zero-based. D0 is the units value
- A : Answer to the question (including answer sign)
- An : nth token in the answer. Zero-based. A0 is the units value. The highest token is the "+" or "-" answer sign
- Amax : The highest token in the answer. It is always the "+" or "-" sign
- S : Prefix for Addition. Think S for Sum. Aka ADD.
- SA : Basic Add. An addition sub-task. An.SA is defined as (Dn + D'n) % 10. For example, 5 + 7 gives 2
- SC : Make Carry. An addition sub-task. An.SC is defined as Dn + D'n >= 10. For example, 5 + 7 gives True
- SS : Make Sum 9. An addition sub-task. An.SS is defined as Dn + D'n == 9. For example, 5 + 7 gives False
- ST : TriCase. An addition sub-task. Refer paper 2 for details
- ST8, ST9, ST10: Outputs of the ST TriCase sub-task. Refer paper 2 for details
- M : Prefix for Subtraction with a **positive** answer. Think M for Minus. Aka SUB
- MD: Basic Difference. A subtraction sub-task. An.MD is defined as (Dn - D'n) % 10. For example, 3 - 7 gives 6
- MB: Borrow One. A positive-answer subtraction sub-task.  An.MB is defined as Dn - D'n < 0. For example, 5 - 7 gives True   
- MZ : Make Zero. A positive-answer subtraction sub-task. An.MZ is defined as Dn - D'n == 0. For example, 5 - 5 gives True
- MT : TriCase. A positive-answer subtraction sub-task. Refer paper 2 for details
- MT1, MT0, MT-1: Outputs of the MT TriCase sub-task. Refer paper 2 for details
- N : Prefix for Subtraction with a **negative** answer. Think N for Negative. Aka NEG
- ND: Basic Difference. A negative-answer subtraction sub-task. An.ND is defined as (Dn - D'n) % 10. For example, 3 - 7 gives 6
- NB: Borrow One. A negative-answer subtraction sub-task.  An.NB is defined as Dn - D'n < 0. For example, 5 - 7 gives True   
- NZ : Make Zero. A negative-answer subtraction sub-task. An.NZ is defined as Dn - D'n == 0. For example, 5 - 5 gives True
- NT : TriCase. A negative-answer subtraction sub-task. Refer paper 2 for details
- GT : Greater Than. A (positive-answer or negative-answer) subtraction sub-task. Dn.GT is defined as Dn > D'n. For example, 3 > 5 gives False
- OPR: Operator. A sub-task that attends to the + or - token in the question (which determines whether the question is addition or subtraction).
- SGN: Sign. A sub-task that attends to the first answer token, which is + or -
