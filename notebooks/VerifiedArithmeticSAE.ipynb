{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Verified Integer Mathematics in Transformers - Train an SAE\n",
        "\n",
        "This Colab trains an SAE on a Transformer models to help understand its MLP layer.\n",
        "\n",
        "The models perform integer addition and/or subtraction e.g. 133357+182243=+0315600 and 123450-345670=-0123230. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens.\n",
        "\n",
        "This Colab follows on from https://github.com/PhilipQuirke/verified_transformers/blob/main/notebooks/VerifiedArithmeticTrain.ipynb which trained the models, and outputs model_name.pth and model_name_train.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries.\n",
        "\n",
        "Imports \"verified_transformer\" public library as \"qt\". This library is specific to this CoLab's \"QuantaTool\" approach to transformer analysis. Refer to [README.md](https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md) for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCdmr6-_Jkzi",
        "outputId": "88094131-4cbb-4dec-c7e9-750a2f4f2258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    !pip install matplotlib\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "    !pip install numpy\n",
        "    !pip install scikit-learn\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "    def setup_jupyter(install_libraries=False):\n",
        "        if install_libraries:\n",
        "            !pip install matplotlib==3.8.4\n",
        "            !pip install kaleido==0.2.1\n",
        "            !pip install transformer_lens==1.15.0\n",
        "            !pip install torchtyping==0.1.4\n",
        "            !pip install transformers==4.39.3\n",
        "\n",
        "            !pip install numpy==1.26.4\n",
        "            !pip install plotly==5.20.0\n",
        "            !pip install pytest==8.1.1\n",
        "            !pip install scikit-learn==1.4.1.post1\n",
        "\n",
        "        print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "        from IPython import get_ipython\n",
        "\n",
        "        ipython = get_ipython()\n",
        "        # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "        ipython.magic(\"load_ext autoreload\")\n",
        "        ipython.magic(\"autoreload 2\")\n",
        "\n",
        "    # setup_jupyter(install_libraries=True)   # Uncomment if you need to install libraries in notebook.\n",
        "    setup_jupyter(install_libraries=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "from transformer_lens.utils import download_file_from_hf\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "\n",
        "import re\n",
        "import sklearn # Aka scikit.learn\n",
        "import skopt # Aka scikit.optimize"
      ],
      "metadata": {
        "id": "ofc_XqLv6pnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2P3cndolKDM"
      },
      "outputs": [],
      "source": [
        "# Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md\n",
        "!pip install --upgrade git+https://github.com/PhilipQuirke/verified_transformers.git  # Specify @branch if testing a specific branch\n",
        "import QuantaTools as qt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to analyze?\n",
        "\n",
        "The existing model weightings created by the sister Colab [VerifiedArithmeticTrain](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/VerifiedArithmeticTrain.ipynb) are loaded from HuggingFace (in Part 5). Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"main\" configuration class. MathsConfig is derived from the chain AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = qt.MathsConfig()\n",
        "\n",
        "\n",
        "# Which model do we want to analyze? Uncomment one line:\n",
        "\n",
        "#cfg.model_name = \"\" # Use default configuration specified in cfg\n",
        "\n",
        "# Addition models\n",
        "#cfg.model_name = \"add_d5_l1_h3_t15K_s372001\"  # AddAccuracy=Two9s. Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions.\n",
        "#cfg.model_name = \"add_d5_l2_h3_t15K_s372001\"  # AddAccuracy=Six9s. AvgFinalLoss=1.6e-08\n",
        "#cfg.model_name = \"add_d5_l2_h3_t40K_s372001\"  # AddAccuracy=Six9s. AvgFinalLoss=2e-09. Fewest nodes\n",
        "#cfg.model_name = \"add_d6_l2_h3_t15K_s372001\"  # AddAccuracy=Fives. AvgFinalLoss=1.7e-08. (2/M fail: 018539+789353=+0807892 ModelAnswer: +0707892, 747332+057349=+0804681 ModelAnswer: +0704681)\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s173289\"  # AddAccuracy=Six9s. AvgFinalLoss=1.5e-08. Fewest nodes\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s572091\"  # AddAccuracy=Six9s. AvgFinalLoss=7e-09\n",
        "#cfg.model_name = \"add_d6_l2_h3_t40K_s372001\"  # AddAccuracy=Six9s. AvgFinalLoss 2e-09\n",
        "#cfg.model_name = \"add_d10_l2_h3_t40K_s572091\" # AddAccuracy=Six9s. AvgFinalLoss=7e-09. (1/M fail: 0000000555+0000000445=+00000001000 ModelAnswer: +00000000900)\n",
        "#cfg.model_name = \"add_d10_l2_h3_t40K_gf_s572091\" # AddAccuracy=Six9s. AvgFinalLoss=3.5-09. GrokFast.\n",
        "\n",
        "# Subtraction model\n",
        "#cfg.model_name = \"sub_d6_l2_h3_t30K_s372001\"  # SubAccuracy=Six9s. AvgFinalLoss=5.8e-06\n",
        "#cfg.model_name = \"sub_d10_l2_h3_t75K_s173289\"  # SubAccuracy=Two9s. (6672/M fails) AvgFinalLoss=0.002002.\n",
        "#cfg.model_name = \"sub_d10_l2_h3_t75K_gf_s173289\"  # SubAccuracy=Two9s. GrokFast. (5246/M fails) AvgFinalLoss=0.001197\n",
        "\n",
        "# Mixed (addition and subtraction) model\n",
        "#cfg.model_name = \"mix_d6_l3_h4_t40K_s372001\"  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=5e-09. (1/M fail: 463687+166096=+0629783 ModelAnswer: +0639783)\n",
        "#cfg.model_name = \"mix_d10_l3_h4_t75K_s173289\"  # Add/SubAccuracy=Five9s/Two9s. AvgFinalLoss=1.125e-06 (2/M fail: 3301956441+6198944455=+09500900896 ModelAnswer: +09500800896) (295/M fail: 8531063649-0531031548=+08000032101 ModelAnswer: +07900032101)\n",
        "#cfg.model_name = \"mix_d10_l3_h4_t75K_gf_s173289\"  # Add/SubAccuracy=Six9s/Three9s. GrokFast. AvgFinalLoss 8.85e-07 (1/M fail) (294/M fail)\n",
        "\n",
        "# Mixed models initialized with addition model\n",
        "#cfg.model_name = \"ins1_mix_d6_l2_h3_t40K_s572091\"  # Add/SubAccuracy=Six9s/Five9s. AvgLoss = 2.4e-08 (5/M fails e.g. 565000-364538=+0200462 ModelAnswer: +0100462)\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h3_t40K_s572091\"  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=1.8e-08. (3/M fails e.g. 072074-272074=-0200000 ModelAnswer: +0200000)\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h3_t80K_s572091\"  # Add/SubAccuracy=Six9s/Five9s AvgLoss = 1.6e-08 (3/M fails e.g. 229672-229678=-0000006 ModelAnswer: +0000006) (EnrichFalse => 0/M, 4/M)\n",
        "cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s372001\"  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=8e-09. MAIN FOCUS\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s173289\"  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.4e-08. (3/M fails e.g. 850038+159060=+1009098 ModelAnswer: +0009098) (2/M fails e.g. 77285-477285=+0100000 Q: ModelAnswer: +0000000) (EnrichFalse => 0/M, 3/M)\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t50K_s572091\"  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=2.9e-08. (4/M fails e.g. 986887-286887=+0700000 ModelAnswer: +0600000) (EnrichFalse => 0/M, 3/M)\n",
        "#cfg.model_name = \"ins1_mix_d10_l3_h3_t50K_s572091\"  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss 6.3e-07  (6/M fails e.g. 5068283822+4931712829=+09999996651 ModelAnswer: +19099996651) (7/M fails e.g. 3761900218-0761808615=+03000091603 ModelAnswer: +02000091603)\n",
        "#cfg.model_name = \"ins1_mix_d10_l3_h3_t50K_gf_s572091\" # Add/SubAccuracy=Five9s/Two9s. GrokFast. AvgFinalLoss=4.0e-06 (2/M fails) (1196/M fails)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads every 100 epochs.\n",
        "#cfg.model_name = \"ins2_mix_d6_l4_h4_t40K_s372001\"  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.7e-08. (3/M fails e.g. 530757+460849=+0991606 ModelAnswer: +0091606) (8 fails e.g. 261926-161857=+0100069 ModelAnswer: +0000069)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads & MLPs every 100 epochs.\n",
        "#cfg.model_name = \"ins3_mix_d6_l4_h3_t40K_s372001\"  # Add/SubAccuracy=Four9s/Two9s. AvgFinalLoss=3.0e-04. (17/M fails e.g. 273257+056745=+0330002 ModelAnswer: +0320002) (3120 fails e,g. 09075-212133=-0003058 ModelAnswer: +0003058)\n",
        "\n",
        "# Mixed models initialized with addition model.\n",
        "#cfg.model_name = \"ins4_mix_d6_l3_h4_t30K_s775824\"  # Add/SubAccuracy=???/???\n",
        "#cfg.model_name = \"ins4_mix_d6_l2_h4_t30K_s775824\"  # Add/SubAccuracy=???/???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BiELcf53ms"
      },
      "outputs": [],
      "source": [
        "cfg.reset_useful()\n",
        "cfg.reset_algo()\n",
        "\n",
        "main_fname = cfg.file_config_prefix\n",
        "if cfg.model_name != \"\":\n",
        "  main_fname = cfg.model_name\n",
        "\n",
        "  # Update cfg member data n_digits, n_layers, n_heads, n_training_steps from model_name\n",
        "  cfg.parse_model_name()\n",
        "\n",
        "  cfg.batch_size = 512 # Default analysis batch size\n",
        "  if cfg.n_layers >= 3 and cfg.n_heads >= 4:\n",
        "    cfg.batch_size = 256 # Reduce batch size to avoid memory constraint issues.\n",
        "\n",
        "cfg.set_seed(cfg.analysis_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "main_fname_pth = main_fname + '.pth'\n",
        "main_fname_train_json = main_fname + '_train.json'\n",
        "main_fname_sae_pth = main_fname + '_sae.pth'\n",
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfdCBTuqh4zq"
      },
      "outputs": [],
      "source": [
        "# Update \"cfg\" with additional training config information from say\n",
        "#      https://huggingface.co/PhilipQuirke/VerifiedArithmetic/raw/main/ins1_mix_d6_l3_h4_t40K_s372001_train.json\"\n",
        "training_data_json = qt.download_huggingface_json(main_repo_name, main_fname_train_json)\n",
        "training_loss_list = qt.load_training_json(cfg, training_data_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI4vY-vSxvxC"
      },
      "outputs": [],
      "source": [
        "def print_config():\n",
        "  print(\"%Add=\", cfg.perc_add, \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", main_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f48_G6wr730Q"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)\n",
        "print('Main model will be read from HuggingFace file', main_repo_name, main_fname_pth)\n",
        "print('Main model training config / loss will be read from HuggingFace file', main_fname_train_json)\n",
        "print('Saving sae model to', main_repo_name, main_fname_sae_pth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3A: Set Up: Vocabulary / Embedding / Unembedding\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeObQk2kzAv7"
      },
      "outputs": [],
      "source": [
        "cfg.initialize_maths_token_positions()\n",
        "qt.set_maths_vocabulary(cfg)\n",
        "qt.set_maths_question_meanings(cfg)\n",
        "print(cfg.token_position_meanings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6rUaYvjOcE"
      },
      "source": [
        "# Part 3B: Set Up: Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = cfg.get_HookedTransformerConfig()\n",
        "\n",
        "# Create the main transformer model\n",
        "cfg.main_model = HookedTransformer(ht_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5: Set Up: Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0"
      },
      "outputs": [],
      "source": [
        "print(\"Loading model from HuggingFace\", main_repo_name, main_fname_pth)\n",
        "\n",
        "cfg.main_model.load_state_dict(download_file_from_hf(repo_name=main_repo_name, file_name=main_fname_pth, force_is_torch=True))\n",
        "cfg.main_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6: Train a SAE\n",
        "\n",
        "Train an SAE which preferably has:\n",
        "- Low Loss and MSE (good reconstruction. Very important)\n",
        "- Low sparsity (Sparsity = # neurons activating. So low sparsity means few neurons are active in any given prediction)\n",
        "- Low number of Active Neurons (makes interpretation easier)\n"
      ],
      "metadata": {
        "id": "e5yD0orfGx4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = qt.get_mixed_maths_dataloader(cfg, num_batches=1000, enrich_data=True)\n",
        "print(\"Data set size\", len(dataloader.dataset))"
      ],
      "metadata": {
        "id": "cjyzeiiSG06A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sae, score, loss, sparsity, neurons_used = qt.analyze_mlp_with_sae(cfg, dataloader, layer_num=0, encoding_dim=32, learning_rate=5e-4, sparsity_target=0.1, sparsity_weight=1e-3, num_epochs=10)\n",
        "print( f\"Score: {score:.4f}, Loss {loss:.4f}, Sparsity {sparsity:.4f}, Neurons Used: {neurons_used}.\")"
      ],
      "metadata": {
        "id": "Xk4_HqhrvYGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sae, score, loss, sparsity, neurons_used = qt.analyze_mlp_with_sae(cfg, dataloader, layer_num=0, encoding_dim=64, learning_rate=0.001, sparsity_target=0.05, sparsity_weight=0.1, num_epochs=10)\n",
        "print( f\"Score: {score:.4f}, Loss {loss:.4f}, Sparsity {sparsity:.4f}, Neurons Used: {neurons_used}.\")"
      ],
      "metadata": {
        "id": "uPUgY4xd5QNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 7: Sweep hyperparams to find the best SAE\n",
        "\n",
        "Sweep hyperparameters to train/score multiple SAEs to find the best scoring SAE. Slow."
      ],
      "metadata": {
        "id": "FOO1Nb2lqT3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'encoding_dim': [64], #[32, 64, 128, 256, 512],\n",
        "    'learning_rate': [1e-3], # [1e-4, 1e-3, 1e-2],\n",
        "    'sparsity_target': [0.05, 0.1], # [0.001, 0.005, 0.01, 0.05, 0.1],\n",
        "    'sparsity_weight': [0.1], #[1e-3, 1e-2, 1e-1, 1.0],\n",
        "    'l1_weight': [1e-4, 1e-3, 1e-2],  # [1e-6, 1e-5, 1e-4, 1e-3, 1e-2],\n",
        "    'num_epochs': [10],\n",
        "    'patience': [2]\n",
        "}"
      ],
      "metadata": {
        "id": "CA_IE7VjY7ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_experiments = 1\n",
        "for param_values in param_grid.values():\n",
        "    num_experiments *= len(param_values)\n",
        "\n",
        "print(f\"Number of configurations to test: {num_experiments}\")"
      ],
      "metadata": {
        "id": "-W-Ay0bvNpQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sae, score, neurons_used, params = qt.optimize_sae_hyperparameters(cfg, dataloader, layer_num=0, param_grid=param_grid)"
      ],
      "metadata": {
        "id": "Szo94L-CqUEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS_zUfwrXl6P"
      },
      "source": [
        "# Part 7: Visualize the SAE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Kt5XD-XU9t"
      },
      "outputs": [],
      "source": [
        "qt.analyze_and_visualize_sae(cfg, sae, dataloader, layer_num=0, max_samples=1000, perplexity=30, n_iter=250)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "P8RfHXneJw6n"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}