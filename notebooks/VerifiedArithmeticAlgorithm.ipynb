{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Verified Integer Mathematics in Transformers - Describe Model Algorithm\n",
        "\n",
        "This Colab describes the algorithm of Transformer models in terms of model behaviours and algorithmic sub-tasks (analysed in other Colabs and stored in JSON files).\n",
        "\n",
        "The models that performs integer addition, subtraction and/or multiplication e.g. 133357+182243=+0315600, 123450-345670=-0123230 and 000345*000823=+283935. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens.\n",
        "\n",
        "This Colab follows on from:\n",
        "- https://github.com/PhilipQuirke/verified_transformers/blob/main/notebooks/VerifiedArithmeticTrain.ipynb trained the models. It outputs model_name.pth and model_name_train.json\n",
        "- https://github.com/PhilipQuirke/verified_transformers/blob/main/notebooks/VerifiedArithmeticAnalyse.ipynb analyzes the models. It documents their sub-tasks in model_name_behavior.json model_name_algorithm.json\n",
        "\n",
        "This Colab loads the above json files from HuggingFace repository https://huggingface.co/PhilipQuirke/VerifiedArithmetic/tree/main\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries.\n",
        "\n",
        "Imports \"verified_transformer\" public library as \"qt\". This library is specific to this CoLab's \"QuantaTool\" approach to transformer analysis. Refer to [README.md](https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md) for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCdmr6-_Jkzi"
      },
      "outputs": [],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    !pip install matplotlib\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "\n",
        "    !pip install numpy\n",
        "    #!pip install scikit-learn\n",
        "    !pip install huggingface_hub\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "    def setup_jupyter(install_libraries=False):\n",
        "        if install_libraries:\n",
        "            !pip install matplotlib==3.8.4\n",
        "            !pip install kaleido==0.2.1\n",
        "            !pip install transformer_lens==1.15.0\n",
        "            !pip install torchtyping==0.1.4\n",
        "            !pip install numpy==1.26.4\n",
        "            !pip install plotly==5.20.0\n",
        "            !pip install pytest==8.1.1\n",
        "            #!pip install scikit-learn==1.4.1.post1\n",
        "\n",
        "        print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "        from IPython import get_ipython\n",
        "\n",
        "        ipython = get_ipython()\n",
        "        # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "        ipython.magic(\"load_ext autoreload\")\n",
        "        ipython.magic(\"autoreload 2\")\n",
        "\n",
        "    # setup_jupyter(install_libraries=True)   # Uncomment if you need to install libraries in notebook.\n",
        "    setup_jupyter(install_libraries=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import textwrap\n",
        "from huggingface_hub import hf_hub_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwekwkrdI6SX"
      },
      "outputs": [],
      "source": [
        "! pip uninstall QuantaTools -y || true   # Ensure a clean install."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2P3cndolKDM"
      },
      "outputs": [],
      "source": [
        "# Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md\n",
        "!pip install --upgrade git+https://github.com/PhilipQuirke/verified_transformers.git  # Specify @branch if testing a specific branch\n",
        "import QuantaTools as qt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to analyse?\n",
        "\n",
        "The existing model weightings created by the sister Colab [VerifiedArithmeticTrain](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/VerifiedArithmeticTrain.ipynb) are loaded from HuggingFace (in Part 5). Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmjGdFcdJat3"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"main\" configuration class. MathsConfig is derived from the chain AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = qt.MathsConfig()\n",
        "\n",
        "# Singleton QuantaTool \"ablation intervention\" configuration class\n",
        "acfg = qt.acfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Which model do we want to analyse? Uncomment one line:\n",
        "\n",
        "#cfg.model_name = \"\" # Use configuration specified in cfg defaults\n",
        "\n",
        "#cfg.model_name = 5-digit and 6-digit digit Addition models\n",
        "#cfg.model_name = \"add_d5_l1_h3_t15K_s372001\"  # Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions.\n",
        "#cfg.model_name = \"add_d5_l2_h3_t15K_s372001\"  # AvgFinalLoss=1.6e-08. Accurate on 1M Qs\n",
        "#cfg.model_name = \"add_d6_l2_h3_t15K_s372001\"  # AvgFinalLoss=1.7e-08. Accurate on 1M Qs. MAIN FOCUS\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s173289\"  # AvgFinalLoss=1.5e-08. Accurate on 1M Qs\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s572091\"  # AvgFinalLoss=7e-09. Accurate on 1M Qs\n",
        "\n",
        "# 6-digit Subtraction model\n",
        "#cfg.model_name = \"sub_d6_l2_h3_t30K_s372001\"  # AvgFinalLoss=5.8e-06. Fails 1M Qs\n",
        "\n",
        "# 6-digit Mixed (addition and subtraction) models\n",
        "#cfg.model_name = \"mix_d6_l3_h4_t40K_s372001\"  # AvgFinalLoss=5e-09. Fails 1M Qs\n",
        "\n",
        "# \"ins1\" 6-digit Mixed models initialised with 6-digit addition model\n",
        "cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s372001\"  # AvgFinalLoss=8e-09. Accurate on 1M Qs for Add and Sub. MAIN FOCUS\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s173289\"  # AvgFinalLoss=1.6e-08. 936K for Add, 1M Qs for Sub\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t50K_s572091\"  # AvgFinalLoss=2.9e-08. 1M for Add. 300K for Sub. For 000041-000047=-0000006 gives +0000006. Improve training data.\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h3_t40K_s572091\"  #  AvgFinalLoss=1.8e-08. Fails on 1M Qs. For 099111-099111=+0000000 gives -0000000. Improve training data.\n",
        "\n",
        "# \"ins2\" 6-digit Mixed model initialised with 6-digit addition model. Reset useful heads every 100 epochs.\n",
        "#cfg.model_name = \"ins2_mix_d6_l4_h4_t40K_s372001\"  # AvgFinalLoss=7e-09. Fails 1M Qs\n",
        "\n",
        "# \"ins3\" 6-digit Mixed model initialised with 6-digit addition model. Reset useful heads & MLPs every 100 epochs.\n",
        "#cfg.model_name = \"ins3_mix_d6_l4_h3_t40K_s372001\"  # AvgFinalLoss=2.6e-06. Fails 1M Qs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BiELcf53ms"
      },
      "outputs": [],
      "source": [
        "# Needed when user changes model_name and reruns this Colab a second time\n",
        "cfg.reset_useful()\n",
        "cfg.reset_algo()\n",
        "cfg.initialize_maths_token_positions()\n",
        "acfg.reset_ablate()\n",
        "\n",
        "if cfg.model_name != \"\":\n",
        "  # Update cfg member data n_digits, n_layers, n_heads, n_training_steps from model_name\n",
        "  cfg.parse_model_name()\n",
        "\n",
        "  # Addition model\n",
        "  cfg.perc_sub = 0\n",
        "  if cfg.model_name.startswith(\"sub_\") :\n",
        "    # Subtraction model\n",
        "    cfg.perc_sub = 100\n",
        "  elif cfg.model_name.startswith(\"mix\") :\n",
        "    # Mixed (addition and subtraction) model\n",
        "    cfg.perc_sub = 66 # Train on 66% subtraction and 33% addition question batches\n",
        "  elif cfg.model_name.startswith(\"ins\") :\n",
        "    # Mixed model initialised with an addition model (using insert mode 1, 2 or 3)\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "\n",
        "  # We train multiple versions of some models, inserting different addition models.\n",
        "  cfg.insert_training_seed = cfg.training_seed\n",
        "\n",
        "  if cfg.model_name.startswith(\"ins1_mix_d6_l3\") :\n",
        "    if cfg.training_seed == 372001:\n",
        "      # Mixed model initialised with add_d6_l2_h3_t15K.pth.\n",
        "      cfg.insert_n_training_steps = 15000\n",
        "    else:\n",
        "      # Mixed model initialised with add_d6_l2_h3_t20K.pth.\n",
        "      cfg.insert_n_training_steps = 20000\n",
        "\n",
        "  cfg.batch_size = 512 # Default analysis batch size\n",
        "  if cfg.n_layers >= 3 and cfg.n_heads >= 4:\n",
        "    cfg.batch_size = 256 # Reduce batch size to avoid memory constraint issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "main_fname = cfg.file_config_prefix()\n",
        "main_fname_pth = main_fname + '.pth'\n",
        "main_fname_behavior_json = main_fname + '_behavior.json'\n",
        "main_fname_algorithm_json = main_fname + '_algorithm.json'\n",
        "\n",
        "def print_config():\n",
        "  print(\"%Add=\", cfg.perc_add(), \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", main_fname)\n",
        "\n",
        "print_config()\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)\n",
        "print('Main model will be read from HuggingLab file', main_fname_pth)\n",
        "print('Main model behavior analysis tags will be read from HuggingLab file', main_fname_behavior_json)\n",
        "print('Main model sub-task analysis tags will be read from HuggingLab file', main_fname_algorithm_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3A: Set Up: Vocabulary / Embedding / Unembedding\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSsQ8EpC1g7M"
      },
      "outputs": [],
      "source": [
        "main_fname_pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeObQk2kzAv7"
      },
      "outputs": [],
      "source": [
        "qt.set_maths_vocabulary(cfg)\n",
        "qt.set_maths_question_meanings(cfg)\n",
        "print(cfg.token_position_meanings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVkOJRmPvPms"
      },
      "source": [
        "# Part 6A: Set Up: Load nodes and behaviour tags\n",
        "Load the useful nodes and associated behaviour tags from a JSON file stored on HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naD2eCZevOsi"
      },
      "outputs": [],
      "source": [
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\"\n",
        "print(\"Loading useful node list with behavior tags from HuggingFace\", main_repo_name, main_fname_behavior_json)\n",
        "\n",
        "file_path = hf_hub_download(repo_id=main_repo_name, filename=main_fname_behavior_json, revision=\"main\")\n",
        "\n",
        "cfg.useful_nodes.load_nodes(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcCpfmKwlAH"
      },
      "source": [
        "# Part 6B: Results: Show nodes and behaviour tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbzIaqmtwmkH"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.sort_nodes()\n",
        "cfg.useful_nodes.print_node_tags()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_quanta_map( title, standard_quanta, cell_num_shades, \\\n",
        "        filters : qt.FilterNode, major_tag : qt.QType, minor_tag : str, get_node_details,  \\\n",
        "        image_width_inches : int = -1, image_height_inches : int = -1,\n",
        "        combine_identical_cells : bool = True, cell_fontsize : int = 9 ): \\\n",
        "\n",
        "  test_nodes = cfg.useful_nodes\n",
        "  if filters is not None:\n",
        "    test_nodes = qt.filter_nodes(test_nodes, filters)\n",
        "\n",
        "  ax1, quanta_results, num_results = qt.calc_quanta_map(\n",
        "      cfg, standard_quanta, cell_num_shades,\n",
        "      test_nodes, major_tag.value, minor_tag, get_node_details,\n",
        "      cell_fontsize, combine_identical_cells, image_width_inches, image_height_inches )\n",
        "\n",
        "  if num_results > 0:\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5tLgDG72GQDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 16A: Results: Show failure percentage map\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated."
      ],
      "metadata": {
        "id": "bcxRyJXpCCxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_quanta_map( \"Failure Frequency Behavior Per Node\", True, qt.FAIL_SHADES, None, qt.QType.FAIL, \"\", qt.get_quanta_fail_perc, 9, 2 * cfg.n_layers, False)"
      ],
      "metadata": {
        "id": "-njDS_PKCDMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifmtnLoTCN5"
      },
      "source": [
        "# Part 16B - Show answer impact behavior map\n",
        "\n",
        "Show the purpose of each useful cell by impact on the answer digits A0 to Amax.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K9PyCKYTUzX"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Answer Impact Behavior Per Node\", True, cfg.num_answer_positions, None, qt.QType.IMPACT, \"\", qt.get_quanta_impact, 9, 2 * cfg.n_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avCfaCT1Puhz"
      },
      "source": [
        "# Part 16C: Result: Show attention map\n",
        "\n",
        "Show attention quanta of useful heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTGoEWHgvFH6"
      },
      "outputs": [],
      "source": [
        "# Only maps attention heads, not MLP layers\n",
        "show_quanta_map( \"Attention Behavior Per Head\", True, qt.ATTN_SHADES, None, qt.QType.ATTN, \"\", qt.get_quanta_attention, 9, 3 * cfg.n_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7-99ZxDOrbF"
      },
      "source": [
        "# Part 16C - Show question complexity map\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show if addition (S), positive-answer subtraction (M) and negative-answer subtraction (N) questions relies on the node.\n",
        "  show_quanta_map( \"Maths Operation Coverage\", False,\n",
        "      4, None, qt.QType.MATH, \"\", qt.get_maths_operation_complexity, 9, 6,\n",
        "      combine_identical_cells=False)"
      ],
      "metadata": {
        "id": "mKeybAj3d6QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyoErRoCA-pz"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  # For each useful cell, show the minimum addition question complexity that relies on the node, as measured using quanta S0, S1, S2, ...\n",
        "  show_quanta_map( \"Addition Min-Complexity Behavior Per Node\", False,\n",
        "      qt.MATH_ADD_SHADES, None, qt.QType.MATH_ADD, qt.MathsBehavior.ADD_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity, 9, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMZzbjxUBQGE"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show the minimum \"positive-answer subtraction\" question complexity that relies on the node, as measured using quanta M0, M1, M2, ...\n",
        "  show_quanta_map( \"Positive-answer Subtraction Min-Complexity Per Node\", False,\n",
        "      qt.MATH_SUB_SHADES, None, qt.QType.MATH_SUB, qt.MathsBehavior.SUB_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity, 9, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUaT47ettc0M"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show the minimum \"negative-answer subtraction\" question complexity that relies on the node, as measured using quanta N0, N1, N2, ...\n",
        "  show_quanta_map( \"Negative-answer Subtraction Min-Complexity Per Node\", False,\n",
        "      qt.MATH_SUB_SHADES, None, qt.QType.MATH_NEG, qt.MathsBehavior.NEG_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity, 9, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 17: Set Up: Load algorithm sub-task tags from json file\n",
        "\n",
        "Load the useful nodes algorithmic sub-task tags from a JSON file stored on HuggingFace"
      ],
      "metadata": {
        "id": "_ve91mILCxOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\"\n",
        "print(\"Loading algorithm sub-tasks from HuggingFace\", main_repo_name, main_fname_algorithm_json)\n",
        "\n",
        "file_path = hf_hub_download(repo_id=main_repo_name, filename=main_fname_algorithm_json, revision=\"main\")\n",
        "\n",
        "cfg.useful_nodes.load_nodes(file_path)"
      ],
      "metadata": {
        "id": "sR4rZdgHGBhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQLfkdlbVAl_"
      },
      "source": [
        "# Part 23A: Show algorithm quanta map\n",
        "\n",
        "Plot the \"algorithm\" tags generated in previous steps as a quanta map. This is an automatically generated partial explanation of the model algorithm.\n",
        "\n",
        "Nodes with multiple tags were tagged (found) by more than one of the above task searches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9VDbjTAVGrP"
      },
      "outputs": [],
      "source": [
        "qt.print_algo_purpose_results(cfg)\n",
        "print()\n",
        "\n",
        "show_quanta_map( \"Algorithm Purpose Per Node\", True, 2, None, qt.QType.ALGO, \"\", qt.get_quanta_binary, 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Buqs9f6mNEj"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Attention Behavior Per Head\", True, qt.ATTN_SHADES, None, qt.QType.ATTN, \"\", qt.get_quanta_attention, 9, 3 * cfg.n_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_m3qiWYrjRJ"
      },
      "source": [
        "# Part 23B: Show known quanta per answer digit\n",
        "\n",
        "Each of the late positions are soley focused on calculating one answer digit. Show the data have we collected on late answer digit.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT8zKdHz1-fZ"
      },
      "outputs": [],
      "source": [
        "for position in range(cfg.num_question_positions + 1, cfg.n_ctx() - 1):\n",
        "  print(\"Position:\", position)\n",
        "\n",
        "  # Calculate a table of the known quanta for the specified position for each late token position\n",
        "  qt.calc_maths_quanta_for_position_nodes(cfg, position)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhheXmLTUfc"
      },
      "source": [
        "# Part 24: Show algorithm tags\n",
        "\n",
        "Show a list of the nodes that have proved useful in calculations, together with data on the nodes behavior and algorithmic purposes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRW6tiM8hDOB"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.print_node_tags(qt.QType.ALGO.value, \"\", False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbvzBDwPvoHw"
      },
      "outputs": [],
      "source": [
        "mixed_model = cfg.model_name.startswith(\"ins1_mix_d6_l3_h4_t40K\") or cfg.model_name.startswith(\"ins2_mix_d6_l4_h4_t40K\") or cfg.model_name.startswith(\"ins3_mix_d6_l4_h3_t40K\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D74GWTY3aKhm"
      },
      "source": [
        "# Part 25 : Results: Test Algorithm - Addition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGMji2snxax"
      },
      "source": [
        "## Part25A : Model add_d5_l1_h3_t30K. Tasks An.SA, An.SC, An.SS\n",
        "\n",
        "This 1-layer model cant do all addition questions. This hypothesis mirrors Paper 1. 14/15 heads have purpose assigned. 0/6 neurons have purpose assigned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYHKHxh-pHUd"
      },
      "outputs": [],
      "source": [
        "# For answer digits (excluding Amax), a An.SA node is needed before the answer digit is revealed\n",
        "def test_algo_sa(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.add_sa_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))\n",
        "\n",
        "# For answer digits (excluding Amax and A0), a An.SC node is needed before the answer digit is revealed\n",
        "def test_algo_sc(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    if impact_digit > 0:\n",
        "      cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.add_sc_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))\n",
        "\n",
        "# For answer digits (excluding Amax, A1 and A0), a An.SS node is needed before the answer digit is revealed\n",
        "def test_algo_ss(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    if impact_digit > 1:\n",
        "      cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.add_ss_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC4oY_HNn5_L"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name == \"add_d5_l1_h3_t30K\":\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_sa(algo_nodes)\n",
        "  test_algo_sc(algo_nodes)\n",
        "  test_algo_ss(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZk-BAE2n5kZ"
      },
      "source": [
        "## Part25B : Models add_d5/d6_l2_h3_t15K. Tasks An.SA, An.SC, An.SS, An.AC\n",
        "\n",
        "These 2 and 3-layer models can do addition accurately.\n",
        "\n",
        "- add_d6_l2_h3_t15K: 21/31 heads have purpose assigned. 0/17 neurons have purpose assigned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsmPe8rNzzvy"
      },
      "outputs": [],
      "source": [
        "# Before Amax is revealed (as a 0 or 1), there must be a Dn.C node for every digit pair\n",
        "# For each digit (except A0) there must be either an An.SS or an Dn.C\n",
        "def test_algo_ac_or_ss(model_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    early_ac = qt.FilterAnd(qt.FilterAlgo(qt.add_st_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(cfg.n_digits+1), qt.QCondition.MAX))\n",
        "    late_ac = qt.FilterAnd(qt.FilterAlgo(qt.add_st_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "    any_ss = qt.FilterAnd(qt.FilterAlgo(qt.add_ss_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "\n",
        "    if cfg.n_layers == 1:\n",
        "      # There must be a Dn.SS node for every answer digit except A0\n",
        "      if impact_digit > 0:\n",
        "        cfg.test_algo_clause(model_nodes, any_ss)\n",
        "    else:\n",
        "      # There must be a Dn.SS node or a Dn.C node for every digit except A0\n",
        "      if impact_digit > 0:\n",
        "        cfg.test_algo_clause(model_nodes, qt.FilterOr(any_ss, late_ac))\n",
        "\n",
        "      # There must a Dn.C node for every digit before the first 1 or 0 digit is calculated\n",
        "      cfg.test_algo_clause(model_nodes, early_ac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cmjOymxluQe"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name == \"add_d5_l2_h3_t15K\" or cfg.model_name == \"add_d6_l2_h3_t15K\":\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_sa(algo_nodes)\n",
        "  test_algo_sc(algo_nodes)\n",
        "  test_algo_ac_or_ss(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQxhIPzs5K6u"
      },
      "source": [
        "# Part 26: Results: Test Algorithm - Subtraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig0eUEDN5XmG"
      },
      "source": [
        "## Part 26A : Model sub_d6_l2_h3_t30K. Tasks MD, MB, MZ\n",
        "\n",
        "This 2-layer model can do subtraction accurately. TBC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_51OgGF3QURv"
      },
      "outputs": [],
      "source": [
        "# For answer digits (excluding Amax), An.MD and An.MB nodes are needed before the answer digit is revealed\n",
        "def test_algo_md_mb(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.sub_md_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))\n",
        "\n",
        "    cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.sub_mb_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))\n",
        "\n",
        "\n",
        "# For answer digits (excluding Amax), An.MZ nodes are needed before the answer digit is revealed\n",
        "def test_algo_mz(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "      pass\n",
        "      #cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(sub_mz_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axer3RNi6RSG"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name == \"sub_d6_l2_h3_t30K\":\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_md_mb(algo_nodes)\n",
        "  test_algo_mz(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aero_LUu3RX"
      },
      "source": [
        "## Part 26B: Test Algorithm - Subtraction - Negative Answer\n",
        "\n",
        "To accurately predict if the answer sign is + or - the model must calculate if\n",
        "D < D'. To calculate this, the model must calculate Dn < D'n or (Dn = D'n and (Dn-1 < D'n-1 or (Dn-2 = D'n-1 and ( etc. It must predict this before the answer sign is revealed.\n",
        "\n",
        "We expect to see nodes useful in negative answer questions, with PCA bigram (or trigram) outputs, attending to these input pairs, evaluated in this order, before the answer sign is revealed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMth-ecxu6NF"
      },
      "outputs": [],
      "source": [
        "# For answer digits (excluding Amax), An.SC is needed before the answer digit is revealed\n",
        "def test_algo_sc(algo_nodes):\n",
        "  sc_locations = {}\n",
        "\n",
        "  sign_position = cfg.an_to_position_name(cfg.n_digits+1)\n",
        "\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    # For answer digits (excluding the +/- answer sign and 0 or 1 first answer digit), An.SC is calculated before the answer sign is revealed\n",
        "    position = cfg.test_algo_clause(algo_nodes,  qt.FilterAnd(\n",
        "      qt.FilterAlgo(qt.sub_mt_tag(impact_digit)),\n",
        "      qt.FilterPosition(sign_position, qt.QCondition.MAX)))\n",
        "    sc_locations[impact_digit] = position\n",
        "\n",
        "  # Check that sc_locations[6] < sc_locations[5] < sc_locations[4] < etc\n",
        "  print(\"SC Locations:\", sc_locations)\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    if impact_digit > 0:\n",
        "      sc1 = sc_locations[impact_digit]\n",
        "      sc2 = sc_locations[impact_digit-1]\n",
        "      description = f\"SC Ordering: A{impact_digit}={sc1}, A{impact_digit-1}={sc2}\"\n",
        "      cfg.test_algo_logic(description, sc1 >= 0 and sc2 >= 0 and sc1 < sc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yrAg4sQu9g4"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name.startswith(\"sub_d6_l2_h3_t30K\") or cfg.model_name.startswith('ins1_mix_d6_l3_h4_t40K') :\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_sc(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCkA6qYCq4iS"
      },
      "source": [
        "# Part 27: Test Algorithm - Mixed Addition and Subtraction model\n",
        "\n",
        "What algorithm do mixed models use to perform both addition and subtraction? Our working hypothesis is Hypothesis 2 as described in https://github.com/PhilipQuirke/verified_transformers/blob/main/mixed_model.md\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFvLmWLf2JA3"
      },
      "source": [
        "## Part 27A: Calculating answer digit A2 in token position A3\n",
        "\n",
        "The below graph displays the same (behavior and algorithm) data as the quanta maps. Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/mixed_model.md section 27A for more explanation.\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1TQpYbs2JcZ"
      },
      "outputs": [],
      "source": [
        "qt.calc_maths_quanta_for_position_nodes(cfg, 18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgasUyOYMG9E"
      },
      "source": [
        "## Part 27.H3 Calculate whether D > D' (using NG tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClNYGvE6Q5T8"
      },
      "outputs": [],
      "source": [
        "filters = qt.FilterContains(qt.QType.MATH_NEG, \"\")\n",
        "\n",
        "#print(\"NG tagged nodes:\", qt.filter_nodes( cfg.useful_nodes, filters ).get_node_names())\n",
        "\n",
        "show_quanta_map( \"Subtraction Behavior NG Nodes\", False, 2, filters, qt.QType.MATH_SUB, \"\", qt.get_maths_min_complexity, 9, 6)\n",
        "show_quanta_map( \"Attention Behavior Per NG Head\", True, 10, filters, qt.QType.ATTN, \"\", qt.get_quanta_attention, 9, 8)\n",
        "show_quanta_map( \"Algorithm Purpose Per NG Node\", True, 2, filters, qt.QType.ALGO, \"\", qt.get_quanta_binary, 9, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mC4guryMA2k"
      },
      "outputs": [],
      "source": [
        "if mixed_model:\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_sc(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vxyIj1FP2Hq"
      },
      "source": [
        "# Part 30: Unit Test automated searches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6g2-mZ5UeJZ"
      },
      "outputs": [],
      "source": [
        "def check_algo_tag_exists(node_location_as_str, the_tags ):\n",
        "  node_location = qt.str_to_node_location(node_location_as_str)\n",
        "  node = cfg.useful_nodes.get_node(node_location)\n",
        "  assert node is not None\n",
        "\n",
        "  for the_tag in the_tags:\n",
        "    if not node.contains_tag(qt.QType.ALGO.value, the_tag):\n",
        "      print( \"Node\", node.name(), \"is missing tag\", the_tag, \"It has tags:\", node.tags )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr5SN-tuP1yO"
      },
      "outputs": [],
      "source": [
        "print(cfg.model_name)\n",
        "\n",
        "if cfg.model_name.startswith('add_d6_l2_h3_t15K'):\n",
        "  check_algo_tag_exists('P11L0H0', ['D2.TC'] )\n",
        "  check_algo_tag_exists('P12L0H0', ['D3.TC'] )\n",
        "  check_algo_tag_exists('P14L0H0', ['A5.SS', 'D4.TC'] )\n",
        "  check_algo_tag_exists('P14L0H2', ['A5.SC', 'D5.TC'] )\n",
        "  check_algo_tag_exists('P14L1H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A4.SC'] )\n",
        "  check_algo_tag_exists('P15L0H1', ['A5.SA'] )\n",
        "  check_algo_tag_exists('P15L0H2', ['A5.SA'] )\n",
        "  check_algo_tag_exists('P16L0H0', ['A3.SC'] )\n",
        "  check_algo_tag_exists('P16L0H1', ['A4.SA'] )\n",
        "  check_algo_tag_exists('P16L0H2', ['A4.SA'] )\n",
        "  check_algo_tag_exists('P17L0H0', ['A2.SC'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.SA'] )\n",
        "  check_algo_tag_exists('P17L0H2', ['A3.SA'] )\n",
        "  check_algo_tag_exists('P18L0H0', ['A1.SC'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.SA'] )\n",
        "  check_algo_tag_exists('P18L0H2', ['A2.SA'] )\n",
        "  check_algo_tag_exists('P19L0H0', ['A0.SC'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.SA'] )\n",
        "  check_algo_tag_exists('P19L0H2', ['A1.SA'] )\n",
        "  check_algo_tag_exists('P20L0H1', ['A0.SA'] )\n",
        "  check_algo_tag_exists('P20L0H2', ['A0.SA'] )\n",
        "\n",
        "if cfg.model_name.startswith('mix_d6_l3_h4_t40K'):\n",
        "  check_algo_tag_exists('P8L0H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L2H0', ['A7.NG'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H3', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P16L0H3', ['A4.SA.A4', 'A4.MD.A4'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.NG'] )\n",
        "  check_algo_tag_exists('P17L0H3', ['A3.SA.A3', 'A3.MD.A3'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.NG'] )\n",
        "  check_algo_tag_exists('P18L0H3', ['A2.SA.A2', 'A2.MD.A2'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.NG'] )\n",
        "  check_algo_tag_exists('P19L0H3', ['A1.SA.A1', 'A1.MD.A1'] )\n",
        "  check_algo_tag_exists('P20L0H0', ['A0.SA', 'A0.MD'] )\n",
        "  check_algo_tag_exists('P20L0H3', ['A0.SA', 'A0.MD'] )\n",
        "  check_algo_tag_exists('P20L2H1', ['A0.NG'] )\n",
        "\n",
        "if cfg.model_name.startswith('ins1_mix_d6_l3_h4_t40K'):\n",
        "  check_algo_tag_exists('P6L0H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P9L0H0', ['A4.MT'] )\n",
        "  check_algo_tag_exists('P9L0H1', ['A4.ST'] )\n",
        "  check_algo_tag_exists('P10L0H1', ['A2.MT'] )\n",
        "  check_algo_tag_exists('P10L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P12L0H0', ['A3.MT'] )\n",
        "  check_algo_tag_exists('P12L0H1', ['A3.ST'] )\n",
        "  check_algo_tag_exists('P12L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P12L1H2', ['A1.MT'] )\n",
        "  check_algo_tag_exists('P13L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L1H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L2H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P14L0H0', ['A5.SS', 'OPR'] )\n",
        "  check_algo_tag_exists('P14L0H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P14L0H2', ['A5.SC', 'A5.ST', 'SGN'] )\n",
        "  check_algo_tag_exists('P14L1H2', ['SGN'] )\n",
        "  check_algo_tag_exists('P14L1H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A4.SC'] )\n",
        "  check_algo_tag_exists('P15L0H1', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H2', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L0H0', ['A3.SC'] )\n",
        "  check_algo_tag_exists('P16L0H1', ['A4.SA', 'A4.MD', 'A4.ND'] )\n",
        "  check_algo_tag_exists('P16L0H2', ['A4.SA', 'A4.MD', 'A4.ND'] )\n",
        "  check_algo_tag_exists('P16L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L1H0', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L2H0', ['SGN'] )\n",
        "  check_algo_tag_exists('P17L0H0', ['A2.SC'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.SA', 'A3.MD', 'A3.ND'] )\n",
        "  check_algo_tag_exists('P17L0H2', ['A3.SA', 'A3.MD', 'A3.ND'] )\n",
        "  check_algo_tag_exists('P17L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P18L0H0', ['A1.SC'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.SA', 'A2.MD', 'A2.ND'] )\n",
        "  check_algo_tag_exists('P18L0H2', ['A2.SA', 'A2.MD', 'A2.ND'] )\n",
        "  check_algo_tag_exists('P19L0H0', ['A0.MB.A1'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.SA', 'A1.MD', 'A1.ND'] )\n",
        "  check_algo_tag_exists('P19L0H2', ['A1.SA', 'A1.MD', 'A1.ND'] )\n",
        "  check_algo_tag_exists('P20L0H1', ['A0.SA', 'A0.MD', 'A0.ND'] )\n",
        "  check_algo_tag_exists('P20L0H2', ['A0.SA', 'A0.MD', 'A0.ND'] )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jFcCpfmKwlAH",
        "avCfaCT1Puhz",
        "v7-99ZxDOrbF",
        "dZk-BAE2n5kZ",
        "ig0eUEDN5XmG"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}