{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Accurate Integer Mathematics in Transformers - Analyse the Model\n",
        "\n",
        "This CoLab analyses a Transformer model that performs integer addition, subtraction and multiplication e.g. 133357+182243=+0315600, 123450-345670=-0123230 and 000345*000823=+283935. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0A: Import libraries\n",
        "Imports standard libraries. Don't bother reading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCdmr6-_Jkzi",
        "outputId": "660a7c13-27be-4ee6-ac16-9dd602187596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    !pip install matplotlib\n",
        "    !pip install prettytable\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "    !pip install numpy\n",
        "    !pip install scikit-learn\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from prettytable import PrettyTable\n",
        "import itertools\n",
        "import re\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNpIsCqtETtF"
      },
      "source": [
        "# Part 0B: Import PCA library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUt2mMzFj7eA"
      },
      "outputs": [],
      "source": [
        "# Import Principal Component Analysis (PCA) library\n",
        "use_pca = True\n",
        "try:\n",
        "  from sklearn.decomposition import PCA\n",
        "except Exception as e:\n",
        "  print(\"pca import failed with exception:\", e)\n",
        "  use_pca = False\n",
        "\n",
        "  # Sometimes version conflicts means the PCA library does not import. This workaround partially fixes the issue\n",
        "  !pip install --upgrade numpy\n",
        "  !pip install --upgrade scikit-learn\n",
        "\n",
        "  # To complete workaround, now select menu option \"Runtime > Restart session and run all\".\n",
        "  stop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQlQPB78lJnc"
      },
      "source": [
        "# Part 0C: Import verified_transformers library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2P3cndolKDM"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade git+https://github.com/PhilipQuirke/verified_transformers.git\n",
        "from QuantaTools import QuantaFilter, QuantaType, position_name, position_name_to_int, row_location_name, location_name, NodeLocation, UsefulNode, str_to_node_location, UsefulInfo, useful_info, answer_name\n",
        "from QuantaTools import token_to_char, tokens_to_string\n",
        "from QuantaTools import FilterAnd, FilterOr, FilterHead, FilterNeuron, FilterContains, FilterPosition, FilterAttention, FilterImpact, FilterPCA, FilterAlgo, filter_nodes\n",
        "from QuantaTools import create_custom_colormap, calc_quanta_map, get_quanta_fail_perc, get_quanta_attention, get_quanta_binary\n",
        "from QuantaTools import get_answer_impact, get_question_answer_impact, compact_answer_if_sequential, get_quanta_impact"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQNjIosyX9Y-"
      },
      "source": [
        "# Part 1A: Configuration: Detailed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwXrSj8KGj-v"
      },
      "outputs": [],
      "source": [
        "# Tokens used in vocab. (Token indexes 0 to 9 represent digits 0 to 9)\n",
        "PLUS_INDEX = 10\n",
        "MINUS_INDEX = 11\n",
        "EQUALS_INDEX = 12\n",
        "MULT_INDEX = 13\n",
        "DIV_INDEX = 14\n",
        "MAX_INDEX = DIV_INDEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmjGdFcdJat3"
      },
      "outputs": [],
      "source": [
        "# Main configuration class for main model creation and training\n",
        "class Config():\n",
        "  #@markdown Main Model\n",
        "  n_layers: int = 3 #@param\n",
        "  n_heads: int = 4 #@param\n",
        "\n",
        "  d_vocab: int = MAX_INDEX+1\n",
        "  d_model: int = 510\n",
        "  d_mlp_multiplier: int = 4\n",
        "  d_mlp: int = d_mlp_multiplier * d_model\n",
        "  d_head: int = 170\n",
        "  training_seed: int = 372001\n",
        "  analysis_seed: int = 673023\n",
        "\n",
        "  #@markdown Data\n",
        "  n_digits: int = 6 #@param\n",
        "  act_fn: str = 'relu'\n",
        "  batch_size: int = 512 # Training used 64. Larger for speed during analysis\n",
        "\n",
        "  #@markdown Optimizer\n",
        "  n_training_steps: int = 40000 #@param\n",
        "  weight_decay: float = 0.00008\n",
        "  lr: int = 0.1\n",
        "\n",
        "  #@markdown Actions\n",
        "\n",
        "  # Percent of questions that are multiplication, subtraction (rest are addition questions).\n",
        "  perc_mult: int = 0 # e.g. 20\n",
        "  perc_sub: int = 0 #@param e.g. 80\n",
        "  def perc_add(self):\n",
        "    return max(0, 100 - self.perc_mult - self.perc_sub)\n",
        "\n",
        "  #@markdown Insert Model\n",
        "  insert_mode: int = 0 #@param 0=None 1=Init, 2=FreezeHeads 3=FreezeAll\n",
        "\n",
        "\n",
        "  # Save graphs to CoLab temp files as PDF or SVG. You can manually export temp files for re-use in papers.\n",
        "  graph_file_suffix = \"svg\"\n",
        "\n",
        "  # The format to output prettytable in. Options are text|html|json|csv|latex\n",
        "  # Use Text for this CoLab, latex for Overleaf output, and html for GitHub blog output\n",
        "  table_out_format: str = \"text\"\n",
        "\n",
        "\n",
        "  # The number of question tokens\n",
        "  # This is also the token position of the first answer digit (which is a \"+\" or a  \"-\")\n",
        "  def question_tokens(self):\n",
        "    return self.n_digits*2 + 2\n",
        "  def answer_tokens(self):\n",
        "    return self.n_digits + 2\n",
        "  def n_ctx(self):\n",
        "    return self.question_tokens() + self.answer_tokens()\n",
        "\n",
        "  # How many slices do we break the MLP layer up into?\n",
        "  def mlp_slices(self):\n",
        "    return 1 # Paper 2 used this granualarity\n",
        "    # return self.n_heads * self.d_mlp_multiplier # Alternative for Paper 3?\n",
        "\n",
        "  # Model name prefix for models stored on HuggingFace\n",
        "  model_name = \"\"\n",
        "\n",
        "  main_model : HookedTransformer = None\n",
        "\n",
        "\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1B: Configuration: Summary\n",
        "\n",
        "Which existing model do we want to analyse?\n",
        "\n",
        "The existing model weightings created by the sister Colab [VerifiedArithmeticTrain](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/VerifiedArithmeticTrain.ipynb) are loaded from HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Which existing model do we want to analyse?\n",
        "# cfg.model_name = \"\" # Use configuration specified in Part 1A\n",
        "# cfg.model_name = \"add_d5_l1_h3_t30K\"  # 5 digit addition model. Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions\n",
        "# cfg.model_name = \"add_d5_l2_h3_t15K\"  # 5 digit addition model\n",
        "# cfg.model_name = \"add_d6_l2_h3_t15K\"  # 6 digit addition model\n",
        "cfg.model_name = \"sub_d6_l2_h3_t30K\"  # 6 digit subtraction model\n",
        "# cfg.model_name = \"mix_d6_l3_h4_t40K\"  # 6 digit addition and subtraction model. AvgFinalLoss=8e-09\n",
        "# cfg.model_name = \"ins1_mix_d6_l3_h4_t40K\"  # 6 digit addition / subtraction model. Initialise with addition model. Handles 1m Qs for Add and Sub\n",
        "# cfg.model_name = \"ins2_mix_d6_l4_h4_t40K\"  # 6 digit addition / subtraction model. Initialised with addition model. Reset useful heads every 100 epochs. AvgFinalLoss=7e-09. Fails 1m Qs\n",
        "# cfg.model_name = \"ins3_mix_d6_l4_h3_t40K\"  # 6 digit addition / subtraction model. Initialised with addition model. Reset useful heads & MLPs every 100 epochs. AvgFinalLoss=2.6e-06. Fails 1m Qs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1C: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BiELcf53ms"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name != \"\":\n",
        "\n",
        "  match = re.search(\"d(\\d)_\", cfg.model_name)\n",
        "  if match:\n",
        "    cfg.n_digits = int(match.group(1))\n",
        "\n",
        "  match = re.search(\"l(\\d)_\", cfg.model_name)\n",
        "  if match:\n",
        "    cfg.n_layers = int(match.group(1))\n",
        "\n",
        "  match = re.search(\"h(\\d)_\", cfg.model_name)\n",
        "  if match:\n",
        "    cfg.n_heads = int(match.group(1))\n",
        "\n",
        "  match = re.search(\"t(\\d\\d)K\", cfg.model_name)\n",
        "  if match:\n",
        "    cfg.n_training_steps = int(match.group(1)) * 1000\n",
        "\n",
        "  cfg.perc_sub = 0\n",
        "  cfg.insert_mode = 0\n",
        "\n",
        "  if cfg.model_name.startswith(\"sub_\") :\n",
        "    cfg.perc_sub = 100\n",
        "\n",
        "  if cfg.model_name == \"mix_d6_l3_h4_t40K\" :\n",
        "    cfg.batch_size = 256\n",
        "    cfg.perc_sub = 66 # Train on 66% subtraction and 33% addition question batches\n",
        "\n",
        "  if cfg.model_name == \"ins1_mix_d6_l3_h4_t40K\" :\n",
        "    cfg.batch_size = 256\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "    cfg.insert_mode = 1 # Initialise with add_d6_l2_h3_t15K.pth.\n",
        "\n",
        "  if cfg.model_name == \"ins2_mix_d6_l4_h4_t40K\" :\n",
        "    cfg.batch_size = 256\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "    cfg.insert_mode = 2 # Initialise with add_d6_l2_h3_t15K.pth. Train & reset useful heads every 100 epochs\n",
        "\n",
        "  if cfg.model_name == \"ins3_mix_d6_l4_h3_t40K\" :\n",
        "    cfg.batch_size = 256\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "    cfg.insert_mode = 3 # Initialise with add_d6_l2_h3_t15K.pth. Trained & reset useful heads & MLPs every 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "def file_prefix():\n",
        "  op_prefix = 'mul' if cfg.perc_mult == 100 else 'sub' if cfg.perc_sub == 100 else 'add' if cfg.perc_add() == 100 else 'mix'\n",
        "\n",
        "  return op_prefix + '_d{}_l{}_h{}_'.format(cfg.n_digits, cfg.n_layers, cfg.n_heads)\n",
        "\n",
        "\n",
        "\n",
        "train_str = str(cfg.n_training_steps//1000) + \"K\"\n",
        "main_fname = '' if cfg.insert_mode == 0 else 'ins{}_'.format(cfg.insert_mode)\n",
        "main_fname += file_prefix() + 't{}_s{}'.format(train_str, cfg.training_seed)\n",
        "main_fname_pth = main_fname + '.pth'\n",
        "main_fname_behavior_json = main_fname + '_behavior.json'\n",
        "main_fname_algorithm_json = main_fname + '_algorithm.json'\n",
        "\n",
        "def print_config():\n",
        "  print(\"%Mult=\", cfg.perc_mult, \"%Sub=\", cfg.perc_sub, \"%Add=\", cfg.perc_add(), \"File\", main_fname)\n",
        "\n",
        "print_config()\n",
        "print('Main model will be read from HuggingLab file', main_fname_pth)\n",
        "print('Main model behavior analysis tags will save to Colab temporary file', main_fname_behavior_json)\n",
        "print('Main model algorithm analysis tags will save to Colab temporary file', main_fname_algorithm_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3A: Set Up: Vocabulary / Embedding / Unembedding\n",
        "\n",
        "Convert from\n",
        "- Human-readable character to numeric token index.\n",
        "- Convert numeric token positions to position \"meanings\"\n",
        "- Convert from number to human-readable stringand vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9NqtFCe18PI"
      },
      "outputs": [],
      "source": [
        "# Vocabulary dictionary: Mapping from character (key) to token (value)\n",
        "useful_info.char_to_token = {str(i) : i for i in range(10)}\n",
        "useful_info.char_to_token['+'] = PLUS_INDEX\n",
        "useful_info.char_to_token['-'] = MINUS_INDEX\n",
        "useful_info.char_to_token['='] = EQUALS_INDEX\n",
        "useful_info.char_to_token['*'] = MULT_INDEX\n",
        "useful_info.char_to_token['\\\\'] = DIV_INDEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QYFZIalJ3tK"
      },
      "outputs": [],
      "source": [
        "# Unit tests\n",
        "assert token_to_char(4) == '4'\n",
        "assert token_to_char(MULT_INDEX) == '*'\n",
        "assert tokens_to_string([EQUALS_INDEX,4,0,7]) == '=407'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeObQk2kzAv7"
      },
      "outputs": [],
      "source": [
        "# Convert D0 to P5, D1 to P4, D2 to P3 in 6 digit addition\n",
        "def dn_to_position_name(n):\n",
        "  return position_name(cfg.n_digits - 1 - n)\n",
        "# Convert D'0 to P10, D'1 to P9, D'2 to P8, etc in 6 digit addition\n",
        "def ddn_to_position_name(n):\n",
        "  return position_name(2 * cfg.n_digits - n)\n",
        "# Convert A0 to P20, A1 to P19, A2 to P18, etc in 6 digit addition\n",
        "def an_to_position_name(n):\n",
        "  return position_name(cfg.n_ctx() - 1 - n)\n",
        "# Position of the operator (+, -, * or /)\n",
        "def op_position_name():\n",
        "  return position_name(cfg.n_digits)\n",
        "\n",
        "\n",
        "def set_question_meanings():\n",
        "  # Question and answer token position meanings D5, .., D0, *, D5', .., D0', =, A7, A6, .., A0\n",
        "  q_meanings = []\n",
        "  for i in range(cfg.n_digits):\n",
        "    q_meanings += [\"D\" + str(cfg.n_digits-i-1)]\n",
        "  q_meanings += \"+\" # Stands in for operation +, - or *\n",
        "  for i in range(cfg.n_digits):\n",
        "    q_meanings += [\"D'\" + str(cfg.n_digits-i-1)]\n",
        "  q_meanings += [\"=\"]\n",
        "\n",
        "  useful_info.initialize_token_positions(cfg.question_tokens(), cfg.answer_tokens(), False )\n",
        "  useful_info.token_position_meanings = q_meanings + useful_info.token_position_meanings[-useful_info.num_answer_positions:]\n",
        "  print(useful_info.token_position_meanings)\n",
        "\n",
        "\n",
        "set_question_meanings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-lFFjjgWAM_"
      },
      "outputs": [],
      "source": [
        "def int_to_answer_str( n ):\n",
        "  s = str(abs(n))\n",
        "  while len(s) < cfg.n_digits + 1 :\n",
        "    s = \"0\" + s\n",
        "  s = (\"+\" if n >= 0 else \"-\") + s\n",
        "  return s\n",
        "\n",
        "\n",
        "# Unit test\n",
        "if cfg.n_digits == 6 :\n",
        "  assert int_to_answer_str(1234) == \"+0001234\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHQpt2iOqffb"
      },
      "outputs": [],
      "source": [
        "# Convert \"0012345\" to 12345\n",
        "def tokens_to_unsigned_int( q, offset, digits ):\n",
        "  a = 0\n",
        "  for j in range(digits):\n",
        "    a = a * 10 + q[offset+j]\n",
        "  return a\n",
        "\n",
        "\n",
        "# Convert \"-12345\" to -12345, and \"+12345\" to 12345\n",
        "def tokens_to_answer(q):\n",
        "  # offset of sign character\n",
        "  sign_offset = cfg.question_tokens()\n",
        "\n",
        "  # 5 digit addition yields a 6 digit answer. So cfg.n_digits+1 DIGITS\n",
        "  answer_digits = cfg.n_digits+1\n",
        "\n",
        "  a = tokens_to_unsigned_int( q, sign_offset+1, answer_digits )\n",
        "  if q[sign_offset] == MINUS_INDEX:\n",
        "    a = - a\n",
        "\n",
        "  return a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6rUaYvjOcE"
      },
      "source": [
        "# Part 3B: Set Up: Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Transformer creation\n",
        "\n",
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = HookedTransformerConfig(\n",
        "    n_layers = cfg.n_layers,\n",
        "    n_heads = cfg.n_heads,\n",
        "    d_model = cfg.d_model,\n",
        "    d_head = cfg.d_head,\n",
        "    d_mlp = cfg.d_mlp,\n",
        "    act_fn = cfg.act_fn,\n",
        "    normalization_type = 'LN',\n",
        "    d_vocab = cfg.d_vocab,\n",
        "    d_vocab_out = cfg.d_vocab,\n",
        "    n_ctx = cfg.n_ctx(),\n",
        "    init_weights = True,\n",
        "    device = \"cuda\",\n",
        "    seed = cfg.training_seed,\n",
        ")\n",
        "\n",
        "cfg.main_model = HookedTransformer(ht_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiJhch4KCej"
      },
      "source": [
        "# Part 4: Set Up: Loss Function & Data Generator\n",
        "This section defines the loss function and the training/testing data generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ2iNO-nKDBW"
      },
      "outputs": [],
      "source": [
        "# Loss functions\n",
        "\n",
        "# Calculate the per-token probability by comparing a batch of prediction \"logits\" to answer \"tokens\"\n",
        "def logits_to_tokens_loss(logits, tokens):\n",
        "  # Addition answer can have one extra digit than question. Answer also has a +/- sign\n",
        "  n_answer_digits = cfg.n_digits+2\n",
        "\n",
        "  # The addition answer digit token probabilities\n",
        "  ans_logits = logits[:, -(n_answer_digits+1):-1]\n",
        "\n",
        "  # Convert raw score (logits) vector into a probability distribution.\n",
        "  # Emphasize the largest scores and suppress the smaller ones, to make them more distinguishable.\n",
        "  ans_probs = F.log_softmax(ans_logits.to(torch.float64), dim=-1)\n",
        "\n",
        "  max_prob_tokens = torch.argmax(ans_probs, dim=-1)\n",
        "\n",
        "  # The addition answer digit tokens\n",
        "  ans_tokens = tokens[:, -(n_answer_digits):]\n",
        "\n",
        "  # Extract values from the ans_probs tensor, based on indices from the ans_tokens tensor\n",
        "  ans_loss = torch.gather(ans_probs, -1, ans_tokens[:, :, None])[..., 0]\n",
        "\n",
        "  return ans_loss, max_prob_tokens\n",
        "\n",
        "\n",
        "# Calculate loss as negative of average per-token mean probability\n",
        "def loss_fn(ans_loss):\n",
        "  return -ans_loss.mean(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUobUMfCkLcs"
      },
      "outputs": [],
      "source": [
        "# Generate an enriched data batch for one operator type\n",
        "# \"Addition\" batch entries are formated XXXXX+YYYYY=+ZZZZZZ e.g. 550030+800020=+1350050\n",
        "# \"Subtraction\" batch entries are formated XXXXX-YYYYY=-ZZZZZZ e.g. 550030-800020=-0249990, 800020-550030=+0249990\n",
        "# \"Multiplication\" batch entries are formated 000XXX*000YYY=+ZZZZZZ e.g. 000345*000678=+233910\n",
        "def data_generator_core( batch_op ):\n",
        "\n",
        "  batch = torch.zeros((cfg.batch_size, cfg.n_ctx())).to(torch.int64)\n",
        "  x = torch.randint(0, 10, (cfg.batch_size, cfg.n_digits))\n",
        "  y = torch.randint(0, 10, (cfg.batch_size, cfg.n_digits))\n",
        "\n",
        "  if batch_op == MULT_INDEX:\n",
        "    # Convert from NNNNNN*NNNNNN= to 000NNN*000NNN= so answer (product) is NNNNNN\n",
        "    num_zeros = cfg.n_digits // 2\n",
        "    for z in range(num_zeros):\n",
        "      x[:, z] = 0\n",
        "      y[:, z] = 0\n",
        "\n",
        "  # Enrich the question data on 60% of batches to speed up training\n",
        "  if ( batch_op == PLUS_INDEX or batch_op == MINUS_INDEX ) and (random.randint(1, 5) < 3):\n",
        "    # Flatten x and y to 1D tensors\n",
        "    x_flat = x.view(-1)\n",
        "    y_flat = y.view(-1)\n",
        "\n",
        "    if batch_op == PLUS_INDEX :\n",
        "      # The UseSum9 task is compound and rare and so hard to learn.\n",
        "      # Increase the MakeSum9 case frequency\n",
        "      # UseSum9 also relies on MakeCarry1 (50%) from previous column.\n",
        "      num_elements_to_modify = int(0.40 * x.numel()) # 40%\n",
        "      indices_to_modify = torch.randperm(x_flat.numel())[:num_elements_to_modify]\n",
        "      if random.randint(1, 2) == 1:\n",
        "        x_flat[indices_to_modify] = 9 - y_flat[indices_to_modify]\n",
        "      else:\n",
        "        y_flat[indices_to_modify] = 9 - x_flat[indices_to_modify]\n",
        "    else:\n",
        "      # Empirically, the model seems to struggle with the sign calculation.\n",
        "      # Minus signs are rarer than positive signs.\n",
        "      # Generate more negative answers by increasing the y value\n",
        "      y_flat[y_flat < 9] += 1\n",
        "\n",
        "    # Reshape x and y back to its original shape\n",
        "    x = x_flat.view(x.shape)\n",
        "    y = y_flat.view(x.shape)\n",
        "\n",
        "\n",
        "  first_answer_index = cfg.question_tokens()\n",
        "\n",
        "  batch[:, :cfg.n_digits] = x\n",
        "  batch[:, cfg.n_digits] = batch_op\n",
        "  batch[:, 1+cfg.n_digits:1+cfg.n_digits*2] = y\n",
        "  batch[:, first_answer_index-1] = EQUALS_INDEX\n",
        "\n",
        "  # Convert each row into a 5-digit number\n",
        "  x_values = x[:, 0]\n",
        "  y_values = y[:, 0]\n",
        "  for dn in range(1,cfg.n_digits):\n",
        "    x_values = x_values * 10 + x[:, dn]\n",
        "    y_values = y_values * 10 + y[:, dn]\n",
        "\n",
        "  # Elementwise operations to give the 1D tensor answers\n",
        "  if batch_op == MULT_INDEX:\n",
        "    answers = x_values * y_values\n",
        "  else:\n",
        "    if batch_op == MINUS_INDEX:\n",
        "      answers = x_values - y_values\n",
        "    else:\n",
        "      answers = x_values + y_values\n",
        "\n",
        "  # Insert the answers into the batch\n",
        "  for i in range(cfg.batch_size):\n",
        "    answer = answers[i]\n",
        "\n",
        "    sign = PLUS_INDEX\n",
        "    if answer < 0:\n",
        "      sign = MINUS_INDEX\n",
        "      answer = - answer\n",
        "\n",
        "    batch[i, first_answer_index] = sign\n",
        "    for j in range(cfg.n_digits+1):\n",
        "      batch[i, cfg.n_ctx()-j-1] = answer % 10\n",
        "      answer = answer // 10\n",
        "      if answer == 0:\n",
        "          break\n",
        "\n",
        "  return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSp8pS1eKHf6"
      },
      "outputs": [],
      "source": [
        "# Define \"iterator\" data generator function. Invoked using next().\n",
        "def data_generator( ):\n",
        "  torch.manual_seed(cfg.analysis_seed)\n",
        "  while True:\n",
        "\n",
        "    batch_rand = random.randint(1, 100)\n",
        "    batch_op = MULT_INDEX if batch_rand <= cfg.perc_mult else MINUS_INDEX if batch_rand <= cfg.perc_mult + cfg.perc_sub else PLUS_INDEX\n",
        "\n",
        "    batch = data_generator_core( batch_op )\n",
        "\n",
        "    yield batch.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqzljhQ4KJU5"
      },
      "outputs": [],
      "source": [
        "# Initialise the data generator\n",
        "ds = data_generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtmioT1THbJA"
      },
      "outputs": [],
      "source": [
        "# Run data generator\n",
        "print(next(ds)[:3,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5: Set Up: Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0"
      },
      "outputs": [],
      "source": [
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\"\n",
        "print(\"Loading model from HuggingFace\", main_repo_name, main_fname_pth)\n",
        "\n",
        "cfg.main_model.load_state_dict(utils.download_file_from_hf(repo_name=main_repo_name, file_name=main_fname_pth, force_is_torch=True))\n",
        "cfg.main_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGxoBWHNKRf0"
      },
      "source": [
        "# Part 6A: Set Up: Major Quanta types\n",
        "\n",
        "Extending the imported QuantaType values (POSITION, FAIL, IMPACT, ATTENTION and ALGO), we define model-specific QuantaType values  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-32U35C94MR4"
      },
      "outputs": [],
      "source": [
        "# What type of mathematical operation was the question\n",
        "QuantaType_MATH_ADD = \"Math.Add\"\n",
        "QuantaType_MATH_SUB = \"Math.Sub\"\n",
        "QuantaType_MATH_VARIED = \"Math.Varied\" # Mixture of question types. Aka Unknown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6W57CphAUls"
      },
      "source": [
        "# Part 6B: Set Up: Minor Quanta types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr4OZri5sq1S"
      },
      "outputs": [],
      "source": [
        "# Related to QuantaType.IMPACT:\n",
        "# No answer digits were impacted by the intervention\n",
        "NO_IMPACT_TAG = \"(none)\"\n",
        "\n",
        "\n",
        "# Related to QuantaType.PCA:\n",
        "# PCA says the node outputs is interpretable aligned to the T8,T9,T10 questions, giving 2 or 3 distinct output clusters\n",
        "PCA_ADD_TAG = \"TR\"\n",
        "\n",
        "\n",
        "\n",
        "# Related to QuantaType_MATH_ADD:\n",
        "# Addition operation \"complexity\" minor tags\n",
        "MATH_ADD_S0_TAG = \"S0\"\n",
        "MATH_ADD_S1_TAG = \"S1\"\n",
        "MATH_ADD_S2_TAG = \"S2\"\n",
        "MATH_ADD_S3_TAG = \"S3\"\n",
        "MATH_ADD_S4_TAG = \"S4\"\n",
        "MATH_ADD_S5_TAG = \"S5\"\n",
        "\n",
        "\n",
        "# Related to QuantaType_MATH_SUB:\n",
        "# Subtraction operation \"complexity\" minor tags\n",
        "MATH_SUB_S0_TAG = \"M0\"\n",
        "MATH_SUB_S1_TAG = \"M1\"\n",
        "MATH_SUB_S2_TAG = \"M2\"\n",
        "MATH_SUB_S3_TAG = \"M3\"\n",
        "MATH_SUB_NG_TAG = \"NG\"\n",
        "\n",
        "\n",
        "# Related to QuantaType.ALGO:\n",
        "ALGO_ADD_BA_TAG = \"BA\" # Addition - Base Add (Dn, D'n)\n",
        "ALGO_ADD_MC_TAG = \"MC\" # Addition - Make Carry (Dn, D'n)\n",
        "ALGO_ADD_US_TAG = \"US\" # Addition - Use Sum 9 (Dn, D'n)\n",
        "ALGO_ADD_TC_TAG = \"TC\" # Addition - TriCase (Dn, D'n)\n",
        "ALGO_SUB_BS_TAG = \"BS\" # Subtraction - Base Sub (Dn, D'n)\n",
        "ALGO_SUB_BO_TAG = \"BO\" # Subtraction - Borrow One (Dn, D'n)\n",
        "ALGO_SUB_SZ_TAG = \"SZ\" # Subtraction - Sum Zero (Dn, D'n)\n",
        "ALGO_SUB_NG_TAG = \"NG\" # Subtraction - Answer is negative (that is A - B where A < B)\n",
        "ALGO_MIX_OP_TAG = \"OP\" # Add/Sub - Attends to operation token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-yFKiDllqEf"
      },
      "source": [
        "# Part 7B: Set Up: Create sample questions by Complexity Quanta\n",
        "\n",
        "Sets of sample questions by complexity quanta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oj_xSuSSKR9t"
      },
      "outputs": [],
      "source": [
        "# Insert a number into the question\n",
        "def insert_question_number(the_question, index, first_digit_index, the_digits, n):\n",
        "\n",
        "  last_digit_index = first_digit_index + the_digits - 1\n",
        "\n",
        "  for j in range(the_digits):\n",
        "    the_question[index, last_digit_index-j] = n % 10\n",
        "    n = n // 10\n",
        "\n",
        "\n",
        "# Create a single question\n",
        "def make_a_question(the_question, index, q1, q2, operator ):\n",
        "\n",
        "  insert_question_number(the_question, index, 0, cfg.n_digits, q1)\n",
        "\n",
        "  the_question[index, cfg.n_digits] = operator\n",
        "\n",
        "  insert_question_number( the_question, index, cfg.n_digits+1, cfg.n_digits, q2)\n",
        "\n",
        "  the_question[index, 2*cfg.n_digits+1] = EQUALS_INDEX\n",
        "\n",
        "  answer = q1+q2\n",
        "  if operator == MINUS_INDEX:\n",
        "    answer = q1-q2\n",
        "  else:\n",
        "    if operator == MULT_INDEX:\n",
        "      answer = q1*q2\n",
        "\n",
        "  the_question[index, 2*cfg.n_digits+2] = PLUS_INDEX if answer >= 0 else MINUS_INDEX\n",
        "  if answer < 0:\n",
        "    answer = -answer\n",
        "\n",
        "  insert_question_number(the_question, index, 2*cfg.n_digits + 3, cfg.n_digits+1, answer)\n",
        "\n",
        "\n",
        "# Create a batch of questions from a 2D matrix of ints\n",
        "def make_questions(operator, q_matrix):\n",
        "  max_len = len(q_matrix)\n",
        "  real_len = 0\n",
        "  questions = torch.zeros((max_len, cfg.n_ctx())).to(torch.int64)\n",
        "  limit = 10 ** cfg.n_digits\n",
        "\n",
        "  for i in range(max_len):\n",
        "    a = q_matrix[i][0]\n",
        "    b = q_matrix[i][1]\n",
        "\n",
        "    if a < limit and b < limit:\n",
        "      make_a_question(questions, real_len, a, b, operator)\n",
        "      real_len += 1\n",
        "\n",
        "  return questions[:real_len]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRCPyETTKaEs"
      },
      "outputs": [],
      "source": [
        "# Manually create some questions that strongly test one quanta\n",
        "\n",
        "\n",
        "# Make BaseAdd questions\n",
        "def make_s0_questions():\n",
        "    return QuantaType_MATH_ADD, MATH_ADD_S0_TAG, make_questions( PLUS_INDEX,\n",
        "      [[0, 0],\n",
        "      [1, 3],\n",
        "      [12345, 33333],\n",
        "      [33333, 12345],\n",
        "      [45762, 33113],\n",
        "      [888, 11111],\n",
        "      [2362, 23123],\n",
        "      [15, 81],\n",
        "      [1000, 4441],\n",
        "      [4440, 11111],\n",
        "      [24033, 25133],\n",
        "      [23533, 21133],\n",
        "      [32500, 1],\n",
        "      [31500, 1111],\n",
        "      [5500, 12323],\n",
        "      [4500, 2209],\n",
        "      [33345, 66643], # =099988\n",
        "      [66643, 33345], # =099988\n",
        "      [10770, 44111],\n",
        "      [60000, 31111],\n",
        "      [10000, 21111],\n",
        "      [107700, 441111],\n",
        "      [600000, 311111],\n",
        "      [100000, 211111],\n",
        "      [1077000, 4411111],\n",
        "      [6000000, 3111111],\n",
        "      [1000000, 2111111],\n",
        "      [10770000, 44111111],\n",
        "      [60000000, 3111111],\n",
        "      [10000000, 2111111]])\n",
        "\n",
        "# Make UseCarry1 (addition) questions\n",
        "def make_s1_questions():\n",
        "    return QuantaType_MATH_ADD, MATH_ADD_S1_TAG, make_questions( PLUS_INDEX,\n",
        "      [[ 15, 45],\n",
        "      [ 27, 55],\n",
        "      [ 35, 59],\n",
        "      [ 150, 451],\n",
        "      [ 270, 551],\n",
        "      [ 350, 591],\n",
        "      [ 1500, 4511],\n",
        "      [ 2700, 5511],\n",
        "      [ 3500, 5911],\n",
        "      [ 40035, 41149],\n",
        "      # [ 44000, 46000], D6 L1 H3 model cant handle this.\n",
        "      [ 70000, 41111],\n",
        "      [ 15000, 25111],\n",
        "      [ 35000, 35111],\n",
        "      [ 45000, 35111],\n",
        "      [ 67000, 25111],\n",
        "      [ 19000, 76111],\n",
        "      [ 15020, 45091],\n",
        "      [ 25002, 55019],\n",
        "      [ 35002, 59019],\n",
        "      [ 150211, 450911],\n",
        "      [ 250021, 550191],\n",
        "      [ 350021, 590191],\n",
        "      [ 1502111, 4509111],\n",
        "      [ 2500211, 5501911],\n",
        "      [ 3500211, 5901911],\n",
        "      [ 15021111, 45091111],\n",
        "      [ 25002111, 55019111],\n",
        "      [ 35002111, 59019111]])\n",
        "\n",
        "\n",
        "# Make SimpleUseSum9 (addition) questions\n",
        "def make_s2_questions():\n",
        "    return QuantaType_MATH_ADD,MATH_ADD_S2_TAG, make_questions( PLUS_INDEX,\n",
        "      [[ 55, 45],\n",
        "      [ 45, 55],\n",
        "      [ 45, 59],\n",
        "      [ 35, 69],\n",
        "      [ 25, 79],\n",
        "      [ 15, 85],\n",
        "      [ 15, 88],\n",
        "      [ 15518, 14511],\n",
        "      [ 14518, 15511],\n",
        "      [ 24533, 25933],\n",
        "      [ 23533, 26933],\n",
        "      [ 32511, 7911],\n",
        "      [ 31511, 8511],\n",
        "      [ 551, 451],\n",
        "      [ 451, 551],\n",
        "      [ 10881, 41127],\n",
        "      [ 41127, 10881],\n",
        "      [ 12386, 82623],\n",
        "      [ 108811, 411271],\n",
        "      [ 411271, 108811],\n",
        "      [ 123861, 826231],\n",
        "      [ 994890, 80105],\n",
        "      [ 970590, 96026],\n",
        "      [ 994890, 80105],\n",
        "      [ 970590, 96026],\n",
        "      [ 1088111, 4112711],\n",
        "      [ 4112711, 1088111],\n",
        "      [ 1238611, 8262311],\n",
        "      [ 10881111, 41127111],\n",
        "      [ 41127111, 10881111],\n",
        "      [ 12386111, 82623111]])\n",
        "\n",
        "# These are two level UseSum9 cascades\n",
        "def make_s3_questions():\n",
        "    return QuantaType_MATH_ADD, MATH_ADD_S3_TAG, make_questions( PLUS_INDEX,\n",
        "      [[ 555, 445],\n",
        "      [ 3340, 6661],\n",
        "      [ 8880, 1121],\n",
        "      [ 1120, 8881],\n",
        "      [ 123, 877],\n",
        "      [ 877, 123],\n",
        "      [ 321, 679],\n",
        "      [ 679, 321],\n",
        "      [ 1283, 78785]])\n",
        "\n",
        "\n",
        "# These are three level UseSum9 cascades\n",
        "def make_s4_questions():\n",
        "    return QuantaType_MATH_ADD, MATH_ADD_S4_TAG, make_questions( PLUS_INDEX,\n",
        "      [[ 5555, 4445],\n",
        "      [ 55550, 44451],\n",
        "      [ 3334, 6666],\n",
        "      [ 33340, 66661],\n",
        "      [ 8888, 1112],\n",
        "      [ 88880, 11121],\n",
        "      [ 1234, 8766],\n",
        "      [ 4321, 5679]])\n",
        "\n",
        "\n",
        "# These are four level UseSum9 cascades\n",
        "def make_s5_questions():\n",
        "    return QuantaType_MATH_ADD, MATH_ADD_S5_TAG, make_questions( PLUS_INDEX,\n",
        "      [[ 44445, 55555],\n",
        "      [ 33334, 66666],\n",
        "      [ 88888, 11112],\n",
        "      [ 12345, 87655],\n",
        "      [ 54321, 45679],\n",
        "      [ 45545, 54455],\n",
        "      [ 36634, 63366],\n",
        "      [ 81818, 18182],\n",
        "      [ 87345, 12655],\n",
        "      [ 55379, 44621]])\n",
        "\n",
        "\n",
        "# Make questions focus mainly on 1 digit at a time\n",
        "# (assuming that the 0 + 0 digit additions/subtractions are trivial bigrams)\n",
        "def make_sn_questions():\n",
        "    return QuantaType_MATH_ADD, \"S*\", make_questions( PLUS_INDEX,\n",
        "      [[ 1, 0],\n",
        "      [ 4, 3],\n",
        "      [ 5, 5],\n",
        "      [ 8, 1],\n",
        "      [ 40, 31],\n",
        "      [ 44, 46],\n",
        "      [ 400, 311],\n",
        "      [ 440, 461],\n",
        "      [ 800, 111],\n",
        "      [ 270, 471],\n",
        "      [ 600, 311],\n",
        "      [ 4000, 3111],\n",
        "      [ 4400, 4611],\n",
        "      [ 6000, 3111],\n",
        "      [ 7000, 4111],\n",
        "      [ 40000, 31111],\n",
        "      [ 44000, 45111],\n",
        "      [ 60000, 31111],\n",
        "      [ 70000, 41111],\n",
        "      [ 10000, 21111],\n",
        "      [ 15000, 25111],\n",
        "      [ 35000, 35111],\n",
        "      [ 45000, 85111],\n",
        "      [ 67000, 85111],\n",
        "      [ 99000, 76111],\n",
        "      [ 76000, 99111],\n",
        "      [ 670000, 851111],\n",
        "      [ 990000, 761111],\n",
        "      [ 760000, 991111],\n",
        "      [ 6700000, 8511111],\n",
        "      [ 9900000, 7611111],\n",
        "      [ 7600000, 9911111],\n",
        "      [ 67000000, 85111111],\n",
        "      [ 99000000, 76111111],\n",
        "      [ 76000000, 99111111]])\n",
        "\n",
        "\n",
        "# Make M0 questions - when no column generates a Borrow One. Answer is always positive (or zero).\n",
        "def make_m0_questions():\n",
        "    return QuantaType_MATH_SUB, MATH_SUB_S0_TAG, make_questions( MINUS_INDEX,\n",
        "      [[0, 0],\n",
        "      [6, 6],\n",
        "      [61, 60],\n",
        "      [611, 600],\n",
        "      [6111, 6000],\n",
        "      [61111, 60000],\n",
        "      [611111, 600000],\n",
        "      [6111111, 6000000],\n",
        "      [61111111, 60000000],\n",
        "      [66666, 12345],\n",
        "      [33333, 12321],\n",
        "      [45762, 34551],\n",
        "      [78901, 78901], # = +000000\n",
        "      [23123, 23123], # = +000000\n",
        "      [86, 15],\n",
        "      [4440, 1230],\n",
        "      [88746, 86544],\n",
        "      [27833, 25133],\n",
        "      [23533, 21133],\n",
        "      [32501, 1],\n",
        "      [31511, 1111],\n",
        "      [55555, 12323],\n",
        "      [45454, 22022],\n",
        "      [66643, 3341],\n",
        "      [66643, 30042],\n",
        "      [99999, 44012],\n",
        "      [61111, 30000],\n",
        "      [99111, 99111], # = +000000\n",
        "      [999991, 440120],\n",
        "      [611111, 300000],\n",
        "      [991111, 991111], # = +0000000\n",
        "      [9999911, 4401200],\n",
        "      [6111111, 3000000],\n",
        "      [9911111, 9911111], # = +00000000\n",
        "      [99999111, 44012000],\n",
        "      [61111111, 30000000],\n",
        "      [99111111, 99111111]]) # = +000000000\n",
        "\n",
        "# Make subtraction M1 questions with exactly one \"borrow 1\" instance. Answer is always positive.\n",
        "def make_m1_questions():\n",
        "    return QuantaType_MATH_SUB, MATH_SUB_S1_TAG, make_questions( MINUS_INDEX,\n",
        "      [[22222, 11113],\n",
        "      [ 22222, 11131],\n",
        "      [ 22222, 11311],\n",
        "      [ 22222, 13111],\n",
        "      [    14,     8],\n",
        "      [   141,    80],\n",
        "      [  1411,   800],\n",
        "      [ 14111,  8000],\n",
        "      [ 55514, 11108],\n",
        "      [ 55141, 11080],\n",
        "      [ 51411, 10800],\n",
        "      [ 140111,  8000],\n",
        "      [ 88888, 22229],\n",
        "      [ 77777, 22292],\n",
        "      [ 66666, 22922],\n",
        "      [ 888888, 222292],\n",
        "      [ 777777, 222922],\n",
        "      [ 666666, 229222],\n",
        "      [ 8888888, 2222922],\n",
        "      [ 7777777, 2229222],\n",
        "      [ 6666666, 2292222],\n",
        "      [ 88888888, 22229222],\n",
        "      [ 77777777, 22292222],\n",
        "      [ 66666666, 22922222]])\n",
        "\n",
        "# Make subtraction M2 questions containing BO and DZ. Answer is always positive (or zero).\n",
        "def make_m2_questions():\n",
        "    return QuantaType_MATH_SUB, MATH_SUB_S2_TAG, make_questions( MINUS_INDEX,\n",
        "      [[22212, 11113],\n",
        "      [ 22122, 11131],\n",
        "      [ 21222, 11311],\n",
        "      [   904,     8],\n",
        "      [  9041,    80],\n",
        "      [ 90411,   800],\n",
        "      [ 55514, 11118],\n",
        "      [ 55141, 11180],\n",
        "      [ 51411, 11800],\n",
        "      [ 88888, 22289],\n",
        "      [ 77777, 22792],\n",
        "      [ 66666, 26922],\n",
        "      [ 888888, 222892],\n",
        "      [ 777777, 227922],\n",
        "      [ 666666, 269222],\n",
        "      [ 8888888, 2228922],\n",
        "      [ 7777777, 2279222],\n",
        "      [ 6666666, 2692222],\n",
        "      [ 88888888, 22289222],\n",
        "      [ 77777777, 22792222],\n",
        "      [ 66666666, 26922222]])\n",
        "\n",
        "\n",
        "# Make subtraction M3,M4,... questions containing BO and multiple DZs. Answer is always positive (or zero).\n",
        "def make_m3_questions():\n",
        "    return QuantaType_MATH_SUB, MATH_SUB_S3_TAG, make_questions( MINUS_INDEX,\n",
        "      [[22112, 11113],\n",
        "      [ 21122, 11131],\n",
        "      [ 99004,     8],\n",
        "      [ 90041,    80],\n",
        "      [ 55114, 11118],\n",
        "      [ 51140, 11180],\n",
        "      [ 88888, 22889],\n",
        "      [ 87777, 27792],\n",
        "      [ 888888, 228892],\n",
        "      [ 877777, 277922],\n",
        "      [ 8888888, 2288922],\n",
        "      [ 7777777, 2779222],\n",
        "      [ 88888888, 22889222],\n",
        "      [ 77777777, 28892222]])\n",
        "\n",
        "\n",
        "# Make subtraction questions with negative answers\n",
        "def make_ng_questions():\n",
        "    return QuantaType_MATH_SUB, MATH_SUB_NG_TAG, make_questions( MINUS_INDEX,\n",
        "      [[0, 1],\n",
        "      [7, 9],\n",
        "      [12345, 33333],\n",
        "      [888, 11111],\n",
        "      [2362, 23123],\n",
        "      [15, 81],\n",
        "      [1111, 4440],\n",
        "      [24033, 25133],\n",
        "      [23533, 88133],\n",
        "      [5511, 12323],\n",
        "      [4511, 22209],\n",
        "      [ 88888, 88889],\n",
        "      [ 55555, 55556],\n",
        "      [ 88881, 88891],\n",
        "      [ 55551, 55561],\n",
        "      [ 88811, 88911],\n",
        "      [ 55511, 55611],\n",
        "      [ 88746, 89544],\n",
        "      [ 27833, 29133],\n",
        "      [ 23533, 23833],\n",
        "      [ 31511, 41111],\n",
        "      [ 55555, 62323],\n",
        "      [ 45454, 72022],\n",
        "      [ 66643, 73341],\n",
        "      [ 66643, 90042],\n",
        "      [ 99998, 99999],\n",
        "      [ 8, 12],\n",
        "      [ 41, 232],\n",
        "      [ 44, 523],\n",
        "      [ 234, 334],\n",
        "      [ 7777, 8434],\n",
        "      [ 88888, 92222],\n",
        "      [ 77777, 84340],\n",
        "      [ 888888, 922220],\n",
        "      [ 777777, 843400],\n",
        "      [ 8888888, 9222200],\n",
        "      [ 7777777, 8434000],\n",
        "      [ 88888888, 92222000],\n",
        "      [ 77777777, 84340000]])\n",
        "\n",
        "\n",
        "v0 = next(ds) # Could be Add, Sub or Mult\n",
        "v1 = next(ds) # Could be Add, Sub or Mult\n",
        "if cfg.perc_add() > 0 and cfg.perc_sub > 0 :\n",
        "  v0 = data_generator_core( PLUS_INDEX )\n",
        "  v1 = data_generator_core( MINUS_INDEX )\n",
        "\n",
        "\n",
        "# Returns ~1000 random and up to ~150 manually-chosen questions\n",
        "def make_varied_questions():\n",
        "  if cfg.perc_mult == 100 :\n",
        "    return torch.vstack((v0.cuda(), v1.cuda()))\n",
        "\n",
        "  _, _, s0 = make_s0_questions()\n",
        "  _, _, s1 = make_s1_questions()\n",
        "  _, _, s2 = make_s2_questions()\n",
        "  _, _, s3 = make_s3_questions()\n",
        "  _, _, s4 = make_s4_questions()\n",
        "  _, _, s5 = make_s5_questions()\n",
        "  _, _, s6 = make_sn_questions()\n",
        "\n",
        "  _, _, m0 = make_m0_questions()\n",
        "  _, _, m1 = make_m1_questions()\n",
        "  _, _, m2 = make_m2_questions()\n",
        "  _, _, m3 = make_m3_questions()\n",
        "  _, _, m4 = make_ng_questions()\n",
        "\n",
        "  if cfg.perc_add() == 100 :\n",
        "    return torch.vstack((v0.cuda(), s0.cuda(), s1.cuda(), s2.cuda(), s3.cuda(), s4.cuda(), v1.cuda()))\n",
        "\n",
        "  if cfg.perc_sub == 100 :\n",
        "    return torch.vstack((v0.cuda(), m0.cuda(), m1.cuda(), m2.cuda(), m3.cuda(), m4.cuda(), v1.cuda()))\n",
        "\n",
        "  return torch.vstack((v0.cuda(), s0.cuda(), m0.cuda(), s1.cuda(), m1.cuda(), s2.cuda(), m2.cuda(), s3.cuda(), m3.cuda(), s4.cuda(), m4.cuda(), s5.cuda(), s6.cuda(), v1.cuda()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyK7QeUjLLFm"
      },
      "source": [
        "# Part 7C: Set Up: Evaluate mathematical Complexity quanta e.g. Add.S2, Sub.M1\n",
        "\n",
        "Functions to evaluate the question \"mathematical complexity\" of questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xiOHRfGKW-W"
      },
      "outputs": [],
      "source": [
        "# Analyse and return the complexity quanta for the Addition (S0 to S4+) or Subtraction (M0 to NG) questions\n",
        "def get_question_complexity(question):\n",
        "  qlist = utils.to_numpy(question)\n",
        "  inputs = qlist[:2*cfg.n_digits+2]\n",
        "  operator = qlist[cfg.n_digits]\n",
        "\n",
        "  if operator == PLUS_INDEX:\n",
        "\n",
        "    # Locate the MC and MS digits (if any)\n",
        "    mc = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    ms = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if inputs[dn] + inputs[dn + cfg.n_digits + 1] == 9:\n",
        "        ms[cfg.n_digits-1-dn] = 1\n",
        "      if inputs[dn] + inputs[dn + cfg.n_digits +1] > 9:\n",
        "        mc[cfg.n_digits-1-dn] = 1\n",
        "\n",
        "    if torch.sum(mc) == 0:\n",
        "      return QuantaType_MATH_ADD, MATH_ADD_S0_TAG\n",
        "\n",
        "    if torch.sum(ms) == 0:\n",
        "      return QuantaType_MATH_ADD, MATH_ADD_S1_TAG\n",
        "\n",
        "    for dn in range(cfg.n_digits-4):\n",
        "      if mc[dn] == 1 and ms[dn+1] == 1 and ms[dn+2] == 1 and ms[dn+3] == 1 and ms[dn+4] == 1:\n",
        "        return QuantaType_MATH_ADD, MATH_ADD_S5_TAG # MC cascades 4 or more digits\n",
        "\n",
        "    for dn in range(cfg.n_digits-3):\n",
        "      if mc[dn] == 1 and ms[dn+1] == 1 and ms[dn+2] == 1 and ms[dn+3] == 1:\n",
        "        return QuantaType_MATH_ADD, MATH_ADD_S4_TAG # MC cascades 3 or more digits\n",
        "\n",
        "    for dn in range(cfg.n_digits-2):\n",
        "      if mc[dn] == 1 and ms[dn+1] == 1 and ms[dn+2] == 1:\n",
        "        return QuantaType_MATH_ADD, MATH_ADD_S3_TAG # MC cascades 2 or more digits\n",
        "\n",
        "    for dn in range(cfg.n_digits-1):\n",
        "      if mc[dn] == 1 and ms[dn+1] == 1:\n",
        "        return QuantaType_MATH_ADD, MATH_ADD_S2_TAG # Simple US 9\n",
        "\n",
        "    return QuantaType_MATH_ADD, MATH_ADD_S1_TAG\n",
        "\n",
        "\n",
        "  if operator == MINUS_INDEX:\n",
        "    a = tokens_to_unsigned_int( question, 0, cfg.n_digits )\n",
        "    b = tokens_to_unsigned_int( question, cfg.n_digits + 1, cfg.n_digits )\n",
        "    if a - b < 0:\n",
        "      return QuantaType_MATH_SUB, MATH_SUB_NG_TAG\n",
        "\n",
        "    # Locate the BO and MZ digits (if any)\n",
        "    bo = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    mz = torch.zeros(cfg.n_digits).to(torch.int64)\n",
        "    for dn in range(cfg.n_digits):\n",
        "      if inputs[dn] - inputs[dn + cfg.n_digits + 1] < 0:\n",
        "        bo[cfg.n_digits-1-dn] = 1\n",
        "      if inputs[dn] - inputs[dn + cfg.n_digits +1] == 0:\n",
        "        mz[cfg.n_digits-1-dn] = 1\n",
        "\n",
        "    # Evaluate BaseSub questions - when no column generates a Borrow One\n",
        "    if torch.sum(bo) == 0:\n",
        "      return QuantaType_MATH_SUB, MATH_SUB_S0_TAG\n",
        "\n",
        "    # Evaluate subtraction \"cascade multiple steps\" questions\n",
        "    for dn in range(cfg.n_digits-3):\n",
        "      if bo[dn] == 1 and mz[dn+1] == 1 and mz[dn+2] == 1 and mz[dn+3] == 1:\n",
        "        return QuantaType_MATH_SUB, \"M4+\" # BO cascades 3 or more digits\n",
        "\n",
        "    # Evaluate subtraction \"cascade multiple steps\" questions\n",
        "    for dn in range(cfg.n_digits-2):\n",
        "      if bo[dn] == 1 and mz[dn+1] == 1 and mz[dn+2] == 1:\n",
        "        return QuantaType_MATH_SUB, MATH_SUB_S3_TAG # BO cascades 2 or more digits\n",
        "\n",
        "    # Evaluate subtraction \"cascade 1\" questions\n",
        "    for dn in range(cfg.n_digits-1):\n",
        "      if bo[dn] == 1 and mz[dn+1] == 1:\n",
        "        return QuantaType_MATH_SUB, MATH_SUB_S2_TAG # BO cascades 1 digit\n",
        "\n",
        "    return QuantaType_MATH_SUB, MATH_SUB_S1_TAG\n",
        "\n",
        "\n",
        "  # Should never get here\n",
        "  print(\"get_question_complexity OP? exception\", question)\n",
        "  return QuantaType_MATH_VARIED, \"OP?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg1z2-YdkWHO"
      },
      "outputs": [],
      "source": [
        "def unit_test_quanta_core(make_questions):\n",
        "  correct_major_tag, correct_complexity, questions = make_questions()\n",
        "  num_questions = questions.shape[0]\n",
        "  print( correct_major_tag + \":\" + correct_complexity, \"#Questions=\", num_questions)\n",
        "\n",
        "  for i in range(num_questions):\n",
        "    major_tag, complexity = get_question_complexity(questions[i])\n",
        "    if major_tag != correct_major_tag or complexity != correct_complexity:\n",
        "      print( \"Complexity mismatch:\", correct_major_tag, major_tag, correct_complexity, complexity, questions[i])\n",
        "\n",
        "\n",
        "# Test that our \"sample questions by quanta\" and \"question quanta evaluation\" are aligned.\n",
        "# If this fails, either the sample questions or the evaluation is buggy.\n",
        "def unit_test_quanta():\n",
        "  unit_test_quanta_core(make_s0_questions)\n",
        "  unit_test_quanta_core(make_s1_questions)\n",
        "  unit_test_quanta_core(make_s2_questions)\n",
        "  unit_test_quanta_core(make_s3_questions)\n",
        "  unit_test_quanta_core(make_s4_questions)\n",
        "  unit_test_quanta_core(make_s5_questions)\n",
        "\n",
        "  unit_test_quanta_core(make_m0_questions)\n",
        "  unit_test_quanta_core(make_m1_questions)\n",
        "  unit_test_quanta_core(make_m2_questions)\n",
        "  unit_test_quanta_core(make_m3_questions)\n",
        "  unit_test_quanta_core(make_ng_questions)\n",
        "\n",
        "\n",
        "unit_test_quanta()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6FwJW0tv4Nf"
      },
      "source": [
        "# Part 8A: Set Up: Question prediction function\n",
        "\n",
        "Create sets of sample questions exercising different quanta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RHrsjKqKhR4"
      },
      "outputs": [],
      "source": [
        "# Build a test batch of random and manually-chosen questions\n",
        "varied_questions = make_varied_questions();\n",
        "\n",
        "\n",
        "# Run the sample batch, gather the cache\n",
        "cfg.main_model.reset_hooks()\n",
        "cfg.main_model.set_use_attn_result(True)\n",
        "sample_logits, sample_cache = cfg.main_model.run_with_cache(varied_questions.cuda())\n",
        "print(sample_cache) # Gives names of datasets in the cache\n",
        "sample_losses_raw, sample_max_prob_tokens = logits_to_tokens_loss(sample_logits, varied_questions.cuda())\n",
        "sample_loss_mean = utils.to_numpy(loss_fn(sample_losses_raw).mean())\n",
        "print(\"Sample Mean Loss\", sample_loss_mean) # Loss < 0.04 is good\n",
        "\n",
        "\n",
        "# attn.hook_z is the \"attention head output\" hook point name (at a specified layer)\n",
        "l_attn_hook_z_name = [utils.get_act_name('z', 0, 'a'),utils.get_act_name('z', 1, 'a'),utils.get_act_name('z', 2, 'a'),utils.get_act_name('z', 3, 'a')] # 'blocks.0.attn.hook_z' etc\n",
        "sample_attn_z_0 = sample_cache[l_attn_hook_z_name[0]]\n",
        "print(\"Sample\", l_attn_hook_z_name[0], sample_attn_z_0.shape) # gives [350, 22, 3, 170] = num_questions, cfg.n_ctx, n_heads, d_head\n",
        "mean_attn_z = torch.mean(sample_attn_z_0, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_attn_hook_z_name[0], mean_attn_z.shape) # gives [1, 22, 3, 170] = 1, cfg.n_ctx, n_heads, d_head\n",
        "\n",
        "\n",
        "# hook_resid_pre is the \"pre residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_pre_name = ['blocks.0.hook_resid_pre','blocks.1.hook_resid_pre','blocks.2.hook_resid_pre','blocks.3.hook_resid_pre']\n",
        "\n",
        "\n",
        "# hook_resid_post is the \"post residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_post_name = ['blocks.0.hook_resid_post','blocks.1.hook_resid_post','blocks.2.hook_resid_post','blocks.3.hook_resid_post']\n",
        "sample_resid_post_0 = sample_cache[l_hook_resid_post_name[0]]\n",
        "print(\"Sample\", l_hook_resid_post_name[0], sample_resid_post_0.shape) # gives [350, 22, 510] = num_questions, cfg.n_ctx, d_model\n",
        "mean_resid_post = torch.mean(sample_resid_post_0, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_hook_resid_post_name[0], mean_resid_post.shape) # gives [1, 22, 510] = 1, cfg.n_ctx, d_model\n",
        "\n",
        "\n",
        "# mlp.hook_post is the \"MLP layer\" hook point name (at a specified layer)\n",
        "l_mlp_hook_post_name = [utils.get_act_name('post', 0),utils.get_act_name('post', 1),utils.get_act_name('post', 2),utils.get_act_name('post', 3)] # 'blocks.0.mlp.hook_post' etc\n",
        "sample_mlp_hook_post_0 = sample_cache[l_mlp_hook_post_name[0]]\n",
        "print(\"Sample\", l_mlp_hook_post_name[0], sample_mlp_hook_post_0.shape) # gives [350, 22, 2040] = num_questions, cfg.n_ctx, cfg.d_mlp\n",
        "mean_mlp_hook_post = torch.mean(sample_mlp_hook_post_0, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_mlp_hook_post_name[0], mean_mlp_hook_post.shape) # gives [1, 22, 2040] = 1, cfg.n_ctx, cfg.d_mlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjhfLpSW9Jsq"
      },
      "outputs": [],
      "source": [
        "verbose = True\n",
        "\n",
        "\n",
        "class T_Config(NodeLocation):\n",
        "  num_questions : int\n",
        "  correct_answers : int\n",
        "  total_mean_loss : float\n",
        "  correct_list = [] # List of size num_questions showing which answers were correct.\n",
        "\n",
        "  sum_num_questions : int\n",
        "  sum_correct_answers : int\n",
        "\n",
        "  output = PrettyTable()\n",
        "\n",
        "  threshold : int\n",
        "\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(0, 0, True, 0)\n",
        "    self.reset()\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.num_questions = 0\n",
        "    self.correct_answers = 0\n",
        "    self.total_mean_loss = 0.0\n",
        "    self.sum_num_questions = 0\n",
        "    self.correct_list = []\n",
        "    self.sum_correct_answers = 0\n",
        "    self.output = PrettyTable()\n",
        "    self.output.field_names = [\"Complexity\", \"#Questions\", \"#Correct\", \"%Correct\", \"Mean loss\"]\n",
        "    self.threshold = 0.01\n",
        "\n",
        "\n",
        "  # Clear the question summary results\n",
        "  def clear_questions_results(self, title):\n",
        "\n",
        "    self.num_questions = 0\n",
        "    self.correct_answers = 0\n",
        "    self.total_mean_loss = 0\n",
        "    self.correct_list = []\n",
        "\n",
        "    if verbose:\n",
        "      print(title)\n",
        "\n",
        "\n",
        "  # Print the question summary results\n",
        "  def print_questions_results(self, prefix):\n",
        "    self.output.add_row([prefix, self.num_questions, str(self.correct_answers), 100*self.correct_answers/self.num_questions, self.total_mean_loss/self.num_questions])\n",
        "    self.sum_num_questions += self.num_questions\n",
        "    self.sum_correct_answers += self.correct_answers\n",
        "\n",
        "\n",
        "  # Print the overall summary results\n",
        "  def print_overall_results(self):\n",
        "    self.output.add_row([\"OVERALL\", self.sum_num_questions, self.sum_correct_answers, \"\", \"\"])\n",
        "    print(self.output.get_formatted_string(out_format=cfg.table_out_format))\n",
        "\n",
        "\n",
        "  # Evidence (not proof) the model is accurate\n",
        "  def might_be_fully_accurate(self):\n",
        "    return self.sum_num_questions == self.sum_correct_answers\n",
        "\n",
        "\n",
        "tcfg = T_Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E56siA_QKe0W"
      },
      "outputs": [],
      "source": [
        "# Ask model to predict answer for each question & collect results\n",
        "def do_questions(questions, show_failures = False):\n",
        "\n",
        "  tcfg.num_questions = questions.shape[0]\n",
        "  tcfg.correct_list = [True] * tcfg.num_questions\n",
        "\n",
        "  # Run with no hook\n",
        "  all_logits = cfg.main_model(questions.cuda())\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "  for question_num in range(tcfg.num_questions):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    losses = loss_fn(all_losses_raw[question_num])\n",
        "    mean_loss = utils.to_numpy(losses.mean())\n",
        "    tcfg.total_mean_loss += mean_loss\n",
        "\n",
        "    model_answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "    model_answer_num = int(model_answer_str)\n",
        "\n",
        "    a = tokens_to_answer(q)\n",
        "\n",
        "    correct = (model_answer_num == a)\n",
        "    tcfg.correct_list[question_num] = correct\n",
        "\n",
        "    if correct :\n",
        "      tcfg.correct_answers += 1\n",
        "\n",
        "    if verbose or (show_failures and not correct):\n",
        "      print(tokens_to_string(q), \"ModelAnswer:\", model_answer_str, \"Loss:\", mean_loss )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN3mEnSRF0DP"
      },
      "outputs": [],
      "source": [
        "def print_question_results_core( title, questions, show_failures = False):\n",
        "  tcfg.clear_questions_results(title)\n",
        "  do_questions(questions, show_failures)\n",
        "  tcfg.print_questions_results(title)\n",
        "\n",
        "\n",
        "def print_question_results( make_questions, show_failures = False):\n",
        "  major_tag, quanta_case, questions = make_questions()\n",
        "  title = major_tag + \".\" + quanta_case\n",
        "  print_question_results_core( title, questions, show_failures)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lag8C3d_KkeQ"
      },
      "source": [
        "# Part 8B: Results: Prediction success by Complexity quanta\n",
        "\n",
        "This section runs hand-curated test cases to indicate which complexity quanta the model can (probably) handle.\n",
        "\n",
        "Not proof - our test cases might be inadequate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8z6RdolRKnnR"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "if cfg.perc_add() > 0:\n",
        "  tcfg.reset()\n",
        "  print_question_results(make_s0_questions)\n",
        "  print_question_results(make_s1_questions)\n",
        "  print_question_results(make_s2_questions)\n",
        "  print_question_results(make_s3_questions)\n",
        "  print_question_results(make_s4_questions)\n",
        "  print_question_results(make_s5_questions)\n",
        "  print_question_results(make_sn_questions)\n",
        "  tcfg.print_overall_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW2SNwxJ-3Kn"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "if cfg.perc_sub > 0:\n",
        "  tcfg.reset()\n",
        "  print_question_results(make_m0_questions)\n",
        "  print_question_results(make_m1_questions)\n",
        "  print_question_results(make_m2_questions)\n",
        "  print_question_results(make_m3_questions)\n",
        "  print_question_results(make_ng_questions)\n",
        "  tcfg.print_overall_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpNvthy48TU0"
      },
      "outputs": [],
      "source": [
        "# Varied questions includes 2 random batches of questions. Show any questions that we can't calculate correctly.\n",
        "tcfg.reset()\n",
        "print_question_results_core( QuantaType_MATH_VARIED, varied_questions, True)\n",
        "tcfg.print_overall_results()\n",
        "\n",
        "model_might_be_fully_accurate = tcfg.might_be_fully_accurate()\n",
        "if model_might_be_fully_accurate:\n",
        "  # This is evidence not proof because there may be very rare edge cases (say 1 in ten million) that did not appear in the test questions.\n",
        "  # Even if you believe you know all the edge cases, and have enriched the training data to contain them, you may not have thought of all edge cases, so this is not proof.\n",
        "  print(\"Model got all test questions correct. This is a pre-requisite for the model to be fully accurate, but this is NOT proof it is fully accurate.\")\n",
        "else:\n",
        "  # Remove the questions that the model failed to answer as they turn up in every cell quanta maps\n",
        "  org_size = varied_questions.shape[0]\n",
        "  varied_questions = varied_questions[torch.tensor(tcfg.correct_list)]\n",
        "  new_size = varied_questions.shape[0]\n",
        "\n",
        "  print()\n",
        "  print(\"WARNING: Model is not fully accurate as it got\", org_size - new_size, \"questions wrong.\")\n",
        "  print(\"RESOLUTION: Understand these failures. Enrich the training data to provide more examples. Retrain the model.\")\n",
        "  print(\"INTERIM: Have reduced 'varied_questions' size from\", org_size, \"to\", new_size, \"so can continue.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXBYdxj-jLZc"
      },
      "source": [
        "# Part 12A: Set Up: Predict Questions and Evaluate Quanta\n",
        "\n",
        "Get model to predict given question answers, with ablation hook(s), and categorise how many questions fail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7LdYzkSvZ4c"
      },
      "outputs": [],
      "source": [
        "# Ask the model to predict the question answers (with the hooks either reading data, doing intervetion ablations, or doing nothing )\n",
        "def predict_questions_core(questions, the_hooks):\n",
        "\n",
        "  cfg.main_model.reset_hooks()\n",
        "  cfg.main_model.set_use_attn_result(True)\n",
        "\n",
        "  all_logits = cfg.main_model.run_with_hooks(questions.cuda(), return_type=\"logits\", fwd_hooks=the_hooks)\n",
        "  all_losses_raw, all_max_prob_tokens = logits_to_tokens_loss(all_logits, questions.cuda())\n",
        "\n",
        "  return all_losses_raw, all_max_prob_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03wT2QJL34aP"
      },
      "outputs": [],
      "source": [
        "def c_predict_questions(questions, the_hooks):\n",
        "\n",
        "  all_losses_raw, all_max_prob_tokens = predict_questions_core(questions, the_hooks)\n",
        "\n",
        "  num_fails = 0\n",
        "  for question_num in range(questions.shape[0]):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    the_loss_mean = utils.to_numpy(loss_fn(all_losses_raw[question_num]).mean())\n",
        "\n",
        "    # Only show the question if the loss exceeds the threshold (because of the ablated token position)\n",
        "    if the_loss_mean > tcfg.threshold:\n",
        "      answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "\n",
        "      # Only count the question if the model got the question wrong\n",
        "      impact_str = get_question_answer_impact( q, answer_str )\n",
        "      if 'A' in impact_str:\n",
        "        num_fails += 1\n",
        "\n",
        "        if verbose :\n",
        "          print(tokens_to_string(q), \"Q: ModelAnswer:\", answer_str, \"Impact:\", impact_str, \"Loss:\", the_loss_mean )\n",
        "\n",
        "  return num_fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGL57MRBLdUh"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "\n",
        "\n",
        "def c_set_resid_post_hook(value, hook):\n",
        "  #print( \"In hook\", l_hook_resid_post_name[tcfg.layer], tcfg.ablate, tcfg.position, value.shape) # Get [64, 22, 510] = cfg.batch_size, num_tokens, d_model\n",
        "\n",
        "  # Copy the mean resid post values in position N to all the batch questions\n",
        "  value[:,tcfg.position,:] = mean_resid_post[0,tcfg.position,:].clone()\n",
        "\n",
        "\n",
        "num_failures_list = []\n",
        "num_questions = 0\n",
        "if cfg.n_digits >= 5 :\n",
        "  c_fwd_hooks = [(l_hook_resid_post_name[0], c_set_resid_post_hook),(l_hook_resid_post_name[1], c_set_resid_post_hook),(l_hook_resid_post_name[2], c_set_resid_post_hook),(l_hook_resid_post_name[3], c_set_resid_post_hook)][:cfg.n_layers]\n",
        "\n",
        "  num_questions = varied_questions.shape[0]\n",
        "\n",
        "  for tcfg.position in range(cfg.n_ctx()):\n",
        "    num_fails = c_predict_questions(varied_questions, c_fwd_hooks)\n",
        "\n",
        "    num_failures_list += [num_fails] if num_fails > 0 else \".\"\n",
        "\n",
        "    if num_fails > 0:\n",
        "      assert tcfg.position < cfg.n_ctx()\n",
        "      useful_info.add_useful_position(tcfg.position)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PjaQvhhayUL"
      },
      "source": [
        "# Part 9 : Results: Can the model do 1 million questions without error?\n",
        "\n",
        "If the model passes this test, this is evidence (not proof) that the model is fully accurate. There may be very rare edge cases (say 1 in ten million) that did not appear in the test questions. Even if you believe you know all the edge cases, and have enriched the training data to contain them, you may not have thought of all edge cases, so this is not proof.\n",
        "\n",
        "If the model fails this test:\n",
        "- Add a few of the failures into the \"test questions\" in part 6C\n",
        "- Understand the \"use case(s)\" driving these failures\n",
        "- Alter the Training CoLab data_generator_core to enrich the training data with examples if these use case(s) and retrain the model.  \n",
        "\n",
        "Takes ~25 mins to run (successfully) for ins_mix_d6_l3_h4_t40K_seed372001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlLOZMVkeqvm"
      },
      "outputs": [],
      "source": [
        "def null_hook(value, hook):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMYZTv5HUp5F"
      },
      "outputs": [],
      "source": [
        "def one_million_questions_core():\n",
        "  global verbose\n",
        "  global ds\n",
        "\n",
        "  verbose = True\n",
        "\n",
        "  cfg.analysis_seed = 345621 # Randomly chosen\n",
        "  ds = data_generator() # Re-initialise the data generator\n",
        "\n",
        "  the_successes = 0\n",
        "  the_fails = 0\n",
        "\n",
        "  num_batches = 1000000//cfg.batch_size\n",
        "  for epoch in range(num_batches):\n",
        "      tokens = next(ds)\n",
        "\n",
        "      the_hook = [(l_attn_hook_z_name[0], null_hook)]\n",
        "      the_fails = c_predict_questions(tokens, the_hook)\n",
        "\n",
        "      if the_fails> 0:\n",
        "        break\n",
        "\n",
        "      the_successes = the_successes + cfg.batch_size\n",
        "\n",
        "      if epoch % 100 == 0:\n",
        "          print(\"Batch\", epoch, \"of\", num_batches, \"#Successes=\", the_successes)\n",
        "\n",
        "  print(\"successes\", the_successes, \"num_fails\", the_fails)\n",
        "  if the_fails > 0:\n",
        "    \"WARNING: Model is not fully accurate. It failed the 1M Q test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znsauYqjaxok"
      },
      "outputs": [],
      "source": [
        "def one_million_questions():\n",
        "  print_config()\n",
        "  print()\n",
        "\n",
        "  if model_might_be_fully_accurate:\n",
        "\n",
        "    # Commented out as it takes > 9 minutes to run\n",
        "    if cfg.perc_add() > 0 and cfg.perc_sub > 0:\n",
        "      print(\"Subtraction:\")\n",
        "      cfg.perc_sub = 100\n",
        "      one_million_questions_core()\n",
        "      print()\n",
        "      print(\"Addition:\")\n",
        "      cfg.perc_sub = 0\n",
        "      one_million_questions_core()\n",
        "\n",
        "    else:\n",
        "      # Predict 1M (sub, add or mult) questions\n",
        "      one_million_questions_core()\n",
        "\n",
        "  else:\n",
        "    print(\"WARNING: Model is not fully accurate. It failed some test questions\")\n",
        "\n",
        "\n",
        "# Takes ~25 minutes to run\n",
        "# one_million_questions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmsGWUbILYin"
      },
      "source": [
        "# Part 12B: Results: Ablate ALL Heads in EACH token position. What is the impact?\n",
        "\n",
        "Here we ablate all heads in each token position (overriding the model memory aka residual stream) and see if loss increases. If loss increases the token position is used by the algorithm. Unused token positions can be excluded from further analysis. Use \"C_\" prefix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mIY_13gOiqn"
      },
      "outputs": [],
      "source": [
        "def save_plt_to_file( full_title ):\n",
        "  if cfg.graph_file_suffix > \"\":\n",
        "    filename = file_prefix() + full_title.replace(\" \", \"\").replace(\",\", \"\").replace(\":\", \"\").replace(\"-\", \"\") + '.' + cfg.graph_file_suffix\n",
        "    plt.savefig(filename, bbox_inches='tight', pad_inches=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpRp5YMmLe1y"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print()\n",
        "print(\"Number of failures when ALL Heads in EACH token position are ablated\")\n",
        "print(\"num_questions=\", num_questions, \"min_useful_position=\", useful_info.min_useful_position(), \"max_useful_position=\", useful_info.max_useful_position() )\n",
        "print()\n",
        "\n",
        "# Token positions names P1 .... P20\n",
        "columns = [\"Posn\"]\n",
        "for i in range(cfg.n_ctx()):\n",
        "  columns += [position_name(i)]\n",
        "\n",
        "rows = [\"Posn\", \"# fails\"]\n",
        "data = [\n",
        "    [\"Posn\"] + useful_info.token_position_meanings,\n",
        "    [\"# fails\"] + num_failures_list\n",
        "]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,1))\n",
        "ax.axis('tight')\n",
        "ax.axis('off')\n",
        "\n",
        "table = ax.table(cellText=data, colLabels=columns, loc='center', cellLoc='center')\n",
        "table.auto_set_font_size(False)\n",
        "table.set_fontsize(10)  # Set the font size here\n",
        "table.scale(1, 1.5)  # The first parameter scales column widths, the second scales row heights\n",
        "\n",
        "save_plt_to_file(\"Failures When Position Ablated\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904WBkTOLg_5"
      },
      "source": [
        "# Part 14: Setup: Analysis of quanta per node\n",
        "\n",
        "Evaluate quanta at node (not position) resolution. Uses \"u_\" prefix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTaSo-UzLlZ_"
      },
      "outputs": [],
      "source": [
        "def u_add_node_tag( the_location, major_tag, minor_tag ):\n",
        "  assert the_location.position >= 0\n",
        "  assert the_location.layer >= 0\n",
        "  assert the_location.num >= 0\n",
        "  assert the_location.position < cfg.n_ctx()\n",
        "  assert the_location.layer < cfg.n_layers\n",
        "  if the_location.is_head:\n",
        "    assert the_location.num < cfg.n_heads\n",
        "  else:\n",
        "    assert the_location.num < cfg.mlp_slices()\n",
        "\n",
        "  useful_info.add_node_tag( the_location, major_tag, minor_tag )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkRnSVQywfkr"
      },
      "outputs": [],
      "source": [
        "# Convert \"A1231231278321\" to \"12378\" or \"87321\"\n",
        "def sort_unique_digits(raw_input_string, do_reverse):\n",
        "  digit_string = ''.join(filter(str.isdigit, raw_input_string))\n",
        "\n",
        "  seen = set()\n",
        "  unique_digits = \"\"\n",
        "  for char in digit_string:\n",
        "      if char not in seen:\n",
        "          seen.add(char)\n",
        "          unique_digits += char\n",
        "\n",
        "  return ''.join(sorted(unique_digits, reverse=do_reverse))\n",
        "\n",
        "\n",
        "# Unit test\n",
        "assert sort_unique_digits(\"A1231231278321\", False) == \"12378\"\n",
        "assert sort_unique_digits(\"A1231231278321\", True) == \"87321\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZG-kUBMph9D"
      },
      "outputs": [],
      "source": [
        "def u_predict_questions(questions, the_hooks):\n",
        "\n",
        "  all_losses_raw, all_max_prob_tokens = predict_questions_core(questions, the_hooks)\n",
        "\n",
        "  num_fails = 0\n",
        "  impact_fails = \"\"\n",
        "  add_complexity_fails = \"\"\n",
        "  sub_complexity_fails = \"\"\n",
        "\n",
        "  for question_num in range(questions.shape[0]):\n",
        "    q = questions[question_num]\n",
        "\n",
        "    the_loss_mean = utils.to_numpy(loss_fn(all_losses_raw[question_num]).mean())\n",
        "\n",
        "    # Only show the question if the loss exceeds the threshold (because of the ablated token position)\n",
        "    if the_loss_mean > tcfg.threshold:\n",
        "      answer_str = tokens_to_string(all_max_prob_tokens[question_num])\n",
        "\n",
        "      impact_str = get_question_answer_impact( q, answer_str )\n",
        "      # Only count the question if the model got the question wrong\n",
        "      if 'A' in impact_str:\n",
        "        num_fails += 1\n",
        "\n",
        "        impact_fails += impact_str\n",
        "\n",
        "        major_tag, minor_tag = get_question_complexity(q)\n",
        "        if major_tag == QuantaType_MATH_ADD:\n",
        "          add_complexity_fails += minor_tag\n",
        "        elif major_tag == QuantaType_MATH_SUB:\n",
        "          sub_complexity_fails += minor_tag\n",
        "\n",
        "        if verbose :\n",
        "          print(tokens_to_string(q), \"U: ModelAnswer:\", answer_str, \"Complexity:\", major_tag, \"Impact:\", impact_str, \"Loss:\", the_loss_mean )\n",
        "\n",
        "\n",
        "  if num_fails > 0:\n",
        "\n",
        "    # Add percentage failure quanta\n",
        "    perc = int( 100.0 * num_fails / len(questions))\n",
        "    u_add_node_tag( tcfg, QuantaType.FAIL, str(perc) )\n",
        "\n",
        "    # Add summary of all answer digit impact quanta failures\n",
        "    u_add_node_tag( tcfg, QuantaType.IMPACT, \"A\" + sort_unique_digits(impact_fails, True) )\n",
        "\n",
        "    # Add summary of all addition question complexity quanta failures\n",
        "    if add_complexity_fails != \"\":\n",
        "      u_add_node_tag( tcfg, QuantaType_MATH_ADD, \"S\" + sort_unique_digits(add_complexity_fails, False) )\n",
        "\n",
        "    # Add summary of all subtraction question complexity quanta failures\n",
        "    if sub_complexity_fails != \"\":\n",
        "      sub_complexity_fails = sort_unique_digits(sub_complexity_fails, False)\n",
        "      if sub_complexity_fails == \"\":\n",
        "        sub_complexity_fails = MATH_SUB_NG_TAG\n",
        "      else:\n",
        "        sub_complexity_fails = \"M\" + sub_complexity_fails\n",
        "      u_add_node_tag( tcfg, QuantaType_MATH_SUB, sub_complexity_fails )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOxNc9SAMGRH"
      },
      "outputs": [],
      "source": [
        "def u_mlp_hook_post(value, hook):\n",
        "  # print( \"In u_mlp_hook_post\", value.shape) # Get [1099, 22, 2040] = num_questions, cfg.n_ctx, cfg.d_mlp (# neurons)\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in the MLP layer\n",
        "  value[:,tcfg.position,:] =  mean_mlp_hook_post[:,tcfg.position,:].clone()\n",
        "  #PQR When we do slices the MLP never fails?? Why??\n",
        "  #slice_size = cfg.d_mlp // cfg.mlp_slices()\n",
        "  #start_index = tcfg.num * slice_size\n",
        "  #end_index = start_index + slice_size\n",
        "  #print (\"PQR\", cfg.mlp_slices(), slice_size, start_index, end_index)\n",
        "  #value[:,tcfg.position,start_index:end_index] =  mean_mlp_hook_post[:,tcfg.position,start_index:end_index].clone()\n",
        "\n",
        "\n",
        "# Ablating the MLP in each layer in each position and seeing if the loss increases shows which layer+MLP are used by the algorithm.\n",
        "def u_mlp_perform_all(questions):\n",
        "  tcfg.is_head = False\n",
        "  for tcfg.position in useful_info.positions:\n",
        "    for tcfg.layer in range(cfg.n_layers):\n",
        "      for tcfg.num in range(cfg.mlp_slices()):\n",
        "        the_hook = [(l_mlp_hook_post_name[tcfg.layer], u_mlp_hook_post)]\n",
        "        u_predict_questions(questions, the_hook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C06ZYHaN3zkp"
      },
      "outputs": [],
      "source": [
        "def u_mlp_hook_post(value, hook):\n",
        "  # print( \"In u_mlp_hook_post\", value.shape) # Get [1099, 22, 2040] = num_questions, cfg.n_ctx, cfg.d_mlp (# neurons)\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in the MLP layer\n",
        "  value[:,tcfg.position,:] =  mean_mlp_hook_post[:,tcfg.position,:].clone()\n",
        "  #PQR When we do slices the MLP never fails?? Why??\n",
        "  #slice_size = cfg.d_mlp // cfg.mlp_slices()\n",
        "  #start_index = tcfg.num * slice_size\n",
        "  #end_index = start_index + slice_size\n",
        "  #print (\"PQR\", cfg.mlp_slices(), slice_size, start_index, end_index)\n",
        "  #value[:,tcfg.position,start_index:end_index] =  mean_mlp_hook_post[:,tcfg.position,start_index:end_index].clone()\n",
        "\n",
        "\n",
        "# Ablating the MLP in each layer in each position and seeing if the loss increases shows which layer+MLP are used by the algorithm.\n",
        "def u_mlp_perform_all(questions):\n",
        "  tcfg.is_head = False\n",
        "  for tcfg.position in useful_info.positions:\n",
        "    for tcfg.layer in range(cfg.n_layers):\n",
        "      for tcfg.num in range(cfg.mlp_slices()):\n",
        "        the_hook = [(l_mlp_hook_post_name[tcfg.layer], u_mlp_hook_post)]\n",
        "        u_predict_questions(questions, the_hook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxc75cZ03yVm"
      },
      "outputs": [],
      "source": [
        "def u_mlp_hook_post(value, hook):\n",
        "  # print( \"In u_mlp_hook_post\", value.shape) # Get [1099, 22, 2040] = num_questions, cfg.n_ctx, cfg.d_mlp (# neurons)\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in the MLP layer\n",
        "  value[:,tcfg.position,:] =  mean_mlp_hook_post[:,tcfg.position,:].clone()\n",
        "  #PQR When we do slices the MLP never fails?? Why??\n",
        "  #slice_size = cfg.d_mlp // cfg.mlp_slices()\n",
        "  #start_index = tcfg.num * slice_size\n",
        "  #end_index = start_index + slice_size\n",
        "  #print (\"PQR\", cfg.mlp_slices(), slice_size, start_index, end_index)\n",
        "  #value[:,tcfg.position,start_index:end_index] =  mean_mlp_hook_post[:,tcfg.position,start_index:end_index].clone()\n",
        "\n",
        "\n",
        "# Ablating the MLP in each layer in each position and seeing if the loss increases shows which layer+MLP are used by the algorithm.\n",
        "def u_mlp_perform_all(questions):\n",
        "  tcfg.is_head = False\n",
        "  for tcfg.position in useful_info.positions:\n",
        "    for tcfg.layer in range(cfg.n_layers):\n",
        "      for tcfg.num in range(cfg.mlp_slices()):\n",
        "        the_hook = [(l_mlp_hook_post_name[tcfg.layer], u_mlp_hook_post)]\n",
        "        u_predict_questions(questions, the_hook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2EnisO6MMGQ"
      },
      "outputs": [],
      "source": [
        "def u_head_attn_hook_z(value, hook):\n",
        "  # print( \"In u_head_attn_hook_z\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "\n",
        "  # Mean ablate. Copy the mean resid post values in position N to all the batch questions\n",
        "  value[:,tcfg.position,tcfg.num,:] = mean_attn_z[:,tcfg.position,tcfg.num,:].clone()\n",
        "\n",
        "\n",
        "# Ablating each head in each layer in each position and seeing if the loss increases shows which position+layer+head are used by the algorithm.\n",
        "def u_head_perform_all(questions):\n",
        "  tcfg.is_head = True\n",
        "  for tcfg.position in useful_info.positions:\n",
        "    for tcfg.layer in range(cfg.n_layers):\n",
        "      for tcfg.num in range(cfg.n_heads):\n",
        "        the_hook = [(l_attn_hook_z_name[tcfg.layer], u_head_attn_hook_z)]\n",
        "        u_predict_questions(questions, the_hook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh3f8Jiahdvq"
      },
      "outputs": [],
      "source": [
        "def h_null_attn_z_hook(value, hook):\n",
        "  global verbose\n",
        "\n",
        "  #print(\"In h_null_attn_z_hook\", value.shape)  # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "\n",
        "\n",
        "def u_calculate_attention_tags(questions):\n",
        "  useful_info.reset_node_tags(QuantaType.ATTENTION)\n",
        "\n",
        "  logits, cache = cfg.main_model.run_with_cache(questions)\n",
        "\n",
        "  all_attention_weights = []\n",
        "  for layer in range(cfg.n_layers):\n",
        "    attention_weights = cache[\"pattern\", layer, \"attn\"]\n",
        "    #print(attention_weights.shape) # 512, 4, 22, 22 = cfg.batch_size, cfg.n_heads, cfg.n_ctx, cfg.n_ctx\n",
        "\n",
        "    average_attention_weights = attention_weights.mean(dim=0)\n",
        "    #print(average_attention_weights.shape) # 4, 22, 22 = cfg.n_heads, cfg.n_ctx, cfg.n_ctx\n",
        "\n",
        "    all_attention_weights += [average_attention_weights]\n",
        "\n",
        "\n",
        "  for node in useful_info.nodes:\n",
        "    if node.is_head:\n",
        "\n",
        "      # Get attention weights for this token in this head\n",
        "      layer_weights = all_attention_weights[node.layer]\n",
        "      weights = layer_weights[node.num, node.position, :]\n",
        "\n",
        "      top_tokens = torch.topk(weights, 4)\n",
        "      total_attention = weights.sum()\n",
        "      attention_percentage = top_tokens.values / total_attention * 100\n",
        "\n",
        "      # Add up to 4 tags with percs per head\n",
        "      for idx, token_idx in enumerate(top_tokens.indices):\n",
        "        perc = attention_percentage[idx]\n",
        "        if perc >= 1.0:\n",
        "          u_add_node_tag( node, QuantaType.ATTENTION, f\"P{token_idx}={perc:.0f}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as9ot9RMMTAi"
      },
      "outputs": [],
      "source": [
        "verbose = False\n",
        "useful_info.nodes = []\n",
        "u_mlp_perform_all(varied_questions)\n",
        "u_head_perform_all(varied_questions)\n",
        "u_calculate_attention_tags(varied_questions)\n",
        "useful_info.sort_nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BmQHiLALp-3"
      },
      "source": [
        " # Part 15A: Set up: Show and save Quanta map\n",
        "\n",
        " Using the UsefulNodes and filtering their tags, show a 2D map of the nodes and the tag minor versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emcB0_CpYTaJ"
      },
      "outputs": [],
      "source": [
        "def show_quanta_map( title, custom_cmap, shades, major_tag, minor_tag, get_node_details, base_fontsize = 10, max_width = 10):\n",
        "\n",
        "  print_config()\n",
        "  print()\n",
        "\n",
        "  ax1, quanta_results = calc_quanta_map(custom_cmap, shades, major_tag, minor_tag, get_node_details, base_fontsize, max_width)\n",
        "\n",
        "  if cfg.graph_file_suffix > \"\":\n",
        "    print(\"Saving quanta map:\", title)\n",
        "    save_plt_to_file(title)\n",
        "  else:\n",
        "    ax1.set_title(file_prefix() + ' ' + title + ' ({} nodes)'.format(len(quanta_results)))\n",
        "\n",
        "  # Show plot\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkyhHRoMOSw"
      },
      "source": [
        "# Part 16A: Results: Show failure percentage quanta map\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated.\n",
        "\n",
        "A cell containing \"< 1\" may add some risk to the accuracy of the overall analysis process. Check to see if this represents a new use case. Improve the test data set to contain more instances of this (new or existing) use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ28dx5YLs0P"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Failure Frequency Per Node\", plt.cm.winter, 10, QuantaType.FAIL, \"\", get_quanta_fail_perc, 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifmtnLoTCN5"
      },
      "source": [
        "# Part 16B - Show answer impact quanta map\n",
        "\n",
        "Show the purpose of each useful cell by impact on the answer digits A0 to A5.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K9PyCKYTUzX"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Answer Impact Per Node\", plt.cm.winter, cfg.n_digits+2, QuantaType.IMPACT, \"\", get_quanta_impact, 9, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avCfaCT1Puhz"
      },
      "source": [
        "# Part 16C: Result: Show attention quanta map\n",
        "\n",
        "Show attention quanta of useful heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTGoEWHgvFH6"
      },
      "outputs": [],
      "source": [
        "# Only maps attention heads, not MLP layers\n",
        "show_quanta_map( \"Attention Per Head\", plt.cm.winter, 10, QuantaType.ATTENTION, \"\", get_quanta_attention, 10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7-99ZxDOrbF"
      },
      "source": [
        "# Part 16C - Show question complexity (S*) quanta map\n",
        "\n",
        "Show the \"minimum\" addition purpose of each useful cell by S0 to S5 quanta.\n",
        "Show the \"minimum\" subtraction purpose of each useful cell by M0 to M5 quanta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tAJl0eYO96W"
      },
      "outputs": [],
      "source": [
        "def get_quanta_min_complexity(node, major_tag, minor_tag, shades):\n",
        "  color_index = 0\n",
        "  cell_text = node.min_tag_suffix( major_tag, minor_tag )\n",
        "  if cell_text != \"\" :\n",
        "    cell_text = cell_text[0:2]\n",
        "    color_index = int(cell_text[1]) if len(cell_text) > 1 and cell_text[1].isdigit() else shades-1\n",
        "\n",
        "  return cell_text, color_index\n",
        "\n",
        "\n",
        "def show_quanta_min_tags( title, major_tag, minor_tag, shades):\n",
        "  show_quanta_map( title, create_custom_colormap(), shades, major_tag, minor_tag, get_quanta_min_complexity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyoErRoCA-pz"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  show_quanta_min_tags( \"Addition Min-Complexity Per Node\", QuantaType_MATH_ADD, \"\", 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMZzbjxUBQGE"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  show_quanta_min_tags( \"Subtraction Min-Complexity Per Node\", QuantaType_MATH_SUB, \"\", 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x48x45-RInZb"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  show_quanta_min_tags( \"Neg-Answer Sub Min-Complexity Per Node\", QuantaType_MATH_SUB, MATH_SUB_NG_TAG, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHSY3blNMe7I"
      },
      "source": [
        "#Part 19A: Set Up: Calc and graph PCA decomposition.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCiBsiQAMhS_"
      },
      "outputs": [],
      "source": [
        "tn_questions = 100\n",
        "\n",
        "\n",
        "def make_t_questions(test_digit, test_case, operation):\n",
        "    limit = 10 ** test_digit\n",
        "    questions = []\n",
        "    for i in range(tn_questions):\n",
        "      x_noise = 0\n",
        "      y_noise = 0\n",
        "\n",
        "      if operation == PLUS_INDEX:\n",
        "        if test_case == 8:\n",
        "          # These are n_digit addition questions where x and y sum is between 0 to 8\n",
        "          x = random.randint(0, 8)\n",
        "          y = random.randint(0, 8-x)\n",
        "        if test_case == 9:\n",
        "          # These are n_digit addition questions where x and y sum is 9\n",
        "          x = random.randint(0, 9)\n",
        "          y = 9 - x\n",
        "        if test_case == 10:\n",
        "          # These are n_digit addition questions where x and y sum is between 10 to 18\n",
        "          x = random.randint(1, 9)\n",
        "          y = random.randint(10-x, 9)\n",
        "\n",
        "        # Randomise the lower digits - ensuring that x_noise + y_noise dont cause a MakeCarry\n",
        "        x_noise = random.randint(0, limit-1)\n",
        "        y_noise = random.randint(0, limit-1 - x_noise)\n",
        "\n",
        "\n",
        "      if operation == MINUS_INDEX:\n",
        "        if test_case == 8:\n",
        "          # These are n_digit subtraction questions where x - y < 0\n",
        "          x = random.randint(0, 8)\n",
        "          y = random.randint(x+1, 9)\n",
        "        if test_case == 9:\n",
        "          # These are n_digit subtraction questions where x - y is 0\n",
        "          x = random.randint(0, 9)\n",
        "          y = x\n",
        "        if test_case == 10:\n",
        "          # These are n_digit subtraction questions where x - y > 0\n",
        "          x = random.randint(1, 9)\n",
        "          y = random.randint(0, x-1)\n",
        "\n",
        "        # Randomise the lower digits - ensuring that x_noise + y_noise dont cause a BorrowOne\n",
        "        x_noise = random.randint(0, limit-1)\n",
        "        y_noise = random.randint(0, x_noise)\n",
        "\n",
        "\n",
        "      x = x * limit + x_noise\n",
        "      y = y * limit + y_noise\n",
        "      questions.append([x, y])\n",
        "\n",
        "    return make_questions(operation, questions)\n",
        "\n",
        "\n",
        "\n",
        "def make_tricase_questions(test_digit, operation):\n",
        "  q1 = make_t_questions(test_digit, 8, operation)\n",
        "  q2 = make_t_questions(test_digit, 9, operation)\n",
        "  q3 = make_t_questions(test_digit, 10, operation)\n",
        "\n",
        "  questions = torch.vstack((q1, q2, q3))\n",
        "\n",
        "  return questions\n",
        "\n",
        "\n",
        "# Cache the sample questions (by answer_digit and operation) for later reuse\n",
        "t_questions_dict = {}\n",
        "for answer_digit in range(cfg.n_digits):\n",
        "    for operation in [PLUS_INDEX, MINUS_INDEX]:\n",
        "        t_questions = make_tricase_questions(answer_digit, operation)\n",
        "        # Use a tuple of (answer_digit, operation) as the key for indexing\n",
        "        t_questions_dict[(answer_digit, operation)] = t_questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKc1kj-ZUeCo"
      },
      "outputs": [],
      "source": [
        "def pca_evr_0_percent(pca):\n",
        "  return int(round(pca.explained_variance_ratio_[0]*100,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWCPgoQZMjgc"
      },
      "outputs": [],
      "source": [
        "# Calculate one Principal Component Analysis\n",
        "def calc_pca_for_an(node_location, operation, answer_digit):\n",
        "  assert node_location.is_head == True\n",
        "\n",
        "  try:\n",
        "    t_questions = t_questions_dict[(answer_digit, operation)]\n",
        "\n",
        "    t_logits, t_cache = cfg.main_model.run_with_cache(t_questions)\n",
        "\n",
        "    # Gather attention patterns for all the (randomly chosen) questions\n",
        "    attention_outputs = []\n",
        "    for i in range(len(t_questions)):\n",
        "\n",
        "      # Output of individual heads, without final bias\n",
        "      attention_cache=t_cache[\"result\", node_location.layer, \"attn\"] # Output of individual heads, without final bias\n",
        "      attention_output=attention_cache[i]  # Shape [n_ctx, n_head, d_model]\n",
        "      attention_outputs.append(attention_output[node_location.position, node_location.num, :])\n",
        "\n",
        "    attn_outputs = torch.stack(attention_outputs, dim=0).cpu()\n",
        "\n",
        "    pca = PCA(n_components=6)\n",
        "    pca.fit(attn_outputs)\n",
        "    pca_attn_outputs = pca.transform(attn_outputs)\n",
        "\n",
        "    title = node_location.name() + ', A'+str(answer_digit) + ', EVR[0]=' + str(pca_evr_0_percent(pca)) + '%'\n",
        "\n",
        "    return pca, pca_attn_outputs, title\n",
        "  except Exception as e:\n",
        "    print( \"calc_pca_for_an Failed:\" + node_location.name() + \" \" + token_to_char(operation) + \" \" + answer_name(answer_digit), e)\n",
        "    return None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ_f5TUmqYBX"
      },
      "outputs": [],
      "source": [
        "# Plot the PCA of PnLnHn's attention pattern, using T8, T9, T10 questions that differ in the An digit\n",
        "def plot_pca_for_an(ax, pca_attn_outputs, title):\n",
        "  ax.scatter(pca_attn_outputs[:tn_questions, 0], pca_attn_outputs[:tn_questions, 1], color='red', label='T8 (0-8)') # t8 questions\n",
        "  ax.scatter(pca_attn_outputs[tn_questions:2*tn_questions, 0], pca_attn_outputs[tn_questions:2*tn_questions, 1], color='green', label='T9') # t9 questions\n",
        "  ax.scatter(pca_attn_outputs[2*tn_questions:, 0], pca_attn_outputs[2*tn_questions:, 1], color='blue', label='T10 (10-18)') # t10 questions\n",
        "  if title != \"\" :\n",
        "    ax.set_title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaRu2ZEaSRNW"
      },
      "outputs": [],
      "source": [
        "def pca_tag(the_digit, strong):\n",
        "  return answer_name(the_digit)  + \".\" + PCA_ADD_TAG + ( \"\" if strong else \".Weak\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk2K3y7pMlQr"
      },
      "outputs": [],
      "source": [
        "def manual_node_pca(ax, position, layer, num, operation, answer_digit):\n",
        "\n",
        "  node_location = NodeLocation(position, layer, True, num)\n",
        "  pca, pca_attn_outputs, title = calc_pca_for_an(node_location, operation, answer_digit)\n",
        "  plot_pca_for_an(ax, pca_attn_outputs, title)\n",
        "\n",
        "  # Add the strong PCA tag to node PCA:A5.TR\n",
        "  u_add_node_tag( node_location, QuantaType.PCA, pca_tag(answer_digit, True) )\n",
        "\n",
        "\n",
        "def auto_node_pca(ax, index, node_location, operation, answer_digit, perc_threshold):\n",
        "\n",
        "  pca, pca_attn_outputs, title = calc_pca_for_an(node_location, operation, answer_digit)\n",
        "  if pca is not None:\n",
        "    perc = pca_evr_0_percent(pca)\n",
        "    if perc > perc_threshold:\n",
        "      plot_pca_for_an(ax, pca_attn_outputs, title)\n",
        "\n",
        "      # Add the weak PCA tag to node PCA:A5.TR.Weak\n",
        "      u_add_node_tag( node_location, QuantaType.PCA, pca_tag(answer_digit, False) )\n",
        "      return True\n",
        "\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBQ1XWg_oJne"
      },
      "outputs": [],
      "source": [
        "def manual_nodes_pca(op, nodes):\n",
        "  cols = 4\n",
        "  rows = 1 + (len(nodes)+1) // cols\n",
        "\n",
        "  fig, axs = plt.subplots(rows, cols)\n",
        "  fig.set_figheight(rows*2 + 1)\n",
        "  fig.set_figwidth(10)\n",
        "\n",
        "  index = 0\n",
        "  for node in nodes:\n",
        "    manual_node_pca(axs[index // cols, index % cols], node[0], node[1], node[2], op, node[3])\n",
        "    index += 1\n",
        "\n",
        "  # Remove any graphs we dont need (except last one)\n",
        "  while index < rows * cols - 1:\n",
        "    ax = axs[index // cols, index % cols]\n",
        "    ax.remove()\n",
        "    index += 1\n",
        "\n",
        "  # Replace last graph with the legend\n",
        "  lines_labels = [axs[0,0].get_legend_handles_labels()]\n",
        "  lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
        "  axs[rows-1, cols-1].legend(lines, labels)\n",
        "  axs[rows-1, cols-1].axis('off') # Now, to hide the last subplot\n",
        "\n",
        "  plt.tight_layout()\n",
        "  save_plt_to_file('Pca Tr')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbiau9foMp3h"
      },
      "source": [
        "#Part 19B: Results: Manual interpetation of PCA results\n",
        "\n",
        "If an attention head and an answer digit An gives an interpretable response (2 or 3 distinct output clusters) on 3 groups of questions aligned to T8, T9 and T10 definitions, then plot the response and add a QuantaType.PCA tag\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhTlzqNr6qN5"
      },
      "outputs": [],
      "source": [
        "useful_info.reset_node_tags(QuantaType.PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ5fS3XNMs8e"
      },
      "outputs": [],
      "source": [
        "# Plot all attention heads with the clearest An selected\n",
        "if use_pca:\n",
        "\n",
        "  if cfg.model_name == \"add_d5_l1_h3_t30K\" :\n",
        "    manual_nodes_pca(PLUS_INDEX,\n",
        "      [[ 12, 0, 0, 4 ],  # P12L0H0 with A4 EVR[0]=98%\n",
        "      [ 12, 0, 2, 3 ],  # P12L0H2 with A3 EVR[0]=99%\n",
        "      [ 13, 0, 0, 3 ],  # P13L0H0 with A3 EVR[0]=99%\n",
        "      [ 13, 0, 2, 2 ],  # P13L0H2 with A2 EVR[0]=99%\n",
        "      [ 14, 0, 0, 2 ],  # P14L0H0 with A2 EVR[0]=100%\n",
        "      [ 14, 0, 2, 1 ],  # P14L0H2 with A1 EVR[0]=99%\n",
        "      [ 15, 0, 0, 1 ],  # P15L0H0 with A1 EVR[0]=99%\n",
        "      [ 15, 0, 2, 0 ],  # P15L0H2 with A0 EVR[0]=99%\n",
        "      [ 16, 0, 0, 0 ]]) # P16L0H0 with A0 EVR[0]=99%\n",
        "\n",
        "  if cfg.model_name == \"add_d5_l2_h3_t15K\" :\n",
        "    manual_nodes_pca(PLUS_INDEX,\n",
        "      [[10, 0, 0, 2 ],  # P10L0H0 with A2 EVR[0]=91%\n",
        "      [ 12, 0, 0, 3 ],  # P12L0H0 with A3 EVR[0]=87%\n",
        "      [ 12, 1, 0, 3 ],  # P12L1H0 with A3 EVR[0]=79%\n",
        "      [ 12, 1, 1, 4 ],  # P12L1H1 with A4 EVR[0]=81%\n",
        "      [ 12, 1, 2, 4 ],  # P12L1H2 with A4 EVR[0]=70%\n",
        "      [ 13, 0, 0, 0 ],  # P13L0H0 with A0 EVR[0]=88%\n",
        "      [ 13, 0, 0, 3 ],  # P13L0H0 with A3 EVR[0]=90%\n",
        "      [ 13, 1, 2, 2 ],  # P13L1H2 with A3 EVR[0]=88%\n",
        "      [ 14, 0, 0, 0 ],  # P14L0H0 with A0 EVR[0]=90%\n",
        "      [ 14, 0, 0, 2 ],  # P14L0H0 with A2 EVR[0]=91%\n",
        "      [ 14, 1, 2, 2 ],  # P14L1H2 with A2 EVR[0]=74%\n",
        "      [ 15, 0, 0, 1 ],  # P15L0H0 with A1 EVR[0]=89%\n",
        "      [ 15, 0, 0, 0 ],  # P15L0H0 with A0 EVR[0]=96%\n",
        "      [ 15, 1, 1, 1 ],  # P15L1H1 with A1 EVR[0]=89%\n",
        "      [ 16, 0, 0, 0 ]]) # P16L0H0 with A0 EVR[0]=90%\n",
        "\n",
        "  if cfg.model_name == \"add_d6_l2_h3_t15K\" :\n",
        "    manual_nodes_pca(PLUS_INDEX,\n",
        "      [[11, 0, 0, 2 ],  # P11L0H0 with A2 EVR[0]=85%\n",
        "      [ 12, 0, 0, 3 ],  # P12L0H0 with A3 EVR[0]=87%\n",
        "      [ 13, 0, 0, 1 ],  # P13L0H0 with A1 EVR[0]=84%\n",
        "      [ 14, 0, 0, 4 ],  # P14L0H0 with A4 EVR[0]=86%\n",
        "      [ 14, 1, 1, 4 ],  # P14L1H1 with A4 EVR[0]=82%\n",
        "      [ 15, 0, 0, 4 ],  # P15L0H0 with A4 EVR[0]=86%\n",
        "      [ 15, 1, 1, 4 ],  # P15L1H1 with A4 EVR[0]=83%\n",
        "      [ 16, 0, 0, 3 ],  # P16L0H0 with A3 EVR[0]=87%\n",
        "      [ 16, 1, 1, 3 ],  # P16L1H1 with A3 EVR[0]=92%\n",
        "      [ 17, 0, 0, 2 ],  # P17L0H0 with A2 EVR[0]=86%\n",
        "      [ 17, 1, 1, 2 ],  # P17L1H1 with A2 EVR[0]=83%\n",
        "      [ 18, 0, 0, 0 ],  # P18L0H0 with A0 EVR[0]=80%\n",
        "      [ 18, 0, 0, 1 ],  # P18L0H1 with A1 EVR[0]=85%\n",
        "      [ 19, 0, 0, 0 ]]) # P19L0H0 with A0 EVR[0]=85%\n",
        "\n",
        "  if cfg.model_name == \"sub_d6_l2_h3_t30K\" :\n",
        "    manual_nodes_pca(PLUS_INDEX,\n",
        "      [[ 8, 0, 0, 4 ],  # P8L0H0 with A4 EVR[0]=37%\n",
        "      [  9, 0, 1, 3 ],  # P9L0H1 with A3 EVR[0]=84%\n",
        "      [ 10, 0, 1, 2 ],  # P10L0H1 with A2 EVR[0]=77%\n",
        "      [ 10, 0, 1, 3 ],  # P10L0H1 with A3 EVR[0]=61%\n",
        "      [ 11, 0, 1, 1 ],  # P11L0H1 with A1 EVR[0]=82%\n",
        "      [ 11, 0, 1, 2 ],  # P11L0H1 with A2 EVR[0]=69%\n",
        "      [ 12, 0, 0, 0 ],  # P12L0H0 with A0 EVR[0]=57%\n",
        "      [ 13, 0, 1, 4 ],  # P13L0H1 with A4 EVR[0]=94%\n",
        "      [ 13, 1, 1, 0 ],  # P13L1H1 with A0 EVR[0]=89%\n",
        "      [ 13, 1, 1, 1 ],  # P13L1H1 with A1 EVR[0]=96%\n",
        "      [ 13, 1, 1, 2 ],  # P13L1H1 with A2 EVR[0]=94%\n",
        "      [ 13, 1, 1, 3 ],  # P13L1H1 with A3 EVR[0]=93%\n",
        "      [ 13, 1, 2, 3 ],  # P13L1H2 with A3 EVR[0]=73%\n",
        "      [ 13, 1, 2, 5 ],  # P13L1H2 with A5 EVR[0]=79%\n",
        "      [ 14, 0, 1, 0 ],  # P14L0H1 with A0 EVR[0]=80%\n",
        "      [ 15, 0, 0, 0 ],  # P15L0H0 with A0 EVR[0]=100%!\n",
        "      [ 15, 0, 0, 1 ],  # P15L0H0 with A1 EVR[0]=100%!\n",
        "      [ 15, 0, 0, 2 ],  # P15L0H0 with A2 EVR[0]=100%!\n",
        "      [ 15, 0, 0, 3 ],  # P15L0H0 with A3 EVR[0]=100%!\n",
        "      [ 15, 0, 0, 4 ],  # P15L0H0 with A4 EVR[0]=100%!\n",
        "      [ 15, 0, 0, 5 ],  # P15L0H0 with A5 EVR[0]=100%!\n",
        "      [ 15, 1, 0, 0 ],  # P15L1H0 with A0 EVR[0]=99%\n",
        "      [ 15, 1, 0, 1 ],  # P15L1H0 with A1 EVR[0]=99%\n",
        "      [ 15, 1, 0, 2 ],  # P15L1H0 with A2 EVR[0]=97%\n",
        "      [ 15, 1, 0, 3 ],  # P15L1H0 with A3 EVR[0]=97%\n",
        "      [ 15, 1, 0, 4 ]]) # P15L1H0 with A4 EVR[0]=84%\n",
        "\n",
        "  if cfg.model_name == \"ins1_mix_d6_l3_h4_t40K\" :\n",
        "    manual_nodes_pca(PLUS_INDEX,\n",
        "      [[13, 1, 3, 1 ],  # P13L1H3 with A1 EVR[0]=85%\n",
        "      [ 14, 1, 2, 0 ],  # P14L1H2 with A0 EVR[0]=77%\n",
        "      [ 14, 1, 2, 2 ],  # P14L1H2 with A2 EVR[0]=82%\n",
        "      [ 14, 1, 3, 4 ],  # P14L1H3 with A4 EVR[0]=87%\n",
        "      [ 15, 0, 3, 5 ],  # P15L0H3 with A5 EVR[0]=100%\n",
        "      [ 15, 1, 2, 2 ],  # P15L1H2 with A2 EVR[0]=81%\n",
        "      [ 15, 1, 3, 4 ],  # P15L1H3 with A4 EVR[0]=87%\n",
        "      [ 16, 0, 3, 4 ],  # P16L0H3 with A4 EVR[0]=99%\n",
        "      [ 16, 1, 2, 0 ],  # P16L1H0 with A0 EVR[0]=78%\n",
        "      [ 16, 1, 2, 1 ],  # P16L1H1 with A1 EVR[0]=77%\n",
        "      [ 16, 1, 2, 2 ],  # P16L1H2 with A2 EVR[0]=80%\n",
        "      [ 16, 1, 3, 2 ],  # P16L1H3 with A2 EVR[0]=78%\n",
        "      [ 17, 0, 3, 3 ],  # P17L0H3 with A3 EVR[0]=99%\n",
        "      [ 17, 1, 2, 2 ],  # P17L1H2 with A2 EVR[0]=84%\n",
        "      [ 17, 1, 3, 2 ],  # P17L1H3 with A2 EVR[0]=90%\n",
        "      [ 18, 0, 3, 2 ],  # P18L0H3 with A2 EVR[0]=98%\n",
        "      [ 18, 1, 3, 1 ],  # P18L1H3 with A1 EVR[0]=88%\n",
        "      [ 19, 0, 3, 1 ],  # P19L0H3 with A1 EVR[0]=98%\n",
        "      [ 19, 2, 0, 0 ],  # P19L2H0 with A0 EVR[0]=77%\n",
        "      [ 19, 2, 1, 0 ],  # P19L2H1 with A0 EVR[0]=80%\n",
        "      [ 20, 0, 0, 0 ],  # P20L0H0 with A0 EVR[0]=80%\n",
        "      [ 20, 0, 3, 0 ]]) # P20L0H3 with A0 EVR[0]=96%\n",
        "\n",
        "else:\n",
        "  print( \"PCA library failed to import. So PCA not done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIu3Pr9CMx3l"
      },
      "source": [
        "#Part 19C: Results: Automatic interpetation of PCA results\n",
        "\n",
        "Part 19B is manual and selective. This part is automatic. It tests nodes not included in Part 19B, where this first (single) principal component explains 66% or more of the node. It adds a QuantaType.PCA \"weak\" tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4FFdqy-79A1"
      },
      "outputs": [],
      "source": [
        "def auto_find_pca_node(node, op, perc_threshold):\n",
        "  fig, axs = plt.subplots(2, 4) # Allow up to 8 graphs\n",
        "  fig.set_figheight(4)\n",
        "  fig.set_figwidth(10)\n",
        "\n",
        "  index = 0\n",
        "  for answer_digit in range(cfg.n_digits+1):\n",
        "    ax = axs[index // 4, index % 4]\n",
        "    if auto_node_pca(ax, index, node, op, answer_digit, perc_threshold):\n",
        "      index += 1\n",
        "\n",
        "  # Remove any graphs we dont need after all\n",
        "  while index < 2 * 4:\n",
        "    ax = axs[index // 4, index % 4]\n",
        "    ax.remove()\n",
        "    index += 1\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdfpkXmAMzg4"
      },
      "outputs": [],
      "source": [
        "def auto_find_pca(op):\n",
        "  perc_threshold = 75\n",
        "\n",
        "  for node in useful_info.nodes:\n",
        "\n",
        "    # Exclude nodes with a (manual) PCA tag - for any answer digit(s)). Exlcude MLP neurons.\n",
        "    if node.is_head and not node.contains_tag(QuantaType.PCA, \"\"):\n",
        "      print( \"Doing PCA on node\", node.name(), \"operation\", token_to_char(op))\n",
        "\n",
        "      auto_find_pca_node(node, op, perc_threshold)\n",
        "\n",
        "\n",
        "if use_pca:\n",
        "  if cfg.perc_add() > 0:\n",
        "    auto_find_pca(PLUS_INDEX)\n",
        "  if cfg.perc_sub > 0:\n",
        "    auto_find_pca(MINUS_INDEX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcCpfmKwlAH"
      },
      "source": [
        "# Part 20A: Results: Show useful nodes and behaviour tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbzIaqmtwmkH"
      },
      "outputs": [],
      "source": [
        "useful_info.print_node_tags()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVkOJRmPvPms"
      },
      "source": [
        "# Part 20B: Results: Save useful nodes and behaviour tags to json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naD2eCZevOsi"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the useful nodes list to a temporary CoLab file in JSON format\n",
        "print( \"Saving useful node list with behavior tags:\", main_fname_behavior_json)\n",
        "useful_info.save_nodes(main_fname_behavior_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bbeIfUxvLzl"
      },
      "source": [
        "# Part 21A : Set up: Interchange Interventions\n",
        "\n",
        "Here we prove that model nodes perform specified calculations. If all the calculations in an algorithm hypothesis are found to exist in a model instance, this provides evidence for the hypothesis.   \n",
        "\n",
        "**Automatic searches** for node purposes are preferred, as they applicable to several models, and survive (non-sigificant, node-reordering) changes to the model after training. When a node purpose is detected, this is documented as a tag on the node.\n",
        "\n",
        "**Manually written tests** of node purposes, specific to a single model instance are also supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8VoNc_ckfrJ"
      },
      "outputs": [],
      "source": [
        "class A_Config():\n",
        "  # A list of NodeLocations\n",
        "  node_locations = []\n",
        "\n",
        "  # A list of stored weightings collected from the model.\n",
        "  # Same length as nodes\n",
        "  layer_store = []\n",
        "\n",
        "  questions = []\n",
        "  null_hooks = []\n",
        "  get_hooks = []\n",
        "  put_hooks = []\n",
        "\n",
        "  # Expected output of an intervention ablation experiment\n",
        "  expected_answer = \"\"\n",
        "  expected_impact = \"\" # e.g A32\n",
        "  # Actual outputs of an intervention ablation experiment\n",
        "  intervened_answer = \"\"\n",
        "  intervened_impact = \"\" # e.g A32\n",
        "\n",
        "\n",
        "  def reset_hooks(self):\n",
        "    self.node_locations = []\n",
        "    self.layer_store = [[],[],[]]   # Supports 3 layers\n",
        "    self.questions = []\n",
        "    self.null_hooks = []\n",
        "    self.get_hooks = []\n",
        "    self.put_hooks = []\n",
        "\n",
        "    tcfg.reset_node_location()\n",
        "    tcfg.threshold = 0.00001\n",
        "\n",
        "\n",
        "  def reset_intervention(self, expected_answer_int = 0, expected_impact = NO_IMPACT_TAG):\n",
        "    self.expected_answer = int_to_answer_str(expected_answer_int)\n",
        "    self.expected_impact = expected_impact if expected_impact != \"\" else NO_IMPACT_TAG\n",
        "    self.intervened_answer = \"\"\n",
        "    self.intervened_impact = NO_IMPACT_TAG\n",
        "\n",
        "\n",
        "  def __init__(self):\n",
        "    self.reset_hooks()\n",
        "    self.reset_intervention()\n",
        "\n",
        "\n",
        "  def node_names(self):\n",
        "    answer = \"\"\n",
        "\n",
        "    for node in self.node_locations:\n",
        "      if answer != \"\":\n",
        "        answer += \", \"\n",
        "      answer += node.name()\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "acfg = A_Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMdSybNpnU0m"
      },
      "outputs": [],
      "source": [
        "# Get and put attention head value hooks\n",
        "\n",
        "def a_null_attn_z_hook(value, hook):\n",
        "  #print(\"In a_null_attn_z_hook\", value.shape)  # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "  pass\n",
        "\n",
        "\n",
        "def a_get_l0_attn_z_hook(value, hook):\n",
        "  # print( \"In a_get_l0_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, cfg.d_head\n",
        "  acfg.layer_store[0] = value.clone()\n",
        "\n",
        "def a_get_l1_attn_z_hook(value, hook):\n",
        "  acfg.layer_store[1] = value.clone()\n",
        "\n",
        "def a_get_l2_attn_z_hook(value, hook):\n",
        "  acfg.layer_store[2] = value.clone()\n",
        "\n",
        "def a_get_l3_attn_z_hook(value, hook):\n",
        "  acfg.layer_store[3] = value.clone()\n",
        "\n",
        "\n",
        "def a_put_l0_attn_z_hook(value, hook):\n",
        "  # print( \"In a_l0_attn_z_hook\", value.shape) # Get [1, 22, 3, 170] = ???, cfg.n_ctx, cfg.n_heads, d_head\n",
        "  for location in acfg.node_locations:\n",
        "    if location.layer == 0:\n",
        "      value[:,location.position,location.num,:] = acfg.layer_store[0][:,location.position,location.num,:].clone()\n",
        "\n",
        "def a_put_l1_attn_z_hook(value, hook):\n",
        "  for location in acfg.node_locations:\n",
        "    if location.layer == 1:\n",
        "      value[:,location.position,location.num,:] = acfg.layer_store[0][:,location.position,location.num,:].clone()\n",
        "\n",
        "def a_put_l2_attn_z_hook(value, hook):\n",
        "  for location in acfg.node_locations:\n",
        "    if location.layer == 2:\n",
        "      value[:,location.position,location.num,:] = acfg.layer_store[0][:,location.position,location.num,:].clone()\n",
        "\n",
        "def a_put_l3_attn_z_hook(value, hook):\n",
        "  for location in acfg.node_locations:\n",
        "    if location.layer == 3:\n",
        "      value[:,location.position,location.num,:] = acfg.layer_store[0][:,location.position,location.num,:].clone()\n",
        "\n",
        "\n",
        "def a_reset(node_locations):\n",
        "  acfg.reset_hooks()\n",
        "  acfg.node_locations = node_locations\n",
        "  acfg.null_hooks = [(l_attn_hook_z_name[0], a_null_attn_z_hook), (l_attn_hook_z_name[1], a_null_attn_z_hook), (l_attn_hook_z_name[2], a_null_attn_z_hook), (l_attn_hook_z_name[3], a_null_attn_z_hook)][:cfg.n_layers]\n",
        "  acfg.get_hooks = [(l_attn_hook_z_name[0], a_get_l0_attn_z_hook), (l_attn_hook_z_name[1], a_get_l1_attn_z_hook), (l_attn_hook_z_name[2], a_get_l2_attn_z_hook), (l_attn_hook_z_name[3], a_get_l3_attn_z_hook)][:cfg.n_layers]\n",
        "  acfg.put_hooks = [(l_attn_hook_z_name[0], a_put_l0_attn_z_hook), (l_attn_hook_z_name[1], a_put_l1_attn_z_hook), (l_attn_hook_z_name[2], a_put_l2_attn_z_hook), (l_attn_hook_z_name[3], a_put_l3_attn_z_hook)][:cfg.n_layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk0gVCF9Gr5D"
      },
      "outputs": [],
      "source": [
        "def run_intervention_core(node_locations, store_question, test_question, operation):\n",
        "  assert(test_question[0] < + 10 ** cfg.n_digits)\n",
        "  assert(test_question[1] > - 10 ** cfg.n_digits)\n",
        "  assert(test_question[0] < + 10 ** cfg.n_digits)\n",
        "  assert(test_question[1] > - 10 ** cfg.n_digits)\n",
        "\n",
        "\n",
        "  a_reset(node_locations)\n",
        "\n",
        "  # Calculate the clean (no intervention) test question answer  e.g. \"+006671\"\n",
        "  clean_answer_int = test_question[0]+test_question[1] if operation == PLUS_INDEX else test_question[0]-test_question[1]\n",
        "  clean_answer = int_to_answer_str(clean_answer_int)\n",
        "  description = \"Intervening on \" + acfg.node_names() + \", CleanAnswer: \" + clean_answer\n",
        "\n",
        "  # Predict \"store\" question and store activation values\n",
        "  acfg.questions = make_questions(operation, [store_question])\n",
        "  predict_questions_core(acfg.questions, acfg.get_hooks)\n",
        "\n",
        "  # Predict \"test\" question overriding PnLmHp to give a bad answer\n",
        "  acfg.questions = make_questions(operation, [test_question])\n",
        "  all_losses_raw, all_max_prob_tokens = predict_questions_core(acfg.questions, acfg.put_hooks)\n",
        "  loss_max = utils.to_numpy(loss_fn(all_losses_raw[0]).max())\n",
        "  acfg.intervened_answer = tokens_to_string(all_max_prob_tokens[0])\n",
        "\n",
        "\n",
        "  # Compare the clean test question answer to what the model generated (impacted by the ablation intervention)\n",
        "  acfg.intervened_impact = get_answer_impact( clean_answer, acfg.intervened_answer )\n",
        "  if acfg.intervened_impact == \"\":\n",
        "    acfg.intervened_impact = NO_IMPACT_TAG\n",
        "\n",
        "  if loss_max > tcfg.threshold:\n",
        "    loss_str = NO_IMPACT_TAG if loss_max < 1e-7 else str(loss_max)\n",
        "\n",
        "    description += \", IntervenedAnswer/Impact: \" + acfg.intervened_answer + \"/\" + acfg.intervened_impact + \", Loss: \" + loss_str\n",
        "\n",
        "  return description\n",
        "\n",
        "\n",
        "# Run an intervention where we have a precise expectation of the intervention impact\n",
        "def run_strong_intervention(node_locations, store_question, test_question, operation, expected_impact, expected_answer_int, show_failures = True):\n",
        "  acfg.reset_intervention(expected_answer_int, expected_impact)\n",
        "\n",
        "  # These are the actual model prediction outputs (while applying our node-level intervention).\n",
        "  description = run_intervention_core(node_locations, store_question, test_question, operation)\n",
        "\n",
        "  answer_success = (acfg.intervened_answer == acfg.expected_answer)\n",
        "  impact_success = (acfg.intervened_impact == acfg.expected_impact)\n",
        "  success = answer_success and impact_success\n",
        "\n",
        "  if show_failures and not success:\n",
        "    print( description )\n",
        "    print(\"Failed: Expected:\", acfg.expected_answer, acfg.expected_impact, \"Model predicted:\", acfg.intervened_answer, acfg.intervened_impact)\n",
        "\n",
        "  return success, answer_success, impact_success\n",
        "\n",
        "\n",
        "# Run an intervention where we expect the intervention to have a non-zero impact and we cant precisely predict the answer\n",
        "def run_weak_intervention(node_locations, store_question, test_question, operation, show_failures = True):\n",
        "\n",
        "  # Calculate the test (clean) question answer e.g. \"+006671\"\n",
        "  expected_answer_int = test_question[0]+test_question[1] if operation == PLUS_INDEX else test_question[0]-test_question[1]\n",
        "  acfg.reset_intervention(expected_answer_int, NO_IMPACT_TAG)\n",
        "\n",
        "  description = run_intervention_core(node_locations, store_question, test_question, operation)\n",
        "\n",
        "  success = not ((acfg.intervened_answer == acfg.expected_answer) or (acfg.intervened_impact == NO_IMPACT_TAG))\n",
        "\n",
        "  if show_failures and not success:\n",
        "    print(\"Failed: Intervention had no impact on the answer\", description)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3RvmrLcKy0w"
      },
      "outputs": [],
      "source": [
        "def repeat_digit(digit):\n",
        "    return int(str(digit) * cfg.n_digits)\n",
        "\n",
        "\n",
        "# unit test\n",
        "if cfg.n_digits == 6:\n",
        "  assert repeat_digit(4) == 444444"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ignore_test(node_locations, alter_digit, strong, show_failures = False):\n",
        "  return True"
      ],
      "metadata": {
        "id": "P_ucys_1txG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "119UX6us5hit"
      },
      "outputs": [],
      "source": [
        "# Search the specified useful node(s), using the test_function, for the expected impact on the_impact_digit\n",
        "def search_and_tag_digit_position( the_impact_digit, the_test_nodes, test_function, strong, the_tag, do_pair_search ):\n",
        "\n",
        "  # Try single nodes first\n",
        "  for node in the_test_nodes:\n",
        "    if test_function( [node], the_impact_digit, strong):\n",
        "      full_tag = the_tag + (\"\" if strong else \".\" + acfg.intervened_impact)\n",
        "      node.add_tag(QuantaType.ALGO, full_tag)\n",
        "      return True\n",
        "\n",
        "  # Try pairs of nodes. Sometimes a task is split across two attention heads (i.e. a virtual attention head)\n",
        "  if do_pair_search:\n",
        "    node_pairs = list(itertools.combinations(the_test_nodes, 2))\n",
        "    for pair in node_pairs:\n",
        "        if test_function( [pair[0], pair[1]], the_impact_digit, strong):\n",
        "          full_tag = the_tag + (\"\" if strong else \".\" + acfg.intervened_impact)\n",
        "          pair[0].add_tag(QuantaType.ALGO, full_tag)\n",
        "          pair[1].add_tag(QuantaType.ALGO, full_tag)\n",
        "          return True\n",
        "\n",
        "  return False\n",
        "\n",
        "\n",
        "# For each useful position, search the related useful node(s), using the test_function, for the expected impact on the_impact_digit.\n",
        "def search_and_tag_digit( prerequisites_function, the_impact_digit, test_function, tag_function, do_pair_search, do_weak_search, from_position, to_position ):\n",
        "\n",
        "  the_tag = tag_function(the_impact_digit)\n",
        "\n",
        "  if from_position == -1:\n",
        "    from_position = useful_info.min_useful_position()\n",
        "  if to_position == -1:\n",
        "    to_position = useful_info.max_useful_position()\n",
        "\n",
        "  # In some models, we don't predict the intervened_answer correctly in test_function.\n",
        "  # So we may do a weak second pass and may add say \"A5.BS.A632\" tag to a node.\n",
        "  for strong in [True, False]:\n",
        "    if strong or do_weak_search:\n",
        "\n",
        "      for position in range(from_position, to_position+1):\n",
        "        test_nodes = filter_nodes( useful_info.nodes, prerequisites_function(position, the_impact_digit))\n",
        "        if search_and_tag_digit_position( the_impact_digit, test_nodes, test_function, strong, the_tag, do_pair_search ):\n",
        "          return True\n",
        "\n",
        "  return False\n",
        "\n",
        "\n",
        "# For each answer digit, for each useful position, search the related useful node(s), using the test_function, for the expected impact on the_impact_digit. We may do 2 passes.\n",
        "def search_and_tag( prerequisites_function, test_function, tag_function, do_pair_search = True, do_weak_search = True, from_position = -1, to_position = -1):\n",
        "  for the_impact_digit in range(useful_info.num_answer_positions):\n",
        "    search_and_tag_digit(\n",
        "      prerequisites_function, the_impact_digit, test_function, tag_function,\n",
        "      do_pair_search, do_weak_search, from_position, to_position )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xraYvF7eBD1p"
      },
      "outputs": [],
      "source": [
        "useful_info.reset_node_tags(QuantaType.ALGO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgg43Sqe8oF1"
      },
      "source": [
        "# Part 21B: Automated Dn.US search\n",
        "\n",
        "The addition Use Sum 9 (US) operation is a simple task. Search for US tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq9WJSHHGN0Q"
      },
      "outputs": [],
      "source": [
        "def add_us_tag(impact_digit):\n",
        "  return answer_name(impact_digit-1)  + \".\" + ALGO_ADD_US_TAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xeffLN6eqIq"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) an Addition UseSum9 node\n",
        "def add_us_prereqs(position, impact_digit):\n",
        "  return FilterAnd(\n",
        "    FilterHead(),\n",
        "    FilterPosition(position_name(position)),\n",
        "    FilterAttention(dn_to_position_name(impact_digit-2)), # Attends to Dn-2\n",
        "    FilterAttention(ddn_to_position_name(impact_digit-2)), # Attends to D'n-2\n",
        "    FilterImpact(answer_name(impact_digit)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8y-7JQX8oSP"
      },
      "outputs": [],
      "source": [
        "def add_us_test(node_locations, alter_digit, strong):\n",
        "  if alter_digit < 2 or alter_digit > cfg.n_digits:\n",
        "    acfg.reset_intervention()\n",
        "    return False\n",
        "\n",
        "  intervention_impact = answer_name(alter_digit)\n",
        "\n",
        "  # 25222 + 44444 = 69666. Has no Dn-2.MC but has Dn-1.US so not a US case\n",
        "  store_question = [repeat_digit(2), repeat_digit(4)]\n",
        "  store_question[0] += (5-2) * 10 ** (alter_digit - 1)\n",
        "\n",
        "  # 34633 + 55555 = 90188. Has Dn-2.MC and Dn-1.US so is a US case\n",
        "  test_question = [repeat_digit(3), repeat_digit(5)]\n",
        "  test_question[0] += (4-3) * 10 ** (alter_digit - 1)\n",
        "  test_question[0] += (6-3) * 10 ** (alter_digit - 2)\n",
        "\n",
        "  # When we intervene we expect answer 80188\n",
        "  intervened_answer = test_question[0] + test_question[1] - 10 ** (alter_digit)\n",
        "\n",
        "\n",
        "  # Unit test\n",
        "  if cfg.n_digits == 5 and alter_digit == 4:\n",
        "    assert store_question[0] == 25222\n",
        "    assert test_question[0] == 34633\n",
        "    assert test_question[0] + test_question[1] == 90188\n",
        "    assert intervened_answer == 80188\n",
        "\n",
        "\n",
        "  success, _, _ = run_strong_intervention(node_locations, store_question, test_question, PLUS_INDEX, intervention_impact, intervened_answer, False)\n",
        "\n",
        "  if success:\n",
        "    print( \"Test confirmed\", acfg.node_names(), \"perform D\"+str(alter_digit)+\".US impacting \"+intervention_impact+\" accuracy.\", \"Strong:\", strong)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUYf20mk8zls"
      },
      "outputs": [],
      "source": [
        "# if cfg.perc_add() > 0: Should not succeed in subtraction cases\n",
        "search_and_tag( add_us_prereqs, add_us_test, add_us_tag, False, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5DMV3I_25ST"
      },
      "source": [
        "# Part 21C: Automated Dn.MC search\n",
        "\n",
        "The addition Make Carry (MC) operation is a simple task. Search for MC tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YizIdKqven8h"
      },
      "outputs": [],
      "source": [
        "def add_mc_tag(impact_digit):\n",
        "  return answer_name(impact_digit-1)  + \".\" + ALGO_ADD_MC_TAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXevYPyteXy1"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) an Addition MakeCarry node\n",
        "def add_mc_prereqs(position, impact_digit):\n",
        "  return FilterAnd(\n",
        "    FilterHead(),\n",
        "    FilterPosition(position_name(position)),\n",
        "    FilterAttention(dn_to_position_name(impact_digit-1)), # MC is calculated on the next lower-value digit.\n",
        "    FilterAttention(ddn_to_position_name(impact_digit-1)), # MC is calculated on the next lower-value digit.\n",
        "    FilterImpact(answer_name(impact_digit)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJBYT0hF3R_u"
      },
      "outputs": [],
      "source": [
        "def add_mc_test(node_locations, impact_digit, strong):\n",
        "  alter_digit = impact_digit - 1\n",
        "\n",
        "  if alter_digit < 0 or alter_digit >= cfg.n_digits:\n",
        "    acfg.reset_intervention()\n",
        "    return False\n",
        "\n",
        "  intervention_impact = answer_name(impact_digit)\n",
        "\n",
        "  # 222222 + 666966 = 889188. Has Dn.MC\n",
        "  store_question = [repeat_digit(2), repeat_digit(6)]\n",
        "  store_question[1] += (9 - 6) * (10 ** alter_digit)\n",
        "\n",
        "  # 333333 + 555555 = 888888. No Dn.MC\n",
        "  test_question = [repeat_digit(3), repeat_digit(5)]\n",
        "\n",
        "  # When we intervene we expect answer 889888\n",
        "  intervened_answer = test_question[0] + test_question[1] + 10 ** (alter_digit+1)\n",
        "\n",
        "  success, _, _ = run_strong_intervention(node_locations, store_question, test_question, PLUS_INDEX, intervention_impact, intervened_answer, False)\n",
        "\n",
        "  if success:\n",
        "    print( \"Test confirmed\", acfg.node_names(), \"perform D\"+str(alter_digit)+\".MC impacting \"+intervention_impact+\" accuracy.\", \"Strong:\", strong)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvS1eOReZUq1"
      },
      "outputs": [],
      "source": [
        "# if cfg.perc_add() > 0: Should not succeed in subtraction cases\n",
        "search_and_tag( add_mc_prereqs, add_mc_test, add_mc_tag, False, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iosx5zE_macF"
      },
      "source": [
        "# Part 21D: Automated Dn.BA search\n",
        "\n",
        "The addition Base Add (BA) operation is a simple task. The task may be split/shared over 2 attention heads in the same position. Search for BA calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq_nczrDdxjy"
      },
      "outputs": [],
      "source": [
        "def add_ba_tag(impact_digit):\n",
        "  return answer_name(impact_digit) + \".\" + ALGO_ADD_BA_TAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLXpgGXpWpPp"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) an Addition BaseAdd node\n",
        "def add_ba_prereqs(position, impact_digit):\n",
        "  return FilterAnd(\n",
        "    FilterHead(),\n",
        "    FilterPosition(position_name(position)),\n",
        "    FilterAttention(dn_to_position_name(impact_digit)), # Attends to Dn\n",
        "    FilterAttention(ddn_to_position_name(impact_digit)), # Attends to D'n\n",
        "    FilterImpact(answer_name(impact_digit)), # Impacts An\n",
        "    FilterAlgo(add_ba_tag(impact_digit), QuantaFilter.NOT)) # Has not already been flagged as a BA task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-Gs5yglncax"
      },
      "outputs": [],
      "source": [
        "def add_ba_test1(alter_digit):\n",
        "  # 222222 + 111111 = 333333. No Dn.MC\n",
        "  store_question = [repeat_digit(2), repeat_digit(1)]\n",
        "\n",
        "  # 555555 + 444444 = 999999. No Dn.MC\n",
        "  test_question = [repeat_digit(5), repeat_digit(4)]\n",
        "\n",
        "  # When we intervene we expect answer 999399\n",
        "  intervened_answer = test_question[0] + test_question[1] + (3-9) * 10 ** alter_digit\n",
        "\n",
        "  return store_question, test_question, intervened_answer\n",
        "\n",
        "\n",
        "def add_ba_test2(alter_digit):\n",
        "  # 222222 + 666666 = 888888. No Dn.MC\n",
        "  store_question = [repeat_digit(2), repeat_digit(6)]\n",
        "\n",
        "  # 555555 + 111111 = 666666. No Dn.MC\n",
        "  test_question = [repeat_digit(5), repeat_digit(1)]\n",
        "\n",
        "  # When we intervene we expect answer 666866\n",
        "  intervened_answer = test_question[0] + test_question[1] + (8-6) * 10 ** alter_digit\n",
        "\n",
        "  return store_question, test_question, intervened_answer\n",
        "\n",
        "\n",
        "def add_ba_test(node_locations, alter_digit, strong, show_failures = False):\n",
        "  intervention_impact = answer_name(alter_digit)\n",
        "\n",
        "  store_question, test_question, intervened_answer = add_ba_test1(alter_digit)\n",
        "  success1, answer_success1, impact_success1 = run_strong_intervention(node_locations, store_question, test_question, PLUS_INDEX, intervention_impact, intervened_answer, show_failures)\n",
        "\n",
        "  store_question, test_question, intervened_answer = add_ba_test2(alter_digit)\n",
        "  success2, answer_success2, impact_success2 = run_strong_intervention(node_locations, store_question, test_question, PLUS_INDEX, intervention_impact, intervened_answer, show_failures)\n",
        "\n",
        "  success = (success1 and success2) if strong else (impact_success1 and impact_success2)\n",
        "\n",
        "  if success:\n",
        "    print( \"Test confirmed:\", acfg.node_names(), \"perform D\"+str(alter_digit)+\".BA = (D\"+str(alter_digit)+\" + D\"+str(alter_digit)+\"') % 10 impacting \"+intervention_impact+\" accuracy.\", \"Strong:\", strong)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIktdaRL-BfP"
      },
      "outputs": [],
      "source": [
        "#if cfg.perc_add() > 0: Should not succeed in subtraction cases\n",
        "search_and_tag( add_ba_prereqs, add_ba_test, add_ba_tag, True, True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThzFD1FxBXg8"
      },
      "source": [
        "# Part 21E: Automated Dn.C search\n",
        "\n",
        "Search for D0.C to D5.C with impact \"A65432\" to \"A65\" in early tokens.\n",
        "\n",
        "A0 and A1 are too simple to need Dn.C values so they are excluded from the answer impact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0aF8E-bd736"
      },
      "outputs": [],
      "source": [
        "def add_tc_tag(focus_digit):\n",
        "  return \"D\" + str(focus_digit) + \".\" + ALGO_ADD_TC_TAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV8sqYs7dCcj"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) an Addition Dn.C node\n",
        "def add_tc_prereqs(position, focus_digit):\n",
        "  return FilterAnd(\n",
        "    FilterHead(),\n",
        "    FilterPosition(position_name(position)),\n",
        "    FilterAttention(dn_to_position_name(focus_digit)), # Attends to Dn\n",
        "    FilterAttention(ddn_to_position_name(focus_digit)), # Attends to D'n\n",
        "    FilterPCA(PCA_ADD_TAG, QuantaFilter.CONTAINS)) # Node PCA is interpretable with respect to T8,T9,T10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-bcEooQBp2v"
      },
      "outputs": [],
      "source": [
        "def add_tc_test(node_locations, focus_digit, strong):\n",
        "  # 222222 + 777977 = 1000188. Has Dn.MC\n",
        "  store_question = [repeat_digit(2), repeat_digit(7)]\n",
        "  store_question[1] += (9 - 7) * (10 ** focus_digit)\n",
        "\n",
        "  # 333333 + 666666 = 999999. No Dn.MC\n",
        "  test_question = [repeat_digit(3), repeat_digit(6)]\n",
        "  alter_sum = test_question[0] + test_question[1]\n",
        "\n",
        "  success = run_weak_intervention(node_locations, store_question, test_question, PLUS_INDEX, False)\n",
        "\n",
        "  if success:\n",
        "    description = acfg.node_names() + \" perform D\"+str(focus_digit)+\".C = TriCase(D\"+str(focus_digit)+\" + D\"+str(focus_digit)+\"')\"\n",
        "    print(\"Test confirmed\", description, \"Impact:\", acfg.intervened_impact, \"Strong:\", strong)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFJV4pfWSwHQ"
      },
      "outputs": [],
      "source": [
        "# if cfg.perc_add() > 0: Should not succeed in subtraction cases\n",
        "search_and_tag( add_tc_prereqs, add_tc_test, add_tc_tag,\n",
        "  False, # Have not seen this task split between nodes.\n",
        "  False,\n",
        "  cfg.n_digits, 2*cfg.n_digits+2) # These occur from the first D'n digit to the first answer digit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jOBIUDzRrGz"
      },
      "source": [
        "# Part 21F: Automated Dn.BS search\n",
        "\n",
        "The subtraction Base Subtraction (BS) operation is a simple task. The task may be split/shared over 2 attention heads in the same position. Search for BS calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE4icd5UR12w"
      },
      "outputs": [],
      "source": [
        "def sub_bs_tag(impact_digit):\n",
        "  return answer_name(impact_digit) + \".\" + ALGO_SUB_BS_TAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbeReTw3R8yR"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) a BaseSubtraction node\n",
        "def sub_bs_prereqs(position, impact_digit):\n",
        "  return FilterAnd(\n",
        "    FilterHead(),\n",
        "    FilterPosition(position_name(position)),\n",
        "    FilterAttention(dn_to_position_name(impact_digit)), # Attends to Dn\n",
        "    FilterAttention(ddn_to_position_name(impact_digit)), # Attends to D'n\n",
        "    FilterImpact(answer_name(impact_digit)), # Impacts An\n",
        "    FilterAlgo(sub_bs_tag(impact_digit), QuantaFilter.NOT)) # Has not already been flagged as a BS task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxce_IoeSTl4"
      },
      "outputs": [],
      "source": [
        "def sub_bs_test1(alter_digit):\n",
        "  # 333333 - 111111 = 222222. No Dn.BO\n",
        "  store_question = [repeat_digit(3), repeat_digit(1)]\n",
        "\n",
        "  # 999999 - 444444 = 555555. No Dn.BO\n",
        "  test_question = [repeat_digit(9), repeat_digit(4)]\n",
        "\n",
        "  # When we intervene we expect answer 555255\n",
        "  intervened_answer = test_question[0] - test_question[1] + (2-5) * 10 ** alter_digit\n",
        "\n",
        "  return store_question, test_question, intervened_answer\n",
        "\n",
        "\n",
        "def sub_bs_test2(alter_digit):\n",
        "  # 666666 - 222222 = 444444. No Dn.BO\n",
        "  store_question = [repeat_digit(6), repeat_digit(2)]\n",
        "\n",
        "  # 555555 - 333333 = 222222. No Dn.BO\n",
        "  test_question = [repeat_digit(5), repeat_digit(3)]\n",
        "\n",
        "  # When we intervene we expect answer 222422\n",
        "  intervened_answer = test_question[0] - test_question[1] + (4-2) * 10 ** alter_digit\n",
        "\n",
        "  return store_question, test_question, intervened_answer\n",
        "\n",
        "\n",
        "def sub_bs_test(node_locations, alter_digit, strong, show_failures = False):\n",
        "  intervention_impact = answer_name(alter_digit)\n",
        "\n",
        "  store_question, test_question, intervened_answer = sub_bs_test1(alter_digit)\n",
        "  success1, answer_success1, impact_success1 = run_strong_intervention(node_locations, store_question, test_question, MINUS_INDEX, intervention_impact, intervened_answer, show_failures)\n",
        "\n",
        "  store_question, test_question, intervened_answer = sub_bs_test2(alter_digit)\n",
        "  success2, answer_success2, impact_success2 = run_strong_intervention(node_locations, store_question, test_question, MINUS_INDEX, intervention_impact, intervened_answer, show_failures)\n",
        "\n",
        "  success = (success1 and success2) if strong else (impact_success1 and impact_success2)\n",
        "\n",
        "  if success:\n",
        "    print( \"Test confirmed:\", acfg.node_names(), \"perform D\"+str(alter_digit)+\".BS = (D\"+str(alter_digit)+\" + D\"+str(alter_digit)+\"') % 10 impacting \"+intervention_impact+\" accuracy.\", \"Strong:\", strong)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKag6sUnVS2N"
      },
      "outputs": [],
      "source": [
        "search_and_tag( sub_bs_prereqs, sub_bs_test, sub_bs_tag, True, True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVyItdhmhIn8"
      },
      "source": [
        "# Part 21G: Automated Dn.BO search\n",
        "\n",
        "The subtraction Borrow One operation is a simple task. Search for BO tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OvVAefqhXVY"
      },
      "outputs": [],
      "source": [
        "def sub_bo_tag(impact_digit):\n",
        "  return answer_name(impact_digit-1)  + \".\" + ALGO_SUB_BO_TAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSbkA_vzhfAh"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) an subtraction Borrow One node\n",
        "def sub_bo_prereqs(position, impact_digit):\n",
        "  return FilterAnd(\n",
        "    FilterHead(),\n",
        "    FilterPosition(position_name(position)),\n",
        "    FilterAttention(dn_to_position_name(impact_digit-1)), # BO is calculated on the next lower-value digit.\n",
        "    FilterAttention(ddn_to_position_name(impact_digit-1)), # BO is calculated on the next lower-value digit.\n",
        "    FilterImpact(answer_name(impact_digit)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvbz0EF7iEV-"
      },
      "outputs": [],
      "source": [
        "def sub_bo_test(node_locations, impact_digit, strong):\n",
        "  alter_digit = impact_digit - 1\n",
        "  intervention_impact = answer_name(impact_digit)\n",
        "\n",
        "  # 222222 - 111311 = 110911. Has Dn.BO\n",
        "  store_question = [repeat_digit(2), repeat_digit(1)]\n",
        "  store_question[1] += (3 - 1) * (10 ** alter_digit)\n",
        "\n",
        "  # 777777 - 444444 = 333333. No Dn.BO\n",
        "  test_question = [repeat_digit(7), repeat_digit(4)]\n",
        "\n",
        "  # When we intervene we expect answer 332333\n",
        "  intervened_answer = test_question[0] - test_question[1] - 10 ** alter_digit\n",
        "\n",
        "  #print(\"PQR\", store_question,test_question,intervened_answer)\n",
        "  success, _, _ = run_strong_intervention(node_locations, store_question, test_question, MINUS_INDEX, intervention_impact, intervened_answer, False)\n",
        "\n",
        "  if success:\n",
        "    print( \"Test confirmed\", acfg.node_names(), \"perform D\"+str(alter_digit)+\".BO impacting \"+intervention_impact+\" accuracy.\", \"Strong:\", strong)\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzjlFwEui7K9"
      },
      "outputs": [],
      "source": [
        "#if cfg.perc_sub > 0: Should not succeed in addition cases\n",
        "search_and_tag( sub_bo_prereqs, sub_bo_test, sub_bo_tag, False, False) #PQR debug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(filter_nodes( useful_info.nodes, sub_bo_prereqs(17, 3)))\n",
        "#print(filter_nodes( useful_info.nodes, sub_bo_prereqs(17, 4)))\n",
        "#print(filter_nodes( useful_info.nodes, sub_bo_prereqs(17, 5)))\n",
        "\n",
        "#nodes = filter_nodes( useful_info.nodes, sub_bo_prereqs(17, 3) )\n",
        "#print(nodes[0].name())\n",
        "#sub_bo_test( [NodeLocation(17, 0, True, 0)], 3, True)\n"
      ],
      "metadata": {
        "id": "i7-EJvCgFzEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 21H: Automated Dn.NG search\n",
        "\n",
        "Somes useful nodes are only used in subtraction when A < B in the A - B question e.g. negative-answer questions. We claim these nodes are somehow associated with converting A - B to - ( B - A )"
      ],
      "metadata": {
        "id": "sJo37Qg2ZQpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sub_ng_tag(impact_digit):\n",
        "  return answer_name(impact_digit)  + \".\" + ALGO_SUB_NG_TAG"
      ],
      "metadata": {
        "id": "uZAVz_dNaMUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sub_ng_prereqs(position, impact_digit):\n",
        "  return FilterAnd(\n",
        "    FilterHead(),\n",
        "    FilterPosition(position_name(position)),\n",
        "    FilterImpact(answer_name(impact_digit)), # Impacts An\n",
        "    FilterContains(QuantaType_MATH_SUB, MATH_SUB_NG_TAG), # Impacts negative-answer questions\n",
        "    # Does not impact positive-answer subtraction questions (of any complexity)\n",
        "    FilterContains(QuantaType_MATH_SUB, MATH_SUB_S0_TAG, QuantaFilter.NOT),\n",
        "    FilterContains(QuantaType_MATH_SUB, MATH_SUB_S1_TAG, QuantaFilter.NOT),\n",
        "    FilterContains(QuantaType_MATH_SUB, MATH_SUB_S2_TAG, QuantaFilter.NOT),\n",
        "    FilterContains(QuantaType_MATH_SUB, MATH_SUB_S3_TAG, QuantaFilter.NOT))"
      ],
      "metadata": {
        "id": "nScZJkfge-7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_tag( sub_ng_prereqs, ignore_test, sub_ng_tag )"
      ],
      "metadata": {
        "id": "SOJ4J214g3La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 21I: Automated Dn.OP search\n",
        "\n",
        "For mixed models that do addition and subtraction the operation token \"+/-\" is key. Find nodes that attend to the operation."
      ],
      "metadata": {
        "id": "Agw7np7gZmgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mix_op_tag(impact_digit):\n",
        "  return ALGO_MIX_OP_TAG"
      ],
      "metadata": {
        "id": "2XjAoHFCaQ0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sub_op_prereqs(position, impact_digit):\n",
        "  return FilterAnd(\n",
        "    FilterHead(),\n",
        "    FilterPosition(position_name(position)),\n",
        "    FilterAttention(op_position_name()))"
      ],
      "metadata": {
        "id": "6totKsJ2hjYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_and_tag( sub_op_prereqs, ignore_test, mix_op_tag )"
      ],
      "metadata": {
        "id": "d0s2ZTMLimIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQLfkdlbVAl_"
      },
      "source": [
        "# Part 22: Show algorithm quanta map\n",
        "\n",
        "Plot the \"algorithm\" tags generated in previous steps as a quanta map. This is an automatically generated partail explanation of the model algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9VDbjTAVGrP"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Algorithm Purpose Per Node\", create_custom_colormap(), 2, QuantaType.ALGO, \"\", get_quanta_binary, 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhheXmLTUfc"
      },
      "source": [
        "# Part 23: Save useful nodes with behaviour and algorithm tags to JSON file\n",
        "\n",
        "Show a list of the nodes that have proved useful in calculations, together with data on the nodes behavior and algorithmic purposes.\n",
        "Save the data to a Colab temporary JSON file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRW6tiM8hDOB"
      },
      "outputs": [],
      "source": [
        "useful_info.print_node_tags(QuantaType.ALGO, False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ktlEftAOyEd"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the useful nodes list with algorithm tags to a temporary CoLab file in JSON format\n",
        "print( \"Saving useful node list with algorithm tags:\", main_fname_algorithm_json)\n",
        "useful_info.save_nodes(main_fname_algorithm_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C__lVcEJlp1r"
      },
      "source": [
        "# Part 24: Test Addition Hypothesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-fBgNpAYTof"
      },
      "outputs": [],
      "source": [
        "num_hypothesis_clause_failures = 0\n",
        "num_hypothesis_clause_successes = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMVzWGdMuz_c"
      },
      "outputs": [],
      "source": [
        "def node_exists(the_nodes, the_filters):\n",
        "  global num_hypothesis_clause_failures\n",
        "  global num_hypothesis_clause_successes\n",
        "\n",
        "  matching_nodes = filter_nodes( the_nodes, the_filters)\n",
        "  num_nodes = len(matching_nodes)\n",
        "\n",
        "  if num_nodes > 0:\n",
        "    print( \"Clause succeeded on \", num_nodes, \"node(s) including\", matching_nodes[0].name(), \":\", the_filters.describe())\n",
        "    num_hypothesis_clause_successes += 1\n",
        "  else:\n",
        "    print( \"Clause failed:\", the_filters.describe())\n",
        "    num_hypothesis_clause_failures += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cmjOymxluQe"
      },
      "outputs": [],
      "source": [
        "# Get the model nodes with a known algorithmic purpose\n",
        "model_nodes = filter_nodes( useful_info.nodes, FilterAlgo(\"\", QuantaFilter.MAY))\n",
        "assert len(model_nodes) > 0\n",
        "\n",
        "if cfg.perc_add() > 0:\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    # For every answer digit (except the first 1 or 0 answer digit), Dn.BA and Dn.MC values are calculated before the answer digit is revealed\n",
        "    node_exists(model_nodes, FilterAnd(FilterAlgo(add_ba_tag(impact_digit)), FilterPosition(an_to_position_name(impact_digit+1), QuantaFilter.MUST_BY)))\n",
        "    node_exists(model_nodes, FilterAnd(FilterAlgo(add_mc_tag(impact_digit)), FilterPosition(an_to_position_name(impact_digit+1), QuantaFilter.MUST_BY)))\n",
        "\n",
        "    early_dnc = FilterAnd(FilterAlgo(add_tc_tag(impact_digit)), FilterPosition(an_to_position_name(cfg.n_digits+1), QuantaFilter.MUST_BY))\n",
        "    late_dnc = FilterAnd(FilterAlgo(add_tc_tag(impact_digit)), FilterPosition(an_to_position_name(impact_digit+1), QuantaFilter.MUST_BY))\n",
        "    any_dnus = FilterAnd(FilterAlgo(add_us_tag(impact_digit)), FilterPosition(an_to_position_name(impact_digit+1), QuantaFilter.MUST_BY))\n",
        "\n",
        "    if cfg.n_layers == 1:\n",
        "      # There must be a Dn.US node for every answer digit except A0\n",
        "      if impact_digit > 0:\n",
        "        node_exists(model_nodes, any_dnus)\n",
        "    else:\n",
        "      # There must be a Dn.US node or a Dn.C node for every digit except A0\n",
        "      if impact_digit > 0:\n",
        "        node_exists(model_nodes, FilterOr(any_dnus, late_dnc))\n",
        "\n",
        "      # There must a Dn.C node for every digit before the first 1 or 0 digit is calculated\n",
        "      node_exists(model_nodes, early_dnc)\n",
        "\n",
        "if cfg.perc_sub > 0:\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    # For every answer digit (except the first 1 or 0 answer digit), Dn.BS values are calculated before the answer digit is revealed\n",
        "    node_exists(model_nodes, FilterAnd(FilterAlgo(sub_bs_tag(impact_digit)), FilterPosition(an_to_position_name(impact_digit+1), QuantaFilter.MUST_BY)))\n",
        "\n",
        "\n",
        "print( \"Overall\", num_hypothesis_clause_successes, \"out of\", num_hypothesis_clause_successes + num_hypothesis_clause_failures, \"clauses succeeded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 30: Unit Test automated searches"
      ],
      "metadata": {
        "id": "6vxyIj1FP2Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unit_test_node_tag(node_location_as_str, the_tags ):\n",
        "  node_location = str_to_node_location(node_location_as_str)\n",
        "  node = useful_info.get_node(node_location)\n",
        "  assert node is not None\n",
        "\n",
        "  for the_tag in the_tags:\n",
        "    assert node.contains_tag( QuantaType.ALGO, the_tag)"
      ],
      "metadata": {
        "id": "f6g2-mZ5UeJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cfg.model_name)\n",
        "\n",
        "if cfg.model_name == \"add_d6_l2_h3_t15K\":\n",
        "  unit_test_node_tag(\"P11L0H0\", [\"D2.TC\"] )\n",
        "  unit_test_node_tag(\"P12L0H0\", [\"D3.TC\"] )\n",
        "  unit_test_node_tag(\"P14L0H0\", [\"A5.US\", \"D4.TC\"] )\n",
        "  unit_test_node_tag(\"P14L0H2\", [\"A5.MC\", \"D5.TC\"] )\n",
        "  unit_test_node_tag(\"P14L1H1\", [\"OP\"] )\n",
        "  unit_test_node_tag(\"P15L0H0\", [\"A4.MC\"] )\n",
        "  unit_test_node_tag(\"P15L0H1\", [\"A5.BA\"] )\n",
        "  unit_test_node_tag(\"P15L0H2\", [\"A5.BA\"] )\n",
        "  unit_test_node_tag(\"P16L0H0\", [\"A3.MC\"] )\n",
        "  unit_test_node_tag(\"P16L0H1\", [\"A4.BA\"] )\n",
        "  unit_test_node_tag(\"P16L0H2\", [\"A4.BA\"] )\n",
        "  unit_test_node_tag(\"P17L0H0\", [\"A2.MC\"] )\n",
        "  unit_test_node_tag(\"P17L0H1\", [\"A3.BA\"] )\n",
        "  unit_test_node_tag(\"P17L0H2\", [\"A3.BA\"] )\n",
        "  unit_test_node_tag(\"P18L0H0\", [\"A1.MC\"] )\n",
        "  unit_test_node_tag(\"P18L0H1\", [\"A2.BA\"] )\n",
        "  unit_test_node_tag(\"P18L0H2\", [\"A2.BA\"] )\n",
        "  unit_test_node_tag(\"P19L0H0\", [\"A0.MC\"] )\n",
        "  unit_test_node_tag(\"P19L0H1\", [\"A1.BA\"] )\n",
        "  unit_test_node_tag(\"P19L0H2\", [\"A1.BA\"] )\n",
        "  unit_test_node_tag(\"P20L0H1\", [\"A0.BA\"] )\n",
        "  unit_test_node_tag(\"P20L0H2\", [\"A0.BA\"] )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vr5SN-tuP1yO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "vNpIsCqtETtF",
        "aQNjIosyX9Y-",
        "P8RfHXneJw6n",
        "tz6rUaYvjOcE",
        "ZHiJhch4KCej",
        "-KJhCxFtNKfm",
        "I-yFKiDllqEf",
        "FyK7QeUjLLFm",
        "Lag8C3d_KkeQ",
        "nXBYdxj-jLZc",
        "2PjaQvhhayUL",
        "ZmsGWUbILYin",
        "3BmQHiLALp-3",
        "v7-99ZxDOrbF",
        "fHSY3blNMe7I",
        "Rbiau9foMp3h",
        "jIu3Pr9CMx3l",
        "IVkOJRmPvPms",
        "Z5DMV3I_25ST",
        "Iosx5zE_macF",
        "ThzFD1FxBXg8",
        "3jOBIUDzRrGz",
        "nVyItdhmhIn8",
        "sJo37Qg2ZQpJ",
        "Agw7np7gZmgP"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}