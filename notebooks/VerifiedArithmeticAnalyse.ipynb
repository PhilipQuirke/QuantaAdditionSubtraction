{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Verified Integer Mathematics in Transformers - Analyze the Model\n",
        "\n",
        "This Colab analyzes the behavior and algorithm sub-tasks performed by nodes in Transformer models.\n",
        "\n",
        "The models perform integer addition and/or subtraction e.g. 133357+182243=+0315600 and 123450-345670=-0123230. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens.\n",
        "\n",
        "This Colab follows on from https://github.com/PhilipQuirke/verified_transformers/blob/main/notebooks/VerifiedArithmeticTrain.ipynb which trained the models, and outputs model_name.pth and model_name_train.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries.\n",
        "\n",
        "Imports \"verified_transformer\" public library as \"qt\". This library is specific to this CoLab's \"QuantaTool\" approach to transformer analysis. Refer to [README.md](https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md) for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCdmr6-_Jkzi"
      },
      "outputs": [],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    !pip install matplotlib\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "    !pip install numpy\n",
        "    !pip install scikit-learn\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "    def setup_jupyter(install_libraries=False):\n",
        "        if install_libraries:\n",
        "            !pip install matplotlib==3.8.4\n",
        "            !pip install kaleido==0.2.1\n",
        "            !pip install transformer_lens==1.15.0\n",
        "            !pip install torchtyping==0.1.4\n",
        "            !pip install transformers==4.39.3\n",
        "\n",
        "            !pip install numpy==1.26.4\n",
        "            !pip install plotly==5.20.0\n",
        "            !pip install pytest==8.1.1\n",
        "            !pip install scikit-learn==1.4.1.post1\n",
        "\n",
        "        print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "        from IPython import get_ipython\n",
        "\n",
        "        ipython = get_ipython()\n",
        "        # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "        ipython.magic(\"load_ext autoreload\")\n",
        "        ipython.magic(\"autoreload 2\")\n",
        "\n",
        "    # setup_jupyter(install_libraries=True)   # Uncomment if you need to install libraries in notebook.\n",
        "    setup_jupyter(install_libraries=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUt2mMzFj7eA"
      },
      "outputs": [],
      "source": [
        "# Import Principal Component Analysis (PCA) library\n",
        "pca_lib_avail = True\n",
        "try:\n",
        "  from sklearn.decomposition import PCA\n",
        "except Exception as e:\n",
        "  print(\"pca import failed with exception:\", e)\n",
        "  pca_lib_avail = False\n",
        "\n",
        "  # Sometimes version conflicts means the PCA library does not import. This workaround partially fixes the issue\n",
        "  !pip install --upgrade numpy\n",
        "  !pip install --upgrade scikit-learn\n",
        "\n",
        "  # To complete workaround, now select menu option \"Runtime > Restart session and Run all\".\n",
        "  stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwekwkrdI6SX"
      },
      "outputs": [],
      "source": [
        "! pip uninstall QuantaTools -y || true   # Ensure a clean install."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2P3cndolKDM"
      },
      "outputs": [],
      "source": [
        "# Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md\n",
        "!pip install --upgrade git+https://github.com/PhilipQuirke/verified_transformers.git  # Specify @branch if testing a specific branch\n",
        "import QuantaTools as qt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to analyze?\n",
        "\n",
        "The existing model weightings created by the sister Colab [VerifiedArithmeticTrain](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/VerifiedArithmeticTrain.ipynb) are loaded from HuggingFace (in Part 5). Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"main\" configuration class. MathsConfig is derived from the chain AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = qt.MathsConfig()\n",
        "\n",
        "\n",
        "# Which model do we want to analyze? Uncomment one line:\n",
        "\n",
        "#cfg.model_name = \"\" # Use default configuration specified in cfg\n",
        "\n",
        "# Addition models\n",
        "#cfg.model_name = \"add_d5_l1_h3_t15K_s372001\"  # AddAccuracy=Two9s. Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions.\n",
        "#cfg.model_name = \"add_d5_l2_h3_t15K_s372001\"  # AddAccuracy=Six9s. AvgFinalLoss=1.6e-08\n",
        "#cfg.model_name = \"add_d6_l2_h3_t15K_s372001\"  # AddAccuracy=Six9s. AvgFinalLoss=1.7e-08. MAIN FOCUS\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s173289\"  # AddAccuracy=Six9s. AvgFinalLoss=1.5e-08\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s572091\"  # AddAccuracy=Six9s. AvgFinalLoss=7e-09\n",
        "#cfg.model_name = \"add_d5_l2_h3_t40K_s372001\"  # AddAccuracy=Six9s. AvgFinalLoss=2e-09. Fewest nodes\n",
        "#cfg.model_name = \"add_d6_l2_h3_t40K_s372001\"  # AddAccuracy=Six9s. AvgFinalLoss 2e-09. Fewest nodes\n",
        "#cfg.model_name = \"add_d10_l2_h3_t40K_s572091\" # AddAccuracy=Six9s. AvgFinalLoss=8e-09. (1/M fail: 0000000555+0000000445=+00000001000 ModelAnswer: +00000000900)\n",
        "\n",
        "# Subtraction model\n",
        "#cfg.model_name = \"sub_d6_l2_h3_t30K_s372001\"  # SubAccuracy=Six9s. AvgFinalLoss=5.8e-06\n",
        "#cfg.model_name = \"sub_d10_l2_h3_t75K_s173289\"  # SubAccuracy=Two9s. (6672/M fails) AvgFinalLoss=0.002002022\n",
        "\n",
        "# Mixed (addition and subtraction) model\n",
        "#cfg.model_name = \"mix_d6_l3_h4_t40K_s372001\"  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=5e-09. (1/M fail: 463687+166096=+0629783 ModelAnswer: +0639783)\n",
        "#cfg.model_name = \"mix_d10_l3_h4_t75K_s173289\"  # Add/SubAccuracy=Five9s/Two9s. AvgFinalLoss=1.125e-06 (2/M fail: 3301956441+6198944455=+09500900896 ModelAnswer: +09500800896) (295/M fail: 8531063649-0531031548=+08000032101 ModelAnswer: +07900032101)\n",
        "\n",
        "# Mixed models initialized with addition model\n",
        "cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s372001\"  # Add/SubAccuracy=Six9s/Six9s. AvgFinalLoss=8e-09. MAIN FOCUS\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s173289\"  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.4e-08. (3/M fails e.g. 850038+159060=+1009098 ModelAnswer: +0009098) (2 fails e.g. 77285-477285=+0100000 Q: ModelAnswer: +0000000).\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t50K_s572091\"  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=2.9e-08. (4/M fails e.g. 986887-286887=+0700000 ModelAnswer: +0600000)\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h3_t40K_s572091\"  # Add/SubAccuracy=Six9s/Five9s. AvgFinalLoss=1.7e-08. (3/M fails e.g. 072074-272074=-0200000 ModelAnswer: +0200000)\n",
        "#cfg.model_name = \"ins1_mix_d10_l3_h3_t50K_s572091\"  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss 6.3e-7  (6/M fails e.g. 5068283822+4931712829=+09999996651 ModelAnswer: +19099996651) (7/M fails e.g. 3761900218-0761808615=+03000091603 ModelAnswer: +02000091603)\n",
        "#cfg.model_name = \"ins1_mix_d6_l2_h3_t40K_s572091\"  # Add/SubAccuracy=Six9s/Five9s. AvgLoss = 2.4e-08 (5/M fails e.g. 565000-364538=+0200462 ModelAnswer: +0100462)\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h3_t80K_s572091\"  # Add/SubAccuracy=Six9s/Five9s AvgLoss = 1.6e-08 (3/M fails e.g. 229672-229678=-0000006 ModelAnswer: +0000006)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads every 100 epochs.\n",
        "#cfg.model_name = \"ins2_mix_d6_l4_h4_t40K_s372001\"  # Add/SubAccuracy=Five9s/Five9s. AvgFinalLoss=1.7e-08. (3/M fails e.g. 530757+460849=+0991606 ModelAnswer: +0091606) (8 fails e.g. 261926-161857=+0100069 ModelAnswer: +0000069)\n",
        "\n",
        "# Mixed model initialized with addition model. Reset useful heads & MLPs every 100 epochs.\n",
        "#cfg.model_name = \"ins3_mix_d6_l4_h3_t40K_s372001\"  # Add/SubAccuracy=Four9s/Two9s. AvgFinalLoss=3.0e-04. (17/M fails e.g. 273257+056745=+0330002 ModelAnswer: +0320002) (3120 fails e,g. 09075-212133=-0003058 ModelAnswer: +0003058)\n",
        "\n",
        "# Mixed models initialized with addition model.\n",
        "#cfg.model_name = \"ins4_mix_d6_l3_h4_t30K_s775824\"  # Add/SubAccuracy=???/???\n",
        "#cfg.model_name = \"ins4_mix_d6_l2_h4_t30K_s775824\"  # Add/SubAccuracy=???/???"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BiELcf53ms"
      },
      "outputs": [],
      "source": [
        "cfg.reset_useful()\n",
        "cfg.reset_algo()\n",
        "\n",
        "main_fname = cfg.file_config_prefix\n",
        "if cfg.model_name != \"\":\n",
        "  main_fname = cfg.model_name\n",
        "\n",
        "  # Update cfg member data n_digits, n_layers, n_heads, n_training_steps from model_name\n",
        "  cfg.parse_model_name()\n",
        "\n",
        "  cfg.batch_size = 512 # Default analysis batch size\n",
        "  if cfg.n_layers >= 3 and cfg.n_heads >= 4:\n",
        "    cfg.batch_size = 256 # Reduce batch size to avoid memory constraint issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "main_fname_pth = main_fname + '.pth'\n",
        "main_fname_train_json = main_fname + '_train.json'\n",
        "main_fname_behavior_json = main_fname + '_behavior.json'\n",
        "main_fname_maths_json = main_fname + '_maths.json'\n",
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfdCBTuqh4zq"
      },
      "outputs": [],
      "source": [
        "# Load additional training config information from say\n",
        "#      https://huggingface.co/PhilipQuirke/VerifiedArithmetic/raw/main/ins1_mix_d6_l3_h4_t40K_s372001_train.json\"\n",
        "training_data_class = None\n",
        "try:\n",
        "  url=\"https://huggingface.co/\"+main_repo_name+\"/raw/main/\"+main_fname_train_json\n",
        "  training_data = qt.download_json(url)\n",
        "  training_data_class = qt.load_training_json(training_data)\n",
        "\n",
        "  cfg.perc_mult = training_data_class.config.perc_mult\n",
        "  cfg.perc_sub = training_data_class.config.perc_sub\n",
        "\n",
        "  cfg.insert_late = training_data_class.config.insert_late\n",
        "  cfg.insert_n_layers = training_data_class.config.insert_n_layers\n",
        "  cfg.insert_n_heads = training_data_class.config.insert_n_heads\n",
        "  cfg.insert_training_seed = training_data_class.config.insert_training_seed\n",
        "  cfg.insert_n_training_steps = training_data_class.config.insert_n_training_steps\n",
        "\n",
        "  print('Loaded main model training config / loss from', url)\n",
        "except Exception as e:\n",
        "  print('Failed to load main model training config / loss. Analysis can still proceed.')\n",
        "  print(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_config():\n",
        "  print(\"%Add=\", cfg.perc_add, \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", main_fname)"
      ],
      "metadata": {
        "id": "lI4vY-vSxvxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_config()\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)\n",
        "print('Main model will be read from HuggingLab file', main_repo_name, main_fname_pth)\n",
        "print('Main model training config / loss will be read from HuggingLab file', main_fname_train_json)\n",
        "print('Main model behavior analysis tags will be saved to Colab temporary file', main_fname_behavior_json)\n",
        "print('Main model maths analysis tags will be saved to Colab temporary file', main_fname_maths_json)"
      ],
      "metadata": {
        "id": "f48_G6wr730Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Results: Model training loss graphs"
      ],
      "metadata": {
        "id": "keTceF_3zbVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.graph_file_suffix = \"pdf\" # Can be pdf, svg or png"
      ],
      "metadata": {
        "id": "SzwhtOfzuMYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the model final training loss and graph loss over epochs\n",
        "if training_data_class:\n",
        "  print( \"Avg loss over last 5 epochs\", training_data_class.avg_final_loss)\n",
        "  print( \"Final epoch loss\", training_data_class.final_loss)\n",
        "\n",
        "  answer_digits = cfg.n_digits + 1\n",
        "  font_size=32\n",
        "\n",
        "  qt.plot_loss_lines(cfg, 1500, [training_data_class.training_loss[:1500]], labels = ['All'], log_y=False, title='Training Loss', font_size=font_size)\n",
        "\n",
        "  full_title, fig = qt.plot_loss_lines(cfg, cfg.n_training_steps, [training_data_class.training_loss], labels = ['All'], log_y=True, title='Training Loss', font_size=font_size)\n",
        "  pio.write_image(fig, cfg.model_name + '_LogTrainingLoss.' + cfg.graph_file_suffix)"
      ],
      "metadata": {
        "id": "KYV9FWt3zfFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3A: Set Up: Vocabulary / Embedding / Unembedding\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeObQk2kzAv7"
      },
      "outputs": [],
      "source": [
        "cfg.initialize_maths_token_positions()\n",
        "qt.set_maths_vocabulary(cfg)\n",
        "qt.set_maths_question_meanings(cfg)\n",
        "print(cfg.token_position_meanings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6rUaYvjOcE"
      },
      "source": [
        "# Part 3B: Set Up: Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Transformer creation\n",
        "\n",
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = HookedTransformerConfig(\n",
        "    n_layers = cfg.n_layers,\n",
        "    n_heads = cfg.n_heads,\n",
        "    d_model = cfg.d_model,\n",
        "    d_head = cfg.d_head,\n",
        "    d_mlp = cfg.d_mlp,\n",
        "    act_fn = cfg.act_fn,\n",
        "    normalization_type = 'LN',\n",
        "    d_vocab = cfg.d_vocab,\n",
        "    d_vocab_out = cfg.d_vocab,\n",
        "    n_ctx = cfg.n_ctx,\n",
        "    init_weights = True,\n",
        "    device = \"cuda\",\n",
        "    seed = cfg.training_seed,\n",
        ")\n",
        "\n",
        "cfg.main_model = HookedTransformer(ht_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiJhch4KCej"
      },
      "source": [
        "# Part 4: Set Up: Loss Function & Data Generator\n",
        "This maths loss function and data generator are imported from QuantaTools as logits_to_tokens_loss, loss_fn, maths_data_generator_core and maths_data_generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqzljhQ4KJU5"
      },
      "outputs": [],
      "source": [
        "# Define \"iterator\" maths \"questions\" data generator function. Invoked using next().\n",
        "ds = qt.maths_data_generator( cfg )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtmioT1THbJA"
      },
      "outputs": [],
      "source": [
        "# Generate sample data generator (unit test)\n",
        "print(next(ds)[:3,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5: Set Up: Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0"
      },
      "outputs": [],
      "source": [
        "print(\"Loading model from HuggingFace\", main_repo_name, main_fname_pth)\n",
        "\n",
        "cfg.main_model.load_state_dict(utils.download_file_from_hf(repo_name=main_repo_name, file_name=main_fname_pth, force_is_torch=True))\n",
        "cfg.main_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS_zUfwrXl6P"
      },
      "source": [
        "# Part 7A: Set Up: Create sample maths questions\n",
        "\n",
        "Create a batch of manually-curated mathematics test questions, and cache some sample model prediction outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Kt5XD-XU9t"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"ablation intervention\" configuration class\n",
        "acfg = qt.acfg\n",
        "acfg.reset_ablate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiK-0P44gvfS"
      },
      "outputs": [],
      "source": [
        "varied_questions = qt.make_maths_test_questions_and_answers(cfg)\n",
        "num_varied_questions = varied_questions.shape[0]\n",
        "\n",
        "qt.a_set_ablate_hooks(cfg) # Updates acfg\n",
        "qt.a_calc_mean_values(cfg, varied_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5clJnASWCPVN"
      },
      "outputs": [],
      "source": [
        "print(\"Num questions:\", num_varied_questions, \"Question length:\", len(varied_questions[0]))\n",
        "print(\"Sample Question:\", varied_questions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6FwJW0tv4Nf"
      },
      "source": [
        "# Part 7B: Results: Can the model correctly predict sample questions?\n",
        "\n",
        "Ask the model to predict the varied_questions (without intervention) to see if the model gets them all right. Categorize answers by complexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E56siA_QKe0W"
      },
      "outputs": [],
      "source": [
        "# Test maths question prediction accuracy on the sample questions provided.\n",
        "# Does NOT use UsefulInfo.* information\n",
        "# Used to estimate the accuracy of the model's predictions.\n",
        "# Returns a reduced set of questions - removing questions that the model failed to answer.\n",
        "print_config()\n",
        "\n",
        "acfg.show_test_failures = True\n",
        "varied_questions = qt.test_maths_questions_by_complexity(cfg, acfg, varied_questions)\n",
        "acfg.show_test_failures = False\n",
        "\n",
        "num_varied_questions = varied_questions.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PjaQvhhayUL"
      },
      "source": [
        "# Part 9 : Results: Is the model 99.9999% accurate?\n",
        "\n",
        "The model's accuracy is 99.9999% (aka \"six 9s\") if it can predict one million questions with 0 or 1 failed predictions. If it has 2 to 10 failed predictions the model's accuracy is called 99.999% (aka \"five 9s\").\n",
        "\n",
        "Note: There may be very rare edge cases (say 1 in ten million) that did not appear in the test questions. So this empirical test can **not** prove 100% accuracy.\n",
        "\n",
        "If the model fails some questions, consider:\n",
        "- Adding a few of the failures into the \"test questions\" into qt.make_maths_test_questions_and_answers()\n",
        "- Understand the \"use case(s)\" driving these failures\n",
        "- Alter qt.maths_data_generator_core to enrich the training data with examples if these use case(s)\n",
        "- Retrain the model using the VerifiedArithmeticTrain Colab.  \n",
        "\n",
        "Takes ~25 mins to run for ins_mix_d6_l3_h4_t40K_s372001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znsauYqjaxok"
      },
      "outputs": [],
      "source": [
        "# When interested in this test, use num_questions=1000000. Else use num_questions=1000 for speed.\n",
        "acfg.show_test_failures = True\n",
        "qt.test_correctness_on_num_questions(cfg, acfg, num_questions = 1000) # = 1000000)\n",
        "acfg.show_test_failures = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXBYdxj-jLZc"
      },
      "source": [
        "# Part 10: Set Up: Which token positions are used by the model?\n",
        "\n",
        "Ablate all nodes in each (question and answer) token position (by overriding the model memory aka residual stream). If the model's prediction loss increases, the token position is useful to the algorithm. Unused token positions are excluded from further analysis. Used to populate the UsefulInfo.useful_positions data. This is token **position level** information.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGL57MRBLdUh"
      },
      "outputs": [],
      "source": [
        "num_failures_list = []\n",
        "acfg.show_test_failures = False\n",
        "\n",
        "for position in range(cfg.n_ctx):\n",
        "  # Test accuracy of model in predicting question answers. Ablates all nodes at acfg.ablate_position. Does NOT use UsefulInfo.* information.\n",
        "  num_fails = qt.test_maths_questions_by_impact(cfg, acfg, varied_questions, position, ablate=True)\n",
        "\n",
        "  if num_fails > 0:\n",
        "    # Add position to UsefulInfo.useful_positions\n",
        "    cfg.add_useful_position(position)\n",
        "    num_failures_list += [num_fails]\n",
        "  else:\n",
        "    num_failures_list += \".\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmsGWUbILYin"
      },
      "source": [
        "# Part 11: Results: Which token positions are used by the model?\n",
        "\n",
        "Which token positions are is used in the model's predictions? Unused token positions are excluded from further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpRp5YMmLe1y"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print(\"num_questions=\", num_varied_questions)\n",
        "print(\"useful_positions=\", cfg.useful_positions )\n",
        "print()\n",
        "\n",
        "cfg.calc_position_failures_map(num_failures_list)\n",
        "qt.save_plt_to_file(cfg=cfg, full_title=\"Failures When Position Ablated\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904WBkTOLg_5"
      },
      "source": [
        "# Part 12A: Set Up: Which nodes are used by the model?\n",
        "\n",
        "Here we ablate each (attention head and MLP neuron) node in each (question and answer) token position see if the model's prediction loss increases. If loss increases then the \"node + token position\" is used by the algorithm. Used to calculate the UsefulInfo.useful_node_location. This is **position+node level** information. Unused nodes are excluded from further analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as9ot9RMMTAi"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes = qt.UsefulNodeList()\n",
        "\n",
        "qt.ablate_mlp_and_add_useful_node_tags(cfg, varied_questions, qt.test_maths_questions_and_add_useful_node_tags)\n",
        "qt.ablate_head_and_add_useful_node_tags(cfg, varied_questions, qt.test_maths_questions_and_add_useful_node_tags)\n",
        "qt.add_node_attention_tags(cfg, varied_questions)\n",
        "\n",
        "cfg.useful_nodes.sort_nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw-Wteh-JBd6"
      },
      "source": [
        "# Part 12B: Results: Which nodes are used by the model?\n",
        "\n",
        "Here are the (attention head and MLP neuron) node in each (question and answer) token position used by the model during predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhEWUt7yJBuh"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.print_node_tags()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BmQHiLALp-3"
      },
      "source": [
        " # Part 13: Set up: Show and save Quanta map\n",
        "\n",
        " Using the UsefulNodes and filtering their tags, show a 2D map of the nodes and the tag minor versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emcB0_CpYTaJ"
      },
      "outputs": [],
      "source": [
        "def show_quanta_map( title, major_tag : qt.QType, minor_tag : str, get_node_details,\n",
        "        image_width_inches : int = -1, image_height_inches : int = -1,\n",
        "        blue_shades : bool = True, cell_num_shades : int = 6,\n",
        "        filters : qt.FilterNode = None, cell_fontsize : int = 9,\n",
        "        combine_identical_cells : bool = True, show_perc_circles : bool = False ):\n",
        "\n",
        "  test_nodes = cfg.useful_nodes\n",
        "  if filters is not None:\n",
        "    test_nodes = qt.filter_nodes(test_nodes, filters)\n",
        "\n",
        "  ax1, quanta_results, num_results = qt.calc_quanta_map(\n",
        "      cfg, blue_shades, cell_num_shades,\n",
        "      test_nodes, major_tag.value, minor_tag, get_node_details,\n",
        "      cell_fontsize, combine_identical_cells, show_perc_circles,\n",
        "      image_width_inches, image_height_inches )\n",
        "\n",
        "  if num_results > 0:\n",
        "    if cfg.graph_file_suffix > \"\":\n",
        "      print(\"Saving quanta map:\", title)\n",
        "      qt.save_plt_to_file(cfg=cfg, full_title=title)\n",
        "    else:\n",
        "      ax1.set_title(cfg.file_config_prefix() + ' ' + title + ' ({} nodes)'.format(len(quanta_results)))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkyhHRoMOSw"
      },
      "source": [
        "# Part 16A: Results: Show failure percentage map\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated. Lower percentages correspond to rarer edge cases. The grey space represents nodes that are not used by the model.\n",
        "\n",
        "A cell containing \"< 1\" may add some risk to the accuracy of the overall analysis process. Check to see if this represents a new use case. Improve the test data set to contain more instances of this (new or existing) use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ28dx5YLs0P"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Failure Frequency Behavior Per Node\", qt.QType.FAIL, \"\", qt.get_quanta_fail_perc,\n",
        "                cell_num_shades = qt.FAIL_SHADES, combine_identical_cells = False, show_perc_circles = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifmtnLoTCN5"
      },
      "source": [
        "# Part 16B - Show answer impact behavior map\n",
        "\n",
        "This map shows the answer digit(s) A0 .. An+1 impacted when we ablate each useful node in the  model. Cells containing values like A5..2 are used in multiple prediction steps to calculate multiple answer digits e.g. A2 to A5. Late token\n",
        "positions focus on predicting one answer digit - partially by using results calculated in early token positions.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K9PyCKYTUzX"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Answer Impact Behavior Per Node\", qt.QType.IMPACT, \"\", qt.get_quanta_impact,\n",
        "                cell_num_shades = cfg.num_answer_positions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avCfaCT1Puhz"
      },
      "source": [
        "# Part 16C: Result: Show attention map\n",
        "\n",
        "This map shows the input tokens each useful attention head attends to at each token position.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTGoEWHgvFH6"
      },
      "outputs": [],
      "source": [
        "# Only maps attention heads, not MLP layers\n",
        "show_quanta_map( \"Attention Behavior Per Head\", qt.QType.ATTN, \"\", qt.get_quanta_attention,\n",
        "                # image_height_inches = 8, # image_width_inches = 11,\n",
        "                cell_num_shades = qt.ATTN_SHADES )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7-99ZxDOrbF"
      },
      "source": [
        "# Part 16C - Show question complexity map\n",
        "\n",
        "This map shows whether each useful node is used\n",
        "to answer the quesstion classes: addition (S), positive-answer subtraction (M) and/or negative-answer subtraction (N) questions. In mixed models, nodes may be used in prediction of two or three questions classes. That is they are polysemantic.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKeybAj3d6QU"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  num_add, num_sub, num_neg, num_triple, num_double, num_single = qt.get_maths_nodes_operation_coverage(cfg.useful_nodes.nodes)\n",
        "  print( \"# useful nodes:\", len(cfg.useful_nodes.nodes))\n",
        "  print( \"# useful nodes involved in S, M, N operations:\", num_add, num_sub, num_neg )\n",
        "  print( \"# useful nodes involved in 3, 2, 1 operations:\", num_triple, num_double, num_single)\n",
        "  print()\n",
        "\n",
        "  # For each useful cell, show if addition (S), positive-answer subtraction (M) and negative-answer subtraction (N) questions relies on the node.\n",
        "  show_quanta_map( \"Maths Operation Coverage\", qt.QType.MATH, \"\", qt.get_maths_operation_complexity,\n",
        "                  blue_shades = False, cell_num_shades = 4, combine_identical_cells = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrxsi3TN7S0S"
      },
      "source": [
        "This map shows the simpliest (lowest complexity) addition quanta S0, S1, etc impacted when we ablate each node in an addition or mixed model. To answer S0 questions, only the S0 nodes are used. To answer S1 questions, S0 and S1 nodes are used, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyoErRoCA-pz"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add > 0:\n",
        "  # For each useful cell, show the minimum addition question complexity that relies on the node, as measured using quanta S0, S1, S2, ...\n",
        "  show_quanta_map( \"Addition Min-Complexity\", qt.QType.MATH_ADD, qt.MathsBehavior.ADD_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_ADD_SHADES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4DTadZo7e9a"
      },
      "source": [
        "This map shows the simpliest (lowest complexity) subtraction quanta M0, M1, etc impacted when we ablate each node in an subtraction or mixed model. To answer M0 questions, only the M0 nodes are used. To answer M1 questions, M0 and M1 nodes are used, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMZzbjxUBQGE"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show the minimum \"positive-answer subtraction\" question complexity that relies on the node, as measured using quanta M0, M1, M2, ...\n",
        "  show_quanta_map( \"Positive-answer Subtraction Min-Complexity\", qt.QType.MATH_SUB, qt.MathsBehavior.SUB_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_SUB_SHADES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUaT47ettc0M"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  # For each useful cell, show the minimum \"negative-answer subtraction\" question complexity that relies on the node, as measured using quanta N0, N1, N2, ...\n",
        "  show_quanta_map( \"Negative-answer Subtraction Min-Complexity\", qt.QType.MATH_NEG, qt.MathsBehavior.NEG_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity,\n",
        "                  blue_shades = False, cell_num_shades = qt.MATH_SUB_SHADES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbiau9foMp3h"
      },
      "source": [
        "# Part 19A: Results: Manual interpretation of PCA results\n",
        "\n",
        "Principal Component Analysis (PCA) is a powerful technique that aids in mechanistic interpretability by simplifying complex datasets into principal components that capture the most significant variance within the data.\n",
        "\n",
        "This library uses PCA to help understand the purpose of individual useful nodes. For more background refer https://github.com/PhilipQuirke/verified_transformers/blob/main/pca.md\n",
        "\n",
        "If an attention head and an answer digit An gives an interpretable response (2 or 3 distinct output clusters) on 3 groups of questions aligned to ST8, ST9 and ST10 definitions, then plot the response and add a PCA tag\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxlgEAPV1g7W"
      },
      "outputs": [],
      "source": [
        "# Create a cache of sample maths questions based on the T8, T9, T10 categorisation in cfg.tricase_questions_dict\n",
        "qt.make_maths_tricase_questions(cfg)\n",
        "\n",
        "cfg.useful_nodes.reset_node_tags(qt.QType.MATH_ADD.value, qt.MathsBehavior.ADD_PCA_TAG.value)\n",
        "cfg.useful_nodes.reset_node_tags(qt.QType.MATH_SUB.value, qt.MathsBehavior.SUB_PCA_TAG.value)\n",
        "cfg.useful_nodes.reset_node_tags(qt.QType.MATH_NEG.value, qt.MathsBehavior.NEG_PCA_TAG.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ5fS3XNMs8e"
      },
      "outputs": [],
      "source": [
        "# Plot all attention heads with the clearest An selected. Data is manually selected\n",
        "if pca_lib_avail:\n",
        "\n",
        "  if cfg.model_name == \"add_d5_l1_h3_t15K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[ 12, 0, 0, 4 ],\n",
        "      [ 12, 0, 2, 3 ],\n",
        "      [ 13, 0, 0, 3 ],\n",
        "      [ 14, 0, 0, 2 ],\n",
        "      [ 15, 0, 0, 1 ]])\n",
        "\n",
        "  elif cfg.model_name == \"add_d5_l2_h3_t15K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[10, 0, 0, 2 ],\n",
        "      [ 10, 0, 2, 1 ],\n",
        "      [ 12, 0, 0, 3 ],\n",
        "      [ 12, 1, 0, 3 ],\n",
        "      [ 12, 1, 1, 4 ],\n",
        "      [ 12, 1, 2, 4 ],\n",
        "      [ 13, 0, 0, 3 ],\n",
        "      [ 13, 1, 2, 2 ],\n",
        "      [ 14, 0, 0, 2 ],\n",
        "      [ 14, 1, 2, 2 ],\n",
        "      [ 15, 0, 0, 1 ],\n",
        "      [ 15, 1, 1, 1 ]])\n",
        "\n",
        "  elif cfg.model_name == \"add_d6_l2_h3_t15K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[11, 0, 1, 1 ], # EVR[0]=31% but needed for D1.ST\n",
        "      [ 11, 0, 0, 2 ],\n",
        "      [ 12, 0, 0, 3 ],\n",
        "      [ 13, 0, 0, 1 ],\n",
        "      [ 13, 0, 1, 0 ], # EVR[0]=32% but needed for D0.ST\n",
        "      [ 14, 0, 0, 4 ],\n",
        "      [ 14, 1, 1, 4 ],\n",
        "      [ 15, 0, 0, 4 ],\n",
        "      [ 15, 1, 1, 4 ],\n",
        "      [ 15, 1, 2, 4 ],\n",
        "      [ 16, 0, 0, 3 ],\n",
        "      [ 16, 1, 1, 3 ],\n",
        "      [ 17, 0, 0, 2 ],\n",
        "      [ 17, 1, 1, 2 ],\n",
        "      [ 18, 0, 0, 1 ]])\n",
        "\n",
        "\n",
        "  elif cfg.model_name == \"add_d6_l2_h3_t20K_s173289\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[ 14, 1, 0, 5 ],\n",
        "      [ 14, 1, 1, 4 ],\n",
        "      [ 14, 1, 2, 4 ],\n",
        "      [ 15, 1, 1, 4 ],\n",
        "      [ 15, 1, 2, 4 ],\n",
        "      [ 16, 1, 1, 3 ],\n",
        "      [ 16, 1, 2, 3 ],\n",
        "      [ 17, 1, 1, 2 ],\n",
        "      [ 18, 1, 1, 1 ]])\n",
        "\n",
        "  elif cfg.model_name == \"add_d6_l2_h3_t20K_s572091\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[ 10, 0, 0, 3 ],\n",
        "      [ 11, 0, 0, 2 ],\n",
        "      [ 12, 0, 0, 1 ],\n",
        "      [ 14, 0, 0, 4 ],\n",
        "      [ 14, 1, 0, 4 ],\n",
        "      [ 14, 1, 1, 4 ],\n",
        "      [ 14, 1, 2, 3 ],\n",
        "      [ 15, 0, 0, 4 ],\n",
        "      [ 15, 1, 0, 4 ],\n",
        "      [ 15, 1, 1, 4 ],\n",
        "      [ 15, 1, 2, 4 ],\n",
        "      [ 16, 0, 0, 3 ],\n",
        "      [ 16, 1, 0, 3 ],\n",
        "      [ 16, 1, 1, 3 ],\n",
        "      [ 17, 0, 0, 2 ],\n",
        "      [ 17, 1, 1, 2 ],\n",
        "      [ 18, 0, 0, 1 ]])\n",
        "\n",
        "  elif cfg.model_name == \"add_d10_l2_h3_t40K_s572091\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[ 20, 0, 0, 1 ],\n",
        "      [ 23, 1, 0, 8 ],\n",
        "      [ 24, 1, 0, 7 ],\n",
        "      [ 22, 1, 0, 8 ],\n",
        "      [ 25, 1, 0, 6 ],\n",
        "      [ 26, 1, 0, 5 ],\n",
        "      [ 27, 1, 0, 4 ],\n",
        "      [ 27, 1, 2, 4 ],\n",
        "      [ 28, 1, 0, 3 ],\n",
        "      [ 29, 1, 0, 2 ],\n",
        "      [ 30, 1, 0, 1 ]])\n",
        "\n",
        "  elif cfg.model_name.startswith(\"sub_d6_l2_h3_t30K\"):\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.MINUS,\n",
        "      [[ 9, 0, 1, 3 ],\n",
        "      [ 10, 0, 1, 2 ],\n",
        "      [ 11, 0, 1, 1 ],\n",
        "      [ 13, 0, 1, 4 ],\n",
        "      [ 13, 1, 2, 5 ],\n",
        "      [ 15, 0, 0, 5 ],\n",
        "      [ 15, 1, 1, 0 ],\n",
        "      [ 15, 1, 1, 1 ],\n",
        "      [ 15, 1, 1, 2 ],\n",
        "      [ 15, 1, 1, 3 ],\n",
        "      [ 15, 1, 1, 4 ],\n",
        "      [ 15, 1, 2, 0 ],\n",
        "      [ 15, 1, 2, 1 ],\n",
        "      [ 15, 1, 2, 2 ],\n",
        "      [ 15, 1, 2, 3 ],\n",
        "      [ 16, 0, 0, 0 ],\n",
        "      [ 16, 0, 0, 1 ],\n",
        "      [ 16, 0, 0, 2 ],\n",
        "      [ 16, 0, 0, 3 ],\n",
        "      [ 16, 0, 0, 4 ],\n",
        "      [ 16, 0, 0, 5 ],\n",
        "      [ 16, 1, 0, 4 ],\n",
        "      [ 16, 1, 1, 0 ],\n",
        "      [ 16, 1, 1, 1 ],\n",
        "      [ 16, 1, 1, 2 ],\n",
        "      [ 16, 1, 1, 3 ],\n",
        "      [ 16, 1, 1, 4 ],\n",
        "      [ 16, 1, 2, 0 ],\n",
        "      [ 16, 1, 2, 1 ],\n",
        "      [ 16, 1, 2, 2 ],\n",
        "      [ 16, 1, 2, 3 ],\n",
        "      [ 16, 1, 2, 4 ],\n",
        "      [ 16, 1, 2, 5 ],\n",
        "      [ 17, 0, 0, 0 ],\n",
        "      [ 17, 0, 0, 1 ],\n",
        "      [ 17, 0, 0, 2 ],\n",
        "      [ 17, 0, 0, 3 ],\n",
        "      [ 17, 1, 0, 3 ],\n",
        "      [ 17, 1, 0, 4 ],\n",
        "      [ 17, 1, 2, 4 ],\n",
        "      [ 18, 0, 0, 0 ],\n",
        "      [ 18, 0, 0, 1 ],\n",
        "      [ 18, 0, 0, 2 ],\n",
        "      [ 18, 1, 0, 2 ],\n",
        "      [ 18, 1, 2, 3 ],\n",
        "      [ 19, 0, 0, 0 ],\n",
        "      [ 19, 1, 2, 2 ],\n",
        "      [ 20, 0, 0, 0 ]])\n",
        "\n",
        "  elif cfg.model_name == \"mix_d6_l3_h4_t40K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[ 8, 1, 0, 4 ],\n",
        "      [ 11, 1, 0, 1 ],\n",
        "      [ 12, 1, 0, 0 ],\n",
        "      [ 13, 1, 1, 1 ],\n",
        "      [ 14, 2, 1, 5 ],\n",
        "      [ 15, 2, 1, 4 ],\n",
        "      [ 16, 2, 1, 3 ],\n",
        "      [ 17, 2, 1, 2 ],\n",
        "      [ 18, 1, 0, 4 ],\n",
        "      [ 18, 2, 1, 1 ]])\n",
        "\n",
        "  elif cfg.model_name == \"ins1_mix_d6_l3_h4_t40K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[10, 0, 0, 2 ],\n",
        "      [ 10, 0, 1, 2 ],\n",
        "      [ 11, 0, 0, 2 ],\n",
        "      [ 11, 0, 1, 1 ],\n",
        "      [ 13, 0, 1, 0 ],\n",
        "      [ 13, 1, 3, 1 ],\n",
        "      [ 14, 1, 2, 0 ],\n",
        "      [ 14, 1, 2, 2 ],\n",
        "      [ 14, 1, 3, 4 ],\n",
        "      [ 15, 0, 3, 5 ],\n",
        "      [ 15, 1, 2, 2 ],\n",
        "      [ 15, 1, 3, 4 ],\n",
        "      [ 16, 0, 3, 4 ],\n",
        "      [ 16, 1, 2, 0 ],\n",
        "      [ 16, 1, 2, 1 ],\n",
        "      [ 16, 1, 2, 2 ],\n",
        "      [ 16, 1, 3, 2 ],\n",
        "      [ 17, 0, 3, 3 ],\n",
        "      [ 17, 1, 2, 2 ],\n",
        "      [ 17, 1, 3, 2 ],\n",
        "      [ 18, 0, 3, 2 ],\n",
        "      [ 18, 1, 3, 1 ],\n",
        "      [ 19, 0, 3, 1 ],\n",
        "      [ 19, 2, 0, 0 ],\n",
        "      [ 19, 2, 1, 0 ],\n",
        "      [ 20, 0, 0, 0 ],\n",
        "      [ 20, 0, 3, 0 ]])\n",
        "\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.MINUS,\n",
        "      [[10, 0, 0, 2 ],\n",
        "      [ 10, 0, 1, 2 ],\n",
        "      [ 11, 0, 0, 2 ],\n",
        "      [ 11, 0, 1, 1 ],\n",
        "      [ 13, 0, 1, 0 ],\n",
        "      [ 14, 0, 0, 4 ],\n",
        "      [ 14, 0, 2, 5 ],\n",
        "      [ 14, 1, 2, 0 ],\n",
        "      [ 14, 1, 2, 2 ],\n",
        "      [ 14, 1, 3, 4 ]])\n",
        "\n",
        "  print('Finished generating plots')\n",
        "\n",
        "else:\n",
        "  print( \"PCA library failed to import. So PCA not done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIu3Pr9CMx3l"
      },
      "source": [
        "# Part 19B: Results: Automatic interpretation of PCA results (Optional)\n",
        "\n",
        "Part 19B is manual and selective. This part is automatic. It tests nodes not included in Part 19A, where this first (single) principal component explains 75% or more of the node. It adds a QType.PCA \"weak\" tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-8LlNMiqxyW"
      },
      "outputs": [],
      "source": [
        "do_auto_pca = False # Suppress for speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UADsW9c1g7X"
      },
      "outputs": [],
      "source": [
        "def auto_node_pca(ax, index, node_location, operation, answer_digit, evr_perc_threshold):\n",
        "\n",
        "    title, error_message = qt.maths_tools._build_title_and_error_message(\n",
        "        cfg=cfg, node_location=node_location, operation=operation, answer_digit=answer_digit\n",
        "    )\n",
        "\n",
        "    if (answer_digit, operation) in cfg.tricase_questions_dict:\n",
        "        test_inputs = cfg.tricase_questions_dict[(answer_digit, operation)]\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "    pca, pca_attn_outputs, title = qt.calc_pca_for_an(\n",
        "        cfg=cfg, node_location=node_location, title=title, error_message=error_message, test_inputs=test_inputs\n",
        "    )\n",
        "\n",
        "    if pca is not None:\n",
        "      perc = qt.pca_evr_0_percent(pca)\n",
        "      if perc > evr_perc_threshold:\n",
        "        qt.maths_tools.plot_pca_for_an(ax, pca_attn_outputs, title)\n",
        "\n",
        "        major_tag = qt.QType.MATH_ADD if operation == qt.MathsToken.PLUS else qt.QType.MATH_SUB # Does not handle NEG case\n",
        "        cfg.add_useful_node_tag( node_location, major_tag.value, qt.maths_tools.pca_op_tag(answer_digit, operation, False) )\n",
        "        return True\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDZ4--e11g7X"
      },
      "outputs": [],
      "source": [
        "def auto_find_pca_node(node, op, evr_perc_threshold):\n",
        "  # Allow up to 12 graphs\n",
        "  num_rows = 3\n",
        "  num_cols = 4\n",
        "\n",
        "  fig, axs = plt.subplots(num_rows, num_cols)\n",
        "  fig.set_figheight(4)\n",
        "  fig.set_figwidth(10)\n",
        "\n",
        "  index = 0\n",
        "  for answer_digit in range(cfg.n_digits+1):\n",
        "    ax = axs[index // num_cols, index % num_cols]\n",
        "    if auto_node_pca(ax, index, node, op, answer_digit, evr_perc_threshold):\n",
        "      index += 1\n",
        "\n",
        "  # Remove any graphs we dont need after all\n",
        "  index2 = index\n",
        "  while index2 < num_rows * num_cols:\n",
        "    ax = axs[index2 // num_cols, index2 % num_cols]\n",
        "    ax.remove()\n",
        "    index2 += 1\n",
        "\n",
        "  if index > 0:\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "  plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCYAud_Y1g7X"
      },
      "outputs": [],
      "source": [
        "def auto_find_pca(operation):\n",
        "  print(\"Automatic (weak) PCA tags for\", cfg.model_name, \"with operation\", qt.token_to_char(cfg, operation))\n",
        "  evr_perc_threshold = 75 # Generally use 75%. Have seen useful cells as low as 33%\n",
        "\n",
        "  for node in cfg.useful_nodes.nodes:\n",
        "\n",
        "    # Exclude nodes with a (manual) PCA tag - for any answer digit(s)). Exclude MLP neurons.\n",
        "    major_tag = qt.QType.MATH_ADD if operation == qt.MathsToken.PLUS else qt.QType.MATH_SUB # Does not handle NEG case\n",
        "    minor_tag_prefix = qt.MathsBehavior.ADD_PCA_TAG if operation == qt.MathsToken.PLUS else qt.MathsBehavior.SUB_PCA_TAG\n",
        "    if node.is_head and not node.contains_tag(major_tag.value, minor_tag_prefix.value):\n",
        "      print( \"Doing PCA on node\", node.name())\n",
        "\n",
        "      auto_find_pca_node(node, operation, evr_perc_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN2Mwk8Ip-pB"
      },
      "outputs": [],
      "source": [
        "if do_auto_pca:\n",
        "  if pca_lib_avail:\n",
        "    if cfg.perc_add > 0:\n",
        "      auto_find_pca(qt.MathsToken.PLUS)\n",
        "    if cfg.perc_sub > 0:\n",
        "      auto_find_pca(qt.MathsToken.MINUS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcCpfmKwlAH"
      },
      "source": [
        "# Part 20: Results: Show useful nodes and behaviour tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbzIaqmtwmkH"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.sort_nodes()\n",
        "cfg.useful_nodes.print_node_tags()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVkOJRmPvPms"
      },
      "source": [
        "# Part 21: Results: Save useful nodes and behaviour tags to json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naD2eCZevOsi"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the useful nodes list to a temporary CoLab file in JSON format\n",
        "print( \"Saving useful node list with behavior tags:\", main_fname_behavior_json)\n",
        "cfg.useful_nodes.save_nodes(main_fname_behavior_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAXc9bD2q0zC"
      },
      "source": [
        "# Part 22 : Results: Search for model algorithm tasks\n",
        "\n",
        "Here we find which model nodes perform which specific algorithm task.\n",
        "- **Automatic searches** for node purposes are preferred, as they applicable to several models, and survive (non-significant, node-reordering) differences between models caused by differences in training.\n",
        "- **Manually written tests** of node purposes, specific to a single model instance are also supported.\n",
        "\n",
        "The qt.search_and_tag searches for a task on useful nodes by:\n",
        "- **filtering** useful nodes, based on \"tag\" pre-requisites, to find the few nodes worth doing investigating. For more detail refer https://github.com/PhilipQuirke/verified_transformers/blob/main/filter.md\n",
        "- **intervention ablation** testing on the interesting nodes:\n",
        "  - The first \"store\" question is run without hooks\n",
        "  - The second \"clean\" question is run with hooks interjecting some data from the \"store\" run. This run gives, not a \"clean\" answer, but an \"intervened\" answer, which mixes the \"store\" answer and the \"clean\" answer. Our beliefs about the nodes algorthmic purpose are baked into the store question, clean question and intervened answer.\n",
        "- An **algorithm tag** is added to all interesting nodes that pass the intervention ablation test(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyVYckFtV-RV"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.reset_node_tags(qt.QType.ALGO.value)\n",
        "acfg.show_test_failures = False\n",
        "acfg.show_test_successes = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgg43Sqe8oF1"
      },
      "source": [
        "## Part 22B: Automated An.SS search\n",
        "\n",
        " Search for addition \"Use Sum 9\" (SS) tasks e.g. 34633+55555=+090188 where D4 and D'4 sum to 9 (4+5), and D3 + D'3 > 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUYf20mk8zls"
      },
      "outputs": [],
      "source": [
        "qt.search_and_tag( cfg, acfg, qt.add_ss_functions )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5DMV3I_25ST"
      },
      "source": [
        "## Part 22C: Automated An.SC search\n",
        "\n",
        "Search for addition \"Make Carry 1\" (SC) tasks e.g. 222222+666966=+0889188 where D2 + D'2 > 10.\n",
        "\n",
        "(Sometimes model chooses to use ST **instead** of SC. Sometimes model chooses to use ST **and** SC. For A1, model can **accurately** use just SC. For A0,  SC and ST are not needed.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvS1eOReZUq1"
      },
      "outputs": [],
      "source": [
        "#acfg.show_test_failures = True\n",
        "qt.search_and_tag( cfg, acfg, qt.add_sc_functions )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iosx5zE_macF"
      },
      "source": [
        "## Part 22D: Automated An.SA search\n",
        "\n",
        "Search for addition \"Simple Add\" (SA) tasks e.g. 555555+111111=+0666666 where D3 + D'3 < 10\n",
        "\n",
        "The SA tasks is sometimes split/shared over 2 attention heads in the same position and layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIktdaRL-BfP"
      },
      "outputs": [],
      "source": [
        "#acfg.show_test_failures = True\n",
        "qt.search_and_tag( cfg, acfg, qt.add_sa_functions,\n",
        "                  do_pair_search = True, allow_impact_mismatch = True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThzFD1FxBXg8"
      },
      "source": [
        "## Part 22E: Automated An.ST search\n",
        "\n",
        "Search for A0.ST to A5.ST with impact \"A65432\" to \"A65\" in early tokens.\n",
        "\n",
        "A0 and A1 are simple to calculate and so do NOT use An.ST or An.STm values. So A0 and A1 are excluded from the answer impact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFJV4pfWSwHQ"
      },
      "outputs": [],
      "source": [
        "qt.search_and_tag( cfg, acfg, qt.add_st_functions,\n",
        "                  do_pair_search = True, allow_impact_mismatch = True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jOBIUDzRrGz"
      },
      "source": [
        "## Part 22F: Automated An.MD search\n",
        "\n",
        "Search for positive-answer subtraction \"Difference\" (MD) tasks e.g. 666666-222222=+0444444 where D3 >= D'3\n",
        "\n",
        "The MD task may be split/shared over 2 attention heads in the same position at the same layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKag6sUnVS2N"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.sub_md_functions,\n",
        "                    do_pair_search = True, allow_impact_mismatch = True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVyItdhmhIn8"
      },
      "source": [
        "## Part 22G: Automated An.MB search\n",
        "\n",
        "Search for positive-answer subtraction \"Borrow One\" (MB) tasks e.g. 222222-111311=+0110911 where D2 > D'2\n",
        "\n",
        "(Sometimes model chooses to use MT **instead** of MB. Sometimes model chooses to use MT **and** MB. For A1, model can **accurately** use just MB. For A0,  MB and MT are not needed.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzjlFwEui7K9"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.sub_mb_functions,\n",
        "                    allow_impact_mismatch = True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJo37Qg2ZQpJ"
      },
      "source": [
        "## Part 22H: Automated An.MT search\n",
        "\n",
        "For accuracy, the addition algorithm calculates cascading \"carry one\" in early tokens using the An.ST sub-task. Paralleling this, the subtraction algorithm calculates cascading \"borrow one\" in early tokens using the An.MT sub-task.\n",
        "\n",
        "This section locates An.MT sub-tasks.\n",
        "\n",
        "Define An.MT = +1 if Dn > D'n else 0 if Dn == D'n else -1  \n",
        "The cascading \"borrow one\" calculation is then:\n",
        "A3.MV = fn(A3.MT, fn(A2.MT, fn(A1.MT, A0.MT)))\n",
        "where f(A,B) = +1 if A=1 or (A == 0 and B <> -1) else -1\n",
        "and the output \"-1\" means a cascading borrow one.\n",
        "\n",
        "The above fn could be simplified, but the (below) GT sub-task often relies on the above definition. The tricase An.MT definition also mirrors the addition An.ST definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOJ4J214g3La"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "    #acfg.show_test_failures = True\n",
        "    #acfg.show_test_successes = True\n",
        "    qt.search_and_tag( cfg, acfg, qt.sub_mt_functions,\n",
        "                      do_pair_search = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agw7np7gZmgP"
      },
      "source": [
        "## Part 22I: Automated OPR search\n",
        "\n",
        "For mixed models that do addition and subtraction the operation token \"+/-\" (in the middle of the question) is key. Find nodes that attend to the question operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0s2ZTMLimIR"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0 and cfg.perc_add > 0 :\n",
        "  qt.search_and_tag( cfg, acfg, qt.opr_functions )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztfj5n8FjYNt"
      },
      "source": [
        "## Part 22J: Automated SGN search\n",
        "\n",
        "For mixed models that do addition and subtraction, and for our subtraction models, the answer sign token \"+/-\" (at the start of the answer) is important. Find nodes that attend to the answer sign token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8smeZ3vBkIQ3"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.sgn_functions )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOVsZIpoQN_r"
      },
      "source": [
        "## Part 22K: Automated An.ND search\n",
        "\n",
        "Search for negative-answer subtraction Difference (ND) tasks e.g. 033333-111111=-077778 where D < D'\n",
        "\n",
        "The ND task may be split/shared over 2 attention heads in the same position at the same layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmBOMTeqRJXf"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.neg_nd_functions,\n",
        "                    do_pair_search = True, allow_impact_mismatch = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF4AjvfG2QDy"
      },
      "source": [
        "## Part 22L: Automated An.NB search\n",
        "\n",
        "Search for negative-answer subtraction Borrow One (NB) tasks e.g. 033333-111411=-078078 where D < D' and D2 < D'2\n",
        "\n",
        "(Sometimes model chooses to use NT **instead** of NB. Sometimes model chooses to use NT **and** NB.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvvtV6ZM48O4"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.neg_nb_functions,\n",
        "                    allow_impact_mismatch = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdWYQKi1Sr3M"
      },
      "source": [
        "## Part 22M: Automated An.GT search\n",
        "\n",
        "Both SUB (e.g. 00600-00201=+000399) and NEG (00100-00201=-000101) questions rely on knowing whether D > D'. How is this calculated?\n",
        "\n",
        "Approach 1: Model has specific GT nodes:\n",
        "Define An.GT = +1 if Dn > D'n else 0 if Dn = D'n else -1  \n",
        "When n_digits = 4, D > D' = f(A3.GT, fn(A2.GT, fn(A1.GT, A0.GT)))\n",
        "Where f(A,B) = +1 if A=1 or (A == 0 and B <> -1) else -1\n",
        "\n",
        "Approach 2: Model leverages the existing MT nodes:\n",
        "When n_digits = 4, D > D' = f(A3.MT, fn(A2.MT, fn(A1.MT, A0.MT)))\n",
        "where f(A,B) = +1 if A=1 or (A == 0 and B <> -1) else -1\n",
        "\n",
        "Usually, one node performs both say A3.MT and A3.GT sub-tasks, but in some models the A3.MT and A3.GT functions are performed by distinct nodes. Hence we test for the MT and GT behavior separately.\n",
        "\n",
        "Both approaches mirrors the calculation style used in ADD to calculate Amax as 1 or 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5f6Y2N-Vrry"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "    #acfg.show_test_successes = False\n",
        "    qt.search_and_tag(cfg, acfg, qt.sub_gt_functions,\n",
        "                      allow_impact_mismatch = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 22N: Automated An.SLT search (under development)\n",
        "\n",
        "Find attention nodes that do OPR and SGN attention and pick one of the 3 outputs of the An.SA/MD/ND node(s) and the An.SC/MB/NB node  "
      ],
      "metadata": {
        "id": "pOc3QuLOTuxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class mix_slt_functions(qt.SubTaskBaseMath):\n",
        "\n",
        "    @staticmethod\n",
        "    def operation():\n",
        "        return qt.MathsToken.DIV # Should be PLUS or MINUS but only supports one tag so return an \"never occurs\" value\n",
        "\n",
        "    @staticmethod\n",
        "    def tag(impact_digit):\n",
        "        return qt.answer_name(impact_digit)  + \".\" + qt.MathsTask.SLT_TAG.value\n",
        "\n",
        "    @staticmethod\n",
        "    def prereqs(cfg, position, impact_digit):\n",
        "        return qt.FilterAnd(\n",
        "              qt.FilterPosition(qt.position_name(position)),\n",
        "              qt.FilterHead(),\n",
        "              qt.FilterLayer(1), # PQR. Guess as layer 0 is fully described\n",
        "              qt.FilterImpact(qt.answer_name(impact_digit))) # Impacts Am\n",
        "\n",
        "    @staticmethod\n",
        "    def alter_digit_int(number_string, alter_digit):\n",
        "        return int(number_string[len(number_string)-alter_digit-1])\n",
        "\n",
        "    @staticmethod\n",
        "    def test_one(cfg, acfg, alter_digit, clean_data, store_data):\n",
        "        acfg.reset_ablate_layer_store()\n",
        "\n",
        "        acfg.operation = store_data[1]\n",
        "        store_question = store_data[0][:cfg.num_question_positions]\n",
        "        qt.a_predict_questions(cfg, store_question, acfg.attn_get_hooks)\n",
        "        store_answer_str = qt.int_to_answer_str(cfg, store_data[2])\n",
        "\n",
        "        acfg.operation = clean_data[1]\n",
        "        clean_question = clean_data[0][:cfg.num_question_positions]\n",
        "        clean_answer_str = qt.int_to_answer_str(cfg, clean_data[2])\n",
        "\n",
        "        # Predict \"test\" question overriding PnLmHp to give a bad answer\n",
        "        all_losses_raw, all_max_prob_tokens = qt.a_predict_questions(cfg, clean_question, acfg.attn_put_hooks)\n",
        "        if acfg.abort:\n",
        "            print(\"(Aborted)\")\n",
        "            return False\n",
        "        if all_losses_raw.shape[0] == 0:\n",
        "            acfg.abort = True\n",
        "            print(\"(Aborted on Bad all_losses_raw)\")\n",
        "            return False\n",
        "        loss_max = utils.to_numpy(qt.loss_fn(all_losses_raw[0]).max())\n",
        "        acfg.intervened_answer = qt.tokens_to_string(cfg, all_max_prob_tokens[0])\n",
        "        acfg.intervened_impact = qt.get_answer_impact( cfg, clean_answer_str, acfg.intervened_answer )\n",
        "        actual_intervened_digit = str(mix_slt_functions.alter_digit_int(acfg.intervened_answer, alter_digit))\n",
        "\n",
        "        # The intervetion impacted alter_digit, changing the digit to the stored version\n",
        "        success = (acfg.intervened_impact != \"\") # and (actual_intervened_digit == store_data[4])\n",
        "\n",
        "        if success:\n",
        "            store_str = qt.tokens_to_string(cfg, store_data[0][0])\n",
        "            clean_str = qt.tokens_to_string(cfg, clean_data[0][0])\n",
        "            print( \"  Test:\", len(acfg.ablate_node_locations), acfg.ablate_node_locations[0].name(), \"Store:\", store_data[3], store_str, store_data[4], \"Clean:\", clean_data[3], clean_str, clean_data[4], \"IntervenedAnswer:\", acfg.intervened_answer, acfg.intervened_impact, actual_intervened_digit)\n",
        "\n",
        "        return success\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    # Generate similar S, M and N questions that differ (as much as possible) only on operator and answer sign\n",
        "    def generate_test_data(cfg, acfg, alter_digit, test_value, first_repeat_digit = 2):\n",
        "        if test_value == 0:\n",
        "          return [], [], []\n",
        "\n",
        "        q_part_1 = cfg.repeat_digit(first_repeat_digit)\n",
        "        q_part_2 = cfg.repeat_digit(1) + (test_value-1) * 10 ** alter_digit # Breaks if test_value is 0\n",
        "\n",
        "        # A: addition 22222+11191=+033413.\n",
        "        s_question = [q_part_1, q_part_2]\n",
        "        s_answer = s_question[0] + s_question[1]\n",
        "        s_question_and_answer = qt.make_maths_questions_and_answers(cfg, qt.MathsToken.PLUS, qt.QType.MATH_ADD, qt.MathsBehavior.UNKNOWN, [s_question])\n",
        "        s_answer_str = str(abs(s_answer))\n",
        "        s_data = [s_question_and_answer, qt.MathsToken.PLUS, s_answer, \"S\", mix_slt_functions.alter_digit_int(s_answer_str,alter_digit) ]\n",
        "        assert( s_answer > 0 )\n",
        "\n",
        "        # M: positive-answer subtraction 22222-11191=+011031.\n",
        "        m_question = [q_part_1, q_part_2]\n",
        "        m_answer = m_question[0] - m_question[1]\n",
        "        m_question_and_answer = qt.make_maths_questions_and_answers(cfg, qt.MathsToken.MINUS, qt.QType.MATH_SUB, qt.MathsBehavior.UNKNOWN, [m_question])\n",
        "        m_answer_str = str(abs(m_answer))\n",
        "        m_data = [m_question_and_answer, qt.MathsToken.MINUS, m_answer, \"M\", mix_slt_functions.alter_digit_int(m_answer_str,alter_digit)  ]\n",
        "        assert( m_answer > 0 )\n",
        "\n",
        "        # N: negative-answer subtraction 02222-11191=-08969\n",
        "        n_question = [q_part_1 - first_repeat_digit * 10 ** (cfg.n_digits-1), q_part_2]\n",
        "        n_answer = n_question[0] - n_question[1]\n",
        "        n_question_and_answer = qt.make_maths_questions_and_answers(cfg, qt.MathsToken.MINUS, qt.QType.MATH_NEG, qt.MathsBehavior.UNKNOWN, [n_question])\n",
        "        n_answer_str = str(abs(n_answer))\n",
        "        n_data = [n_question_and_answer, qt.MathsToken.MINUS, n_answer, \"N\", mix_slt_functions.alter_digit_int(n_answer_str,alter_digit)  ]\n",
        "        assert( n_answer < 0 )\n",
        "\n",
        "        return s_data, m_data, n_data\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    # Generate similar S, M and N questions. Intervene on all 6 combinations of 2 of them. Test impact\n",
        "    def test(cfg, acfg, alter_digit, strong):\n",
        "        if alter_digit >= cfg.n_digits - 1: # For now exclude the top digit as assert( m_answer > 0 ) fails\n",
        "            acfg.reset_intervention()\n",
        "            return False\n",
        "\n",
        "        s_data, m_data, n_data = mix_slt_functions.generate_test_data(cfg, acfg, alter_digit, 9)\n",
        "\n",
        "        num_success = 0\n",
        "\n",
        "        # Context: acfg.ablate_node_locations\n",
        "        num_success += mix_slt_functions.test_one( cfg, acfg, alter_digit, s_data, m_data )\n",
        "        num_success += mix_slt_functions.test_one( cfg, acfg, alter_digit, s_data, n_data )\n",
        "        num_success += mix_slt_functions.test_one( cfg, acfg, alter_digit, m_data, s_data)\n",
        "        num_success += mix_slt_functions.test_one( cfg, acfg, alter_digit, m_data, n_data )\n",
        "        num_success += mix_slt_functions.test_one( cfg, acfg, alter_digit, n_data, s_data )\n",
        "        num_success += mix_slt_functions.test_one( cfg, acfg, alter_digit, n_data, m_data )\n",
        "\n",
        "        success = num_success >= 1\n",
        "        if success:\n",
        "            print( \"Success\", acfg.ablate_node_names, \"perform\", mix_slt_functions.tag(alter_digit), num_success)\n",
        "\n",
        "        return success\n"
      ],
      "metadata": {
        "id": "acOyBly5MlyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class test_mix_slt_functions(mix_slt_functions):\n",
        "\n",
        "    @staticmethod\n",
        "    # Unit test for generate_test_data\n",
        "    def test_generate_test_data(cfg, acfg):\n",
        "        for test_value in range(10):\n",
        "            if test_value != 0: # Zero is not a good value to test with\n",
        "                s_data, m_data, n_data = mix_slt_functions.generate_test_data(cfg, acfg, 1, test_value)\n",
        "\n",
        "                assert( s_data[2] > 0 )\n",
        "                assert( s_data[3] == \"S\" )\n",
        "                if test_value== 9:\n",
        "                    assert( s_data[4] == 1 )\n",
        "\n",
        "                assert( m_data[2] > 0 )\n",
        "                assert( m_data[3] == \"M\" )\n",
        "                if test_value== 9:\n",
        "                    assert( m_data[4] == 3 )\n",
        "\n",
        "                assert( n_data[2] < 0 )\n",
        "                assert( n_data[3] == \"N\" )\n",
        "                if test_value== 9:\n",
        "                    assert( n_data[4] == 6 )\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def test_generate_test_data_part2(cfg, acfg):\n",
        "\n",
        "        columns = [\"Alter Digit\", \"Test Value\", \"S\", \"M\", \"N\", \"(4-S)%10=M\", \"(S+5)%10=N\"]\n",
        "\n",
        "        data = []\n",
        "        for alter_digit in range(cfg.n_digits - 1):\n",
        "            for test_value in range(10):\n",
        "                if test_value != 0: # Zero is not a good value to test with\n",
        "                    s_data, m_data, n_data = mix_slt_functions.generate_test_data(cfg, acfg, alter_digit, test_value)\n",
        "\n",
        "                    if alter_digit == 2 and test_value == 9:\n",
        "                      print( \"Questions of form:\", qt.tokens_to_string(cfg, s_data[0][0]), qt.tokens_to_string(cfg, m_data[0][0]), qt.tokens_to_string(cfg, s_data[0][0]))\n",
        "\n",
        "                    s_to_m = (4 - s_data[4]) % 10 == m_data[4]\n",
        "                    s_to_n = (s_data[4] + 5) % 10 == n_data[4]\n",
        "                    data += [[str(alter_digit), str(test_value), str(s_data[4]), str(m_data[4]), str(n_data[4]), str(s_to_m), str(s_to_n)]]\n",
        "            data += [[\"\", \"\", \"\", \"\", \"\", \"\", \"\"]]\n",
        "\n",
        "        _, ax = plt.subplots(figsize=(10,6))\n",
        "        ax.axis('off')\n",
        "\n",
        "        table = ax.table(cellText=data, colLabels=columns, loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def test_generate_test_data_part3(cfg, acfg, first_repeat_digit):\n",
        "\n",
        "        num_tests = 0\n",
        "        num_successes = 0\n",
        "        for alter_digit in range(cfg.n_digits - 1):\n",
        "            for test_value in range(10):\n",
        "                if test_value != 0: # Zero is not a good value to test with\n",
        "                    s_data, m_data, n_data = mix_slt_functions.generate_test_data(cfg, acfg, alter_digit, test_value, first_repeat_digit)\n",
        "\n",
        "                    s_str = qt.tokens_to_string(cfg, s_data[0][0])\n",
        "                    m_str = qt.tokens_to_string(cfg, m_data[0][0])\n",
        "                    n_str = qt.tokens_to_string(cfg, n_data[0][0])\n",
        "\n",
        "                    s_digit = mix_slt_functions.alter_digit_int(s_str, alter_digit)\n",
        "                    m_digit = mix_slt_functions.alter_digit_int(m_str, alter_digit)\n",
        "                    n_digit = mix_slt_functions.alter_digit_int(n_str, alter_digit)\n",
        "\n",
        "                    s_to_m = (4 - s_digit) % 10\n",
        "                    s_to_n = (s_digit + 5) % 10\n",
        "\n",
        "                    num_tests += 1\n",
        "                    if s_to_m == m_digit and s_to_n == n_digit:\n",
        "                        num_successes += 1\n",
        "                    else:\n",
        "                        print( \"A\"+str(alter_digit), \"test_value\", test_value, \"S:\", s_str, \"M:\", m_str, \"N:\", n_str, \"S->M:\", s_to_m, \"S->N:\", s_to_n)\n",
        "\n",
        "        print( \"Num Tests:\", num_tests, \"Num Successes:\", num_successes)"
      ],
      "metadata": {
        "id": "gQ5ycyFCvkw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    test_mix_slt_functions.test_generate_test_data(cfg, acfg)"
      ],
      "metadata": {
        "id": "9ulSsdbvcLLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There is a simple bigram mapping from S to M. That is (4 - S) % 10 => M\n",
        "# There is a simple bigram mapping from S to N. That is (S + 5) % 10 => N\n",
        "# Q: Do L0 nodes do S, and L1 nodes do this mapping?\n",
        "#     Q: Do L0 nodes just do S?\n",
        "if False:\n",
        "    test_mix_slt_functions.test_generate_test_data_part2(cfg, acfg)"
      ],
      "metadata": {
        "id": "iWF-P_Pqdmxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    test_mix_slt_functions.test_generate_test_data_part3(cfg, acfg, first_repeat_digit=2)\n",
        "    test_mix_slt_functions.test_generate_test_data_part3(cfg, acfg, first_repeat_digit=3)"
      ],
      "metadata": {
        "id": "SU72j19c0XiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    cfg.useful_nodes.reset_node_tags(qt.QType.ALGO.value, qt.MathsTask.SLT_TAG.value)\n",
        "\n",
        "    acfg.reset_intervention_totals()\n",
        "    acfg.operation = mix_slt_functions.operation()\n",
        "    acfg.show_test_failures = False\n",
        "    acfg.show_test_successes = True\n",
        "    the_impact_digit = 2\n",
        "    position = 18\n",
        "\n",
        "    the_tag = mix_slt_functions.tag(the_impact_digit)\n",
        "\n",
        "    the_filters = mix_slt_functions.prereqs(cfg, position, the_impact_digit)\n",
        "\n",
        "    # Filter useful nodes as per callers prerequisites\n",
        "    test_nodes = qt.filter_nodes( cfg.useful_nodes, the_filters)\n",
        "\n",
        "    # Do not test nodes that already have the search tag assigned (perhaps from a previous search run)\n",
        "    test_nodes = qt.filter_nodes( test_nodes, qt.FilterAlgo(the_tag, qt.QCondition.NOT))\n",
        "\n",
        "    num_test_nodes = len(test_nodes.nodes)\n",
        "    print(num_test_nodes)\n",
        "    #qt.search_and_tag_digit_position(cfg, acfg, the_impact_digit, test_nodes, mix_slt_functions, strong=False, the_tag=the_tag, do_pair_search=False )\n",
        "\n",
        "    #node = test_nodes.nodes[0]\n",
        "    for node in test_nodes.nodes:\n",
        "        acfg.ablate_node_locations = [node]\n",
        "        if mix_slt_functions.test(cfg, acfg, the_impact_digit, False):\n",
        "            full_tag = the_tag + (\"\" if False else \".\" + acfg.intervened_impact)\n",
        "            acfg.num_tags_added += node.add_tag(qt.QType.ALGO.value, full_tag)"
      ],
      "metadata": {
        "id": "0V_MgP4MhwZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if False:\n",
        "    if cfg.perc_sub > 0 and cfg.perc_add > 0 :\n",
        "        qt.search_and_tag(cfg, acfg, mix_slt_functions,\n",
        "                      allow_impact_mismatch=False, do_pair_search=False)"
      ],
      "metadata": {
        "id": "7NDkmElOcNfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQLfkdlbVAl_"
      },
      "source": [
        "# Part 23: Show algorithm quanta map\n",
        "\n",
        "This map shows a compacted view of all useful token positions (horizontally) and all useful attention heads and MLP layers\n",
        "(vertically) used in predictions as blue cells. In each cell, the algorithm sub-task(s) Base Add SA, Make Carry SC, TriCase ST, etc found by automated search with ablation testing are shown.\n",
        "\n",
        "Sometimes a subtask is logIcally shared across two attention heads. The SA, MD and ND subtasks sometimes do this.\n",
        "\n",
        "This map plots the \"algorithm\" tags generated in previous steps as a quanta map. This is an automatically generated partial explanation of the model algorithm.\n",
        "\n",
        "Nodes with multiple tags were tagged (found) by more than one of the above subtask searches."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If a cell only has an OPR tag or only has a SGN tag then we do not understood its purpose.\n",
        "# The tag is just an \"attention\" fact. Remove these tags from the algorithm map\n",
        "# (A cell that has both OPR and SGN tags, we believe it is a \"Select question case\" node. We keep it)\n",
        "for node in cfg.useful_nodes.nodes:\n",
        "    tags = node.filter_tags(qt.QType.ALGO.value)\n",
        "    if len(tags) == 1:\n",
        "        only_tag = tags[0]\n",
        "        if qt.MathsTask.OPR_TAG.value in only_tag or qt.MathsTask.SGN_TAG.value in only_tag:\n",
        "            print( \"Removing\", node.name(), only_tag)\n",
        "            node.reset_tags(qt.QType.ALGO.value)"
      ],
      "metadata": {
        "id": "Q4bvm3yzQ8Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCHcurqILvtN"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "qt.print_algo_purpose_results(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRWSKaURK1L2"
      },
      "outputs": [],
      "source": [
        "# Show useful nodes that have identified algorithm sub-task tags\n",
        "show_quanta_map( \"Maths Purpose Per Node\", qt.QType.ALGO, \"\", qt.get_quanta_binary,\n",
        "                 #image_width_inches = 8, image_height_inches = 2,\n",
        "                 cell_num_shades = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9VDbjTAVGrP"
      },
      "outputs": [],
      "source": [
        "# Show ALL useful nodes with their algorithm sub-task tags (if any)\n",
        "show_quanta_map( \"Maths Purpose All Nodes\", qt.QType.IMPACT, \"\", qt.get_quanta_algo,\n",
        "                 #image_width_inches = 8, image_height_inches = 4,\n",
        "                 cell_num_shades = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_m3qiWYrjRJ"
      },
      "source": [
        "# Part 24: Show known quanta per answer digit\n",
        "\n",
        "Each of the late positions are soley focused on calculating one answer digit. Show the data have we collected on late answer digit.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT8zKdHz1-fZ"
      },
      "outputs": [],
      "source": [
        "for position in range(cfg.num_question_positions + 1, cfg.n_ctx - 1):\n",
        "  print(\"Position:\", position)\n",
        "\n",
        "  # Calculate a table of the known quanta for the specified position for each late token position\n",
        "  qt.calc_maths_quanta_for_position_nodes(cfg, position)\n",
        "\n",
        "  qt.save_plt_to_file(cfg=cfg, full_title=\"Quanta At \"+ qt.position_name(position))\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 25: Compare ST and SC\n",
        "The sub-tasks ST and SC are similar: They both take Dn,D'n inputs (10x10) and generate \"carry one\" outputs. They differ in that ST occurs in early tokens and has tri-state output, whereas SC occurs in late tokens and has bi-state output. For a sample mixed model, this figure shows PCA results comparing ST and SC output for A2 and A3."
      ],
      "metadata": {
        "id": "jux5CWRZ7XDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if cfg.perc_add > 0 and cfg.n_layers >= 2:\n",
        "    a2st = cfg.useful_nodes.get_node_by_tag(qt.QType.ALGO.value, \"A2.ST\")\n",
        "    a2sc = cfg.useful_nodes.get_node_by_tag(qt.QType.ALGO.value, \"A2.SC\")\n",
        "    a3st = cfg.useful_nodes.get_node_by_tag(qt.QType.ALGO.value, \"A3.ST\")\n",
        "    a3sc = cfg.useful_nodes.get_node_by_tag(qt.QType.ALGO.value, \"A3.SC\")\n",
        "\n",
        "    #qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "    #  [[ 10, 0, 1, 2 ], # A2.ST Trigram?\n",
        "    #  [ 17, 0, 0, 2 ],  # A2.SC Bigram needed (Trigram okay)\n",
        "    #  [ 12, 0, 1, 3 ],  # A3.ST Trigram?\n",
        "    #  [ 16, 0, 0, 3 ]]) # A3.SC Bigram needed (Trigram okay)\n",
        "\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "        [a2st, # A2.ST Trigram?\n",
        "        a2sc,  # A2.SC Bigram needed (Trigram okay)\n",
        "        a3st,  # A3.ST Trigram?\n",
        "        a3sc]) # A3.SC Bigram needed (Trigram okay)\n"
      ],
      "metadata": {
        "id": "sp54DotP7aLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhheXmLTUfc"
      },
      "source": [
        "# Part 26: Save useful nodes with behaviour and algorithm tags to JSON file\n",
        "\n",
        "Show a list of the nodes that have proved useful in calculations, together with data on the nodes behavior and algorithmic purposes.\n",
        "Save the data to a Colab temporary JSON file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRW6tiM8hDOB"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.print_node_tags(qt.QType.ALGO.value, \"\", False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ktlEftAOyEd"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the useful nodes list with maths tags to a temporary CoLab file in JSON format\n",
        "print( \"Saving useful node list with maths tags:\", main_fname_maths_json)\n",
        "cfg.useful_nodes.save_nodes(main_fname_maths_json, qt.QType.ALGO.value)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "F_IIpX2H2tNe",
        "P8RfHXneJw6n",
        "ZHiJhch4KCej",
        "-KJhCxFtNKfm",
        "qS_zUfwrXl6P",
        "D6FwJW0tv4Nf",
        "2PjaQvhhayUL",
        "904WBkTOLg_5",
        "Rw-Wteh-JBd6",
        "3BmQHiLALp-3",
        "jIu3Pr9CMx3l",
        "jFcCpfmKwlAH",
        "IVkOJRmPvPms",
        "Iosx5zE_macF",
        "ThzFD1FxBXg8",
        "3jOBIUDzRrGz",
        "nVyItdhmhIn8",
        "sJo37Qg2ZQpJ",
        "Agw7np7gZmgP",
        "ztfj5n8FjYNt",
        "GOVsZIpoQN_r",
        "UF4AjvfG2QDy",
        "fdWYQKi1Sr3M",
        "LQhheXmLTUfc"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}