{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG2gZSoSJD5C"
      },
      "source": [
        "# Verified Integer Mathematics in Transformers - Analyse the Model\n",
        "\n",
        "This CoLab analyses a Transformer model that performs integer addition, subtraction and multiplication e.g. 133357+182243=+0315600, 123450-345670=-0123230 and 000345*000823=+283935. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzkGrSqHJKqN"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTd3nmsMJV5T"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries.\n",
        "\n",
        "Imports \"verified_transformer\" public library as \"qt\". This library is specific to this CoLab's \"QuantaTool\" approach to transformer analysis. Refer to [README.md](https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md) for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCdmr6-_Jkzi"
      },
      "outputs": [],
      "source": [
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    !pip install matplotlib\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "    !pip install numpy\n",
        "    !pip install scikit-learn\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "    def setup_jupyter(install_libraries=False):\n",
        "        if install_libraries:\n",
        "            !pip install matplotlib==3.8.4\n",
        "            !pip install kaleido==0.2.1\n",
        "            !pip install transformer_lens==1.15.0\n",
        "            !pip install torchtyping==0.1.4\n",
        "            !pip install transformers==4.39.3\n",
        "\n",
        "            !pip install numpy==1.26.4\n",
        "            !pip install plotly==5.20.0\n",
        "            !pip install pytest==8.1.1\n",
        "            !pip install scikit-learn==1.4.1.post1\n",
        "\n",
        "        print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "        from IPython import get_ipython\n",
        "\n",
        "        ipython = get_ipython()\n",
        "        # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "        ipython.magic(\"load_ext autoreload\")\n",
        "        ipython.magic(\"autoreload 2\")\n",
        "\n",
        "    # setup_jupyter(install_libraries=True)   # Uncomment if you need to install libraries in notebook.\n",
        "    setup_jupyter(install_libraries=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up2QLAZLJnG9"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve-TndERJoaJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6zOEFryJqGN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "import re\n",
        "from enum import Enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6TE7A9SxySA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8VQ4e0QJsIB"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUt2mMzFj7eA"
      },
      "outputs": [],
      "source": [
        "# Import Principal Component Analysis (PCA) library\n",
        "use_pca = True\n",
        "try:\n",
        "  from sklearn.decomposition import PCA\n",
        "except Exception as e:\n",
        "  print(\"pca import failed with exception:\", e)\n",
        "  use_pca = False\n",
        "\n",
        "  # Sometimes version conflicts means the PCA library does not import. This workaround partially fixes the issue\n",
        "  !pip install --upgrade numpy\n",
        "  !pip install --upgrade scikit-learn\n",
        "\n",
        "  # To complete workaround, now select menu option \"Runtime > Restart session and Run all\".\n",
        "  stop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwekwkrdI6SX"
      },
      "outputs": [],
      "source": [
        "! pip uninstall QuantaTools -y || true   # Ensure a clean install."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2P3cndolKDM"
      },
      "outputs": [],
      "source": [
        "# Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md\n",
        "!pip install --upgrade git+https://github.com/PhilipQuirke/verified_transformers.git  # Specify @branch if testing a specific branch\n",
        "import QuantaTools as qt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGPkaokJQM5"
      },
      "source": [
        "# Part 1A: Configuration\n",
        "\n",
        "Which existing model do we want to analyse?\n",
        "\n",
        "The existing model weightings created by the sister Colab [VerifiedArithmeticTrain](https://github.com/PhilipQuirke/transformer-maths/blob/main/assets/VerifiedArithmeticTrain.ipynb) are loaded from HuggingFace (in Part 5). Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/README.md for more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmjGdFcdJat3"
      },
      "outputs": [],
      "source": [
        "# Singleton QuantaTool \"main\" configuration class. MathsConfig is derived from the chain AlgoConfig > UsefulConfig > ModelConfig\n",
        "cfg = qt.MathsConfig()\n",
        "\n",
        "# Singleton QuantaTool \"ablation intervention\" configuration class\n",
        "acfg = qt.acfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1DXZQ2E6yAi"
      },
      "outputs": [],
      "source": [
        "# Which model do we want to analyse? Uncomment one line:\n",
        "\n",
        "#cfg.model_name = \"\" # Use configuration specified in cfg defaults\n",
        "\n",
        "#cfg.model_name = 5-digit and 6-digit digit Addition models\n",
        "#cfg.model_name = \"add_d5_l1_h3_t15K_s372001\"  # Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions.\n",
        "#cfg.model_name = \"add_d5_l2_h3_t15K_s372001\"  # AvgFinalLoss=1.6e-08. Accurate on 1M Qs\n",
        "cfg.model_name = \"add_d6_l2_h3_t15K_s372001\"  # AvgFinalLoss=1.7e-08. Accurate on 1M Qs\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s173289\"  # AvgFinalLoss=1.5e-08. Accurate on 1M Qs\n",
        "#cfg.model_name = \"add_d6_l2_h3_t20K_s572091\"  # AvgFinalLoss=7e-09. Accurate on 1M Qs\n",
        "\n",
        "# 6-digit Subtraction model\n",
        "#cfg.model_name = \"sub_d6_l2_h3_t30K_s372001\"  # AvgFinalLoss=5.8e-06. Fails 1M Qs\n",
        "\n",
        "# 6-digit Mixed (addition and subtraction) models\n",
        "#cfg.model_name = \"mix_d6_l3_h4_t40K_s372001\"  # AvgFinalLoss=5e-09. Fails 1M Qs\n",
        "\n",
        "#  \"ins1\" 6-digit Mixed models initialised with 6-digit addition model\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s372001\"  # AvgFinalLoss=8e-09. Accurate on 1M Qs for Add and Sub\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t40K_s173289\"  # AvgFinalLoss=1.6e-08. 936K for Add, 1M Qs for Sub\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t50K_s572091\"  # AvgFinalLoss=2.9e-08. 1M for Add. 300K for Sub. For 000041-000047=-0000006 gives +0000006. Improve training data.\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h3_t40K_s572091\"  #  AvgFinalLoss=1.8e-08. Fails on 1M Qs. For 099111-099111=+0000000 gives -0000000. Improve training data.\n",
        "\n",
        "# \"ins2\" 6-digit Mixed model initialised with 6-digit addition model. Reset useful heads every 100 epochs.\n",
        "#cfg.model_name = \"ins2_mix_d6_l4_h4_t40K_s372001\"  # AvgFinalLoss=7e-09. Fails 1M Qs\n",
        "\n",
        "# \"ins3\" 6-digit Mixed model initialised with 6-digit addition model. Reset useful heads & MLPs every 100 epochs.\n",
        "#cfg.model_name = \"ins3_mix_d6_l4_h3_t40K_s372001\"  # AvgFinalLoss=2.6e-06. Fails 1M Qs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_IIpX2H2tNe"
      },
      "source": [
        "# Part 1B: Configuration: Input and Output file names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5BiELcf53ms"
      },
      "outputs": [],
      "source": [
        "# Needed when user changes model_name and reruns this Colab a second time\n",
        "cfg.reset_useful()\n",
        "cfg.reset_algo()\n",
        "cfg.initialize_maths_token_positions()\n",
        "acfg.reset_ablate()\n",
        "\n",
        "if cfg.model_name != \"\":\n",
        "  # Update cfg member data n_digits, n_layers, n_heads, n_training_steps from model_name\n",
        "  cfg.parse_model_name()\n",
        "\n",
        "  # Addition model\n",
        "  cfg.perc_sub = 0\n",
        "  if cfg.model_name.startswith(\"sub_\") :\n",
        "    # Subtraction model\n",
        "    cfg.perc_sub = 100\n",
        "  elif cfg.model_name.startswith(\"mix\") :\n",
        "    # Mixed (addition and subtraction) model\n",
        "    cfg.perc_sub = 66 # Train on 66% subtraction and 33% addition question batches\n",
        "  elif cfg.model_name.startswith(\"ins\") :\n",
        "    # Mixed model initialised with an addition model (using insert mode 1, 2 or 3)\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "\n",
        "  # We train multiple versions of some models, inserting different addition models.\n",
        "  cfg.insert_training_seed = cfg.training_seed\n",
        "\n",
        "  if cfg.model_name.startswith(\"ins1_mix_d6_l3\") :\n",
        "    if cfg.training_seed == 372001:\n",
        "      # Mixed model initialised with add_d6_l2_h3_t15K.pth.\n",
        "      cfg.insert_n_training_steps = 15000\n",
        "    else:\n",
        "      # Mixed model initialised with add_d6_l2_h3_t20K.pth.\n",
        "      cfg.insert_n_training_steps = 20000\n",
        "\n",
        "  cfg.batch_size = 512 # Default analysis batch size\n",
        "  if cfg.n_layers >= 3 and cfg.n_heads >= 4:\n",
        "    cfg.batch_size = 256 # Reduce batch size to avoid memory constraint issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0DJkn5l2gq3"
      },
      "outputs": [],
      "source": [
        "main_fname = cfg.file_config_prefix()\n",
        "main_fname_pth = main_fname + '.pth'\n",
        "main_fname_behavior_json = main_fname + '_behavior.json'\n",
        "main_fname_algorithm_json = main_fname + '_algorithm.json'\n",
        "\n",
        "def print_config():\n",
        "  print(\"%Add=\", cfg.perc_add(), \"%Sub=\", cfg.perc_sub, \"%Mult=\", cfg.perc_mult, \"InsertMode=\", cfg.insert_mode, \"File=\", main_fname)\n",
        "\n",
        "print_config()\n",
        "print(\"weight_decay=\", cfg.weight_decay, \"lr=\", cfg.lr, \"batch_size=\", cfg.batch_size)\n",
        "print('Main model will be read from HuggingLab file', main_fname_pth)\n",
        "print('Main model behavior analysis tags will save to Colab temporary file', main_fname_behavior_json)\n",
        "print('Main model algorithm analysis tags will save to Colab temporary file', main_fname_algorithm_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8RfHXneJw6n"
      },
      "source": [
        "# Part 3A: Set Up: Vocabulary / Embedding / Unembedding\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSsQ8EpC1g7M"
      },
      "outputs": [],
      "source": [
        "main_fname_pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeObQk2kzAv7"
      },
      "outputs": [],
      "source": [
        "qt.set_maths_vocabulary(cfg)\n",
        "qt.set_maths_question_meanings(cfg)\n",
        "print(cfg.token_position_meanings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz6rUaYvjOcE"
      },
      "source": [
        "# Part 3B: Set Up: Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA16Nb2PJ7MB"
      },
      "outputs": [],
      "source": [
        "# Transformer creation\n",
        "\n",
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = HookedTransformerConfig(\n",
        "    n_layers = cfg.n_layers,\n",
        "    n_heads = cfg.n_heads,\n",
        "    d_model = cfg.d_model,\n",
        "    d_head = cfg.d_head,\n",
        "    d_mlp = cfg.d_mlp(),\n",
        "    act_fn = cfg.act_fn,\n",
        "    normalization_type = 'LN',\n",
        "    d_vocab = cfg.d_vocab,\n",
        "    d_vocab_out = cfg.d_vocab,\n",
        "    n_ctx = cfg.n_ctx(),\n",
        "    init_weights = True,\n",
        "    device = \"cuda\",\n",
        "    seed = cfg.training_seed,\n",
        ")\n",
        "\n",
        "cfg.main_model = HookedTransformer(ht_cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHiJhch4KCej"
      },
      "source": [
        "# Part 4: Set Up: Loss Function & Data Generator\n",
        "This maths loss function and data generator are imported from QuantaTools as logits_to_tokens_loss, loss_fn, maths_data_generator_core and maths_data_generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqzljhQ4KJU5"
      },
      "outputs": [],
      "source": [
        "# Define \"iterator\" maths \"questions\" data generator function. Invoked using next().\n",
        "ds = qt.maths_data_generator( cfg )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtmioT1THbJA"
      },
      "outputs": [],
      "source": [
        "# Generate sample data generator (unit test)\n",
        "print(next(ds)[:3,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KJhCxFtNKfm"
      },
      "source": [
        "# Part 5: Set Up: Load Model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD4_HR5h1g7N"
      },
      "outputs": [],
      "source": [
        "main_fname_pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRMkB_8GNRc0"
      },
      "outputs": [],
      "source": [
        "main_repo_name=\"PhilipQuirke/VerifiedArithmetic\"\n",
        "print(\"Loading model from HuggingFace\", main_repo_name, main_fname_pth)\n",
        "\n",
        "cfg.main_model.load_state_dict(utils.download_file_from_hf(repo_name=main_repo_name, file_name=main_fname_pth, force_is_torch=True))\n",
        "cfg.main_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-yFKiDllqEf"
      },
      "source": [
        "# Part 7A: Set Up: Create sample maths questions\n",
        "\n",
        "Create a batch of manually-curated mathematics test questions, and cache some sample model prediction outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiK-0P44gvfS"
      },
      "outputs": [],
      "source": [
        "varied_questions = qt.make_maths_test_questions_and_answers(cfg)\n",
        "num_varied_questions = varied_questions.shape[0]\n",
        "\n",
        "qt.a_set_ablate_hooks(cfg)\n",
        "qt.a_calc_mean_values(cfg, varied_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5clJnASWCPVN"
      },
      "outputs": [],
      "source": [
        "print(\"Num questions:\", num_varied_questions, \"Question length:\", len(varied_questions[0]))\n",
        "print(\"Sample Question:\", varied_questions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6FwJW0tv4Nf"
      },
      "source": [
        "# Part 7B: Results: Can the model correctly predict sample questions?\n",
        "\n",
        "Ask the model to predict the varied_questions (without intervention) to see if the model gets them all right. Categorise answers by complexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E56siA_QKe0W"
      },
      "outputs": [],
      "source": [
        "# Test maths question prediction accuracy on the sample questions provided.\n",
        "# Does NOT use acfg.* or UsefulInfo.* information\n",
        "# Used to estimate the accuracy of the model's predictions.\n",
        "# Returns a reduced set of questions - removing questions that the model failed to answer.\n",
        "print_config()\n",
        "\n",
        "acfg.show_test_failures = True\n",
        "varied_questions = qt.test_maths_questions_by_complexity(cfg, acfg, varied_questions)\n",
        "acfg.show_test_failures = False\n",
        "\n",
        "num_varied_questions = varied_questions.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PjaQvhhayUL"
      },
      "source": [
        "# Part 9 : Results: Can the model do 1 million questions without error?\n",
        "\n",
        "If the model passes this test, this is evidence (not proof) that the model is fully accurate. There may be very rare edge cases (say 1 in ten million) that did not appear in the test questions. Even if you believe you know all the edge cases, and have enriched the training data to contain them, you may not have thought of all edge cases, so this is not proof.\n",
        "\n",
        "If the model fails this test:\n",
        "- Add a few of the failures into the \"test questions\" into qt.make_maths_test_questions_and_answers()\n",
        "- Understand the \"use case(s)\" driving these failures\n",
        "- Alter the Training CoLab data_generator_core to enrich the training data with examples if these use case(s) and retrain the model.  \n",
        "\n",
        "Takes ~25 mins to run (successfully) for ins_mix_d6_l3_h4_t40K_s372001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znsauYqjaxok"
      },
      "outputs": [],
      "source": [
        "# Takes ~25 minutes to run with num_questions=1000000.\n",
        "# When not interested in this test, use num_questions=1000 for speed (while still checking the code runs).\n",
        "acfg.show_test_failures = True\n",
        "qt.test_correctness_on_num_questions(cfg, acfg, num_questions=1000)\n",
        "acfg.show_test_failures = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXBYdxj-jLZc"
      },
      "source": [
        "# Part 10: Set Up: Which token positions are used by the model?\n",
        "\n",
        "Ablate all nodes in each (question and answer) token position (by overriding the model memory aka residual stream). If the model's prediction loss increases, the token position is useful to the algorithm. Unused token positions are excluded from further analysis. Used to populate the UsefulInfo.useful_positions data. This is token **position level** information.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGL57MRBLdUh"
      },
      "outputs": [],
      "source": [
        "num_failures_list = []\n",
        "\n",
        "for position in range(cfg.n_ctx()):\n",
        "  # Test accuracy of model in predicting question answers. Ablates all nodes at acfg.ablate_position. Does NOT use UsefulInfo.* information.\n",
        "  num_fails = qt.test_maths_questions_by_impact(cfg, acfg, varied_questions, position, True)\n",
        "\n",
        "  if num_fails > 0:\n",
        "    # Add position to UsefulInfo.useful_positions\n",
        "    cfg.add_useful_position(position)\n",
        "    num_failures_list += [num_fails]\n",
        "  else:\n",
        "    num_failures_list += \".\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmsGWUbILYin"
      },
      "source": [
        "# Part 11: Results: Which token positions are used by the model?\n",
        "\n",
        "Which token positions are is used in the model's predictions? Unused token positions are excluded from further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpRp5YMmLe1y"
      },
      "outputs": [],
      "source": [
        "print_config()\n",
        "print(\"num_questions=\", num_varied_questions)\n",
        "print(\"useful_positions=\", cfg.useful_positions )\n",
        "print()\n",
        "\n",
        "cfg.graph_file_suffix = \"svg\" # Can be pdf, svg or png\n",
        "cfg.calc_position_failures_map(num_failures_list)\n",
        "qt.save_plt_to_file(cfg=cfg, full_title=\"Failures When Position Ablated\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "904WBkTOLg_5"
      },
      "source": [
        "# Part 12A: Set Up: Which nodes are used by the model?\n",
        "\n",
        "Here we ablate each (attention head and MLP neuron) node in each (question and answer) token position see if the model's prediction loss increases. If loss increases then the \"node + token position\" is used by the algorithm. Used to calculate the UsefulInfo.useful_node_location. This is **position+node level** information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "as9ot9RMMTAi"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes = qt.UsefulNodeList()\n",
        "\n",
        "qt.ablate_mlp_and_add_useful_node_tags(cfg, varied_questions, qt.test_maths_questions_and_add_useful_node_tags)\n",
        "qt.ablate_head_and_add_useful_node_tags(cfg, varied_questions, qt.test_maths_questions_and_add_useful_node_tags)\n",
        "qt.add_node_attention_tags(cfg, varied_questions)\n",
        "\n",
        "cfg.useful_nodes.sort_nodes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw-Wteh-JBd6"
      },
      "source": [
        "# Part 12B: Results: Which nodes are used by the model?\n",
        "\n",
        "Here are the (attention head and MLP neuron) node in each (question and answer) token position used by the model during predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhEWUt7yJBuh"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.print_node_tags()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BmQHiLALp-3"
      },
      "source": [
        " # Part 13: Set up: Show and save Quanta map\n",
        "\n",
        " Using the UsefulNodes and filtering their tags, show a 2D map of the nodes and the tag minor versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emcB0_CpYTaJ"
      },
      "outputs": [],
      "source": [
        "def show_quanta_map( title, standard_quanta, cell_num_shades, \\\n",
        "        filters : qt.FilterNode, major_tag : qt.QType, minor_tag : str, get_node_details,  \\\n",
        "        image_width_inches : int = -1, image_height_inches : int = -1,\n",
        "        combine_identical_cells : bool = True, cell_fontsize : int = 9 ): \\\n",
        "\n",
        "  test_nodes = cfg.useful_nodes\n",
        "  if filters is not None:\n",
        "    test_nodes = qt.filter_nodes(test_nodes, filters)\n",
        "\n",
        "  ax1, quanta_results, num_results = qt.calc_quanta_map(\n",
        "      cfg, standard_quanta, cell_num_shades,\n",
        "      test_nodes, major_tag.value, minor_tag, get_node_details,\n",
        "      cell_fontsize, combine_identical_cells, image_width_inches, image_height_inches )\n",
        "\n",
        "  if num_results > 0:\n",
        "    if cfg.graph_file_suffix > \"\":\n",
        "      print(\"Saving quanta map:\", title)\n",
        "      qt.save_plt_to_file(cfg=cfg, full_title=title)\n",
        "    else:\n",
        "      ax1.set_title(cfg.file_config_prefix() + ' ' + title + ' ({} nodes)'.format(len(quanta_results)))\n",
        "\n",
        "    # Show plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpkyhHRoMOSw"
      },
      "source": [
        "# Part 16A: Results: Show failure percentage map\n",
        "\n",
        "Show the percentage failure rate (incorrect prediction) when individual Attention Heads and MLPs are ablated.\n",
        "\n",
        "A cell containing \"< 1\" may add some risk to the accuracy of the overall analysis process. Check to see if this represents a new use case. Improve the test data set to contain more instances of this (new or existing) use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ28dx5YLs0P"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Failure Frequency Behavior Per Node\", True, qt.FAIL_SHADES, None, qt.QType.FAIL, \"\", qt.get_quanta_fail_perc, 9, 2 * cfg.n_layers, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IifmtnLoTCN5"
      },
      "source": [
        "# Part 16B - Show answer impact behavior map\n",
        "\n",
        "Show the purpose of each useful cell by impact on the answer digits A0 to Amax.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K9PyCKYTUzX"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Answer Impact Behavior Per Node\", True, cfg.num_answer_positions, None, qt.QType.IMPACT, \"\", qt.get_quanta_impact, 9, 2 * cfg.n_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avCfaCT1Puhz"
      },
      "source": [
        "# Part 16C: Result: Show attention map\n",
        "\n",
        "Show attention quanta of useful heads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTGoEWHgvFH6"
      },
      "outputs": [],
      "source": [
        "# Only maps attention heads, not MLP layers\n",
        "show_quanta_map( \"Attention Behavior Per Head\", True, qt.ATTN_SHADES, None, qt.QType.ATTN, \"\", qt.get_quanta_attention, 9, 3 * cfg.n_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7-99ZxDOrbF"
      },
      "source": [
        "# Part 16C - Show question complexity map\n",
        "\n",
        "Show the \"minimum\" addition purpose of each useful cell by S0 to S5 quanta.\n",
        "Show the \"minimum\" subtraction purpose of each useful cell by M0 to M5 quanta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyoErRoCA-pz"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_add() > 0:\n",
        "  show_quanta_map( \"Addition Min-Complexity Behavior Per Node\", False,\n",
        "      qt.MATH_ADD_SHADES, None, qt.QType.MATH_ADD, qt.MathsBehavior.ADD_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity, 9, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMZzbjxUBQGE"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  show_quanta_map( \"Postive-answer Subtraction Min-Complexity Per Node\", False,\n",
        "      qt.MATH_SUB_SHADES, None, qt.QType.MATH_SUB, qt.MathsBehavior.SUB_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity, 9, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUaT47ettc0M"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  show_quanta_map( \"Negative-answer Subtraction Min-Complexity Per Node\", False,\n",
        "      qt.MATH_SUB_SHADES, None, qt.QType.MATH_NEG, qt.MathsBehavior.NEG_COMPLEXITY_PREFIX.value, qt.get_maths_min_complexity, 9, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbiau9foMp3h"
      },
      "source": [
        "# Part 19A: Results: Manual interpretation of PCA results\n",
        "\n",
        "Principal Component Analysis (PCA) is a powerful technique that aids in mechanistic interpretability by simplifying complex datasets into principal components that capture the most significant variance within the data.\n",
        "\n",
        "This library uses PCA to help understand the purpose of individual useful nodes. For more background refer https://github.com/PhilipQuirke/verified_transformers/blob/main/pca.md\n",
        "\n",
        "If an attention head and an answer digit An gives an interpretable response (2 or 3 distinct output clusters) on 3 groups of questions aligned to T8, T9 and T10 definitions, then plot the response and add a PCA tag\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxlgEAPV1g7W"
      },
      "outputs": [],
      "source": [
        "# Create a cache of sample maths questions based on the T8, T9, T10 categorisation in cfg.tricase_questions_dict\n",
        "qt.make_maths_tricase_questions(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ5fS3XNMs8e"
      },
      "outputs": [],
      "source": [
        "# Plot all attention heads with the clearest An selected\n",
        "if use_pca:\n",
        "\n",
        "  if cfg.model_name == \"add_d5_l1_h3_t15K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[ 12, 0, 0, 4 ],\n",
        "      [ 12, 0, 2, 3 ],\n",
        "      [ 13, 0, 0, 3 ],\n",
        "      [ 14, 0, 0, 2 ],\n",
        "      [ 15, 0, 0, 1 ],\n",
        "      [ 16, 0, 0, 0 ]])\n",
        "\n",
        "  if cfg.model_name == \"add_d5_l2_h3_t15K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[10, 0, 0, 2 ],\n",
        "      [ 12, 0, 0, 3 ],\n",
        "      [ 12, 1, 0, 3 ],\n",
        "      [ 12, 1, 1, 4 ],\n",
        "      [ 12, 1, 2, 4 ],\n",
        "      [ 13, 0, 0, 0 ],\n",
        "      [ 13, 0, 0, 3 ],\n",
        "      [ 13, 1, 2, 2 ],\n",
        "      [ 14, 0, 0, 0 ],\n",
        "      [ 14, 0, 0, 2 ],\n",
        "      [ 14, 1, 2, 2 ],\n",
        "      [ 15, 0, 0, 1 ],\n",
        "      [ 15, 0, 0, 0 ],\n",
        "      [ 15, 1, 1, 1 ],\n",
        "      [ 16, 0, 0, 0 ]])\n",
        "\n",
        "  if cfg.model_name == \"add_d6_l2_h3_t15K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[11, 0, 1, 1 ], # Reasonable?\n",
        "      [ 11, 0, 0, 2 ],\n",
        "      [ 12, 0, 0, 3 ],\n",
        "      [ 13, 0, 0, 1 ],\n",
        "      [ 14, 0, 0, 4 ],\n",
        "      [ 14, 1, 1, 4 ],\n",
        "      [ 15, 0, 0, 4 ],\n",
        "      [ 15, 1, 1, 4 ],\n",
        "      [ 15, 1, 2, 4 ],\n",
        "      [ 16, 0, 0, 3 ],\n",
        "      [ 16, 1, 1, 3 ],\n",
        "      [ 17, 0, 0, 2 ],\n",
        "      [ 17, 1, 1, 2 ],\n",
        "      [ 18, 0, 0, 0 ],\n",
        "      [ 18, 0, 0, 1 ],\n",
        "      [ 19, 0, 0, 0 ]])\n",
        "\n",
        "  if cfg.model_name.startswith(\"sub_d6_l2_h3_t30K\"):\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.MINUS,\n",
        "      [[14, 0, 1, 0 ],\n",
        "      [ 15, 0, 0, 5 ],\n",
        "      [ 15, 1, 1, 0 ],\n",
        "      [ 15, 1, 1, 1 ],\n",
        "      [ 15, 1, 1, 2 ],\n",
        "      [ 15, 1, 1, 3 ],\n",
        "      [ 15, 1, 1, 4 ],\n",
        "      [ 15, 1, 2, 0 ],\n",
        "      [ 15, 1, 2, 1 ],\n",
        "      [ 15, 1, 2, 2 ],\n",
        "      [ 15, 1, 2, 3 ],\n",
        "      [ 16, 0, 0, 0 ],\n",
        "      [ 16, 0, 0, 1 ],\n",
        "      [ 16, 0, 0, 2 ],\n",
        "      [ 16, 0, 0, 3 ],\n",
        "      [ 16, 0, 0, 4 ],\n",
        "      [ 16, 0, 0, 5 ],\n",
        "      [ 16, 1, 0, 4 ],\n",
        "      [ 16, 1, 1, 0 ],\n",
        "      [ 16, 1, 1, 1 ],\n",
        "      [ 16, 1, 1, 2 ],\n",
        "      [ 16, 1, 1, 3 ],\n",
        "      [ 16, 1, 1, 4 ],\n",
        "      [ 16, 1, 2, 0 ],\n",
        "      [ 16, 1, 2, 1 ],\n",
        "      [ 16, 1, 2, 2 ],\n",
        "      [ 16, 1, 2, 3 ],\n",
        "      [ 16, 1, 2, 4 ],\n",
        "      [ 16, 1, 2, 5 ],\n",
        "      [ 17, 0, 0, 0 ],\n",
        "      [ 17, 0, 0, 1 ],\n",
        "      [ 17, 0, 0, 2 ],\n",
        "      [ 17, 0, 0, 3 ],\n",
        "      [ 17, 1, 0, 3 ],\n",
        "      [ 17, 1, 0, 4 ],\n",
        "      [ 17, 1, 2, 0 ],\n",
        "      [ 17, 1, 2, 4 ],\n",
        "      [ 18, 0, 0, 0 ],\n",
        "      [ 18, 0, 0, 1 ],\n",
        "      [ 18, 0, 0, 2 ],\n",
        "      [ 18, 0, 2, 0 ],\n",
        "      [ 18, 1, 2, 3 ],\n",
        "      [ 19, 0, 0, 0 ],\n",
        "      [ 19, 1, 2, 2 ],\n",
        "      [ 20, 0, 0, 0 ],\n",
        "      [ 18, 0, 2, 0 ],\n",
        "\t    [ 18, 0, 2, 0 ]])\n",
        "\n",
        "  if cfg.model_name == \"mix_d6_l3_h4_t40K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[ 8, 0, 0, 4 ],\n",
        "      [  9, 0, 1, 3 ],\n",
        "      [ 10, 0, 1, 2 ],\n",
        "      [ 10, 0, 1, 3 ],\n",
        "      [ 11, 0, 1, 1 ],\n",
        "      [ 11, 0, 1, 2 ],\n",
        "      [ 12, 0, 0, 0 ],\n",
        "      [ 13, 0, 1, 4 ],\n",
        "      [ 13, 1, 1, 0 ],\n",
        "      [ 13, 1, 1, 1 ],\n",
        "      [ 13, 1, 1, 2 ],\n",
        "      [ 13, 1, 1, 3 ],\n",
        "      [ 13, 1, 2, 3 ],\n",
        "      [ 13, 1, 2, 5 ],\n",
        "      [ 14, 0, 1, 0 ],\n",
        "      [ 15, 0, 0, 0 ],\n",
        "      [ 15, 0, 0, 1 ],\n",
        "      [ 15, 0, 0, 2 ],\n",
        "      [ 15, 0, 0, 3 ],\n",
        "      [ 15, 0, 0, 4 ],\n",
        "      [ 15, 0, 0, 5 ],\n",
        "      [ 15, 1, 0, 0 ],\n",
        "      [ 15, 1, 0, 1 ],\n",
        "      [ 15, 1, 0, 2 ],\n",
        "      [ 15, 1, 0, 3 ],\n",
        "      [ 15, 1, 0, 4 ]])\n",
        "\n",
        "  if cfg.model_name == \"ins1_mix_d6_l3_h4_t40K_s372001\":\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "      [[10, 0, 0, 2 ],\n",
        "      [ 10, 0, 1, 2 ],\n",
        "      [ 11, 0, 0, 2 ],\n",
        "      [ 11, 0, 1, 1 ],\n",
        "      [ 13, 0, 1, 0 ],\n",
        "      [ 13, 1, 3, 1 ],\n",
        "      [ 14, 1, 2, 0 ],\n",
        "      [ 14, 1, 2, 2 ],\n",
        "      [ 14, 1, 3, 4 ],\n",
        "      [ 15, 0, 3, 5 ],\n",
        "      [ 15, 1, 2, 2 ],\n",
        "      [ 15, 1, 3, 4 ],\n",
        "      [ 16, 0, 3, 4 ],\n",
        "      [ 16, 1, 2, 0 ],\n",
        "      [ 16, 1, 2, 1 ],\n",
        "      [ 16, 1, 2, 2 ],\n",
        "      [ 16, 1, 3, 2 ],\n",
        "      [ 17, 0, 3, 3 ],\n",
        "      [ 17, 1, 2, 2 ],\n",
        "      [ 17, 1, 3, 2 ],\n",
        "      [ 18, 0, 3, 2 ],\n",
        "      [ 18, 1, 3, 1 ],\n",
        "      [ 19, 0, 3, 1 ],\n",
        "      [ 19, 2, 0, 0 ],\n",
        "      [ 19, 2, 1, 0 ],\n",
        "      [ 20, 0, 0, 0 ],\n",
        "      [ 20, 0, 3, 0 ]])\n",
        "\n",
        "    qt.manual_nodes_pca(cfg, qt.MathsToken.MINUS,\n",
        "      [[10, 0, 0, 2 ],\n",
        "      [ 10, 0, 1, 2 ],\n",
        "      [ 11, 0, 0, 2 ],\n",
        "      [ 11, 0, 1, 1 ],\n",
        "      [ 13, 0, 1, 0 ],\n",
        "      [ 14, 0, 0, 4 ],\n",
        "      [ 14, 0, 2, 5 ],\n",
        "      [ 14, 1, 2, 0 ],\n",
        "      [ 14, 1, 2, 2 ],\n",
        "      [ 14, 1, 3, 4 ]])\n",
        "\n",
        "  print('Finished generating plots')\n",
        "\n",
        "else:\n",
        "  print( \"PCA library failed to import. So PCA not done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIu3Pr9CMx3l"
      },
      "source": [
        "# Part 19B: Results: Automatic interpretation of PCA results (Optional)\n",
        "\n",
        "Part 19B is manual and selective. This part is automatic. It tests nodes not included in Part 19A, where this first (single) principal component explains 75% or more of the node. It adds a QType.PCA \"weak\" tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UADsW9c1g7X"
      },
      "outputs": [],
      "source": [
        "def auto_node_pca(ax, index, node_location, operation, answer_digit, perc_threshold=0.75):\n",
        "\n",
        "    title, error_message = qt.maths_tools._build_title_and_error_message(\n",
        "        cfg=cfg, node_location=node_location, operation=operation, answer_digit=answer_digit\n",
        "    )\n",
        "\n",
        "    if (answer_digit, operation) in cfg.tricase_questions_dict:\n",
        "        test_inputs = cfg.tricase_questions_dict[(answer_digit, operation)]\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "    pca, pca_attn_outputs, title = qt.calc_pca_for_an(\n",
        "        cfg=cfg, node_location=node_location, title=title, error_message=error_message, test_inputs=test_inputs\n",
        "    )\n",
        "\n",
        "    if pca is not None:\n",
        "      perc = qt.pca_evr_0_percent(pca)\n",
        "      if perc > perc_threshold:\n",
        "        qt.maths_tools.plot_pca_for_an(ax, pca_attn_outputs, title)\n",
        "\n",
        "        major_tag = qt.QType.MATH_ADD if operation == qt.MathsToken.PLUS else qt.QType.MATH_SUB # Does not handle NEG case\n",
        "        cfg.add_useful_node_tag( node_location, major_tag.value, qt.maths_tools.pca_op_tag(answer_digit, operation, False) )\n",
        "        return True\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDZ4--e11g7X"
      },
      "outputs": [],
      "source": [
        "def auto_find_pca_node(node, op, perc_threshold):\n",
        "  fig, axs = plt.subplots(2, 4) # Allow up to 8 graphs\n",
        "  fig.set_figheight(4)\n",
        "  fig.set_figwidth(10)\n",
        "\n",
        "  index = 0\n",
        "  for answer_digit in range(cfg.n_digits+1):\n",
        "    ax = axs[index // 4, index % 4]\n",
        "    if auto_node_pca(ax, index, node, op, answer_digit, perc_threshold):\n",
        "      index += 1\n",
        "\n",
        "  # Remove any graphs we dont need after all\n",
        "  while index < 2 * 4:\n",
        "    ax = axs[index // 4, index % 4]\n",
        "    ax.remove()\n",
        "    index += 1\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCYAud_Y1g7X"
      },
      "outputs": [],
      "source": [
        "def auto_find_pca(operation):\n",
        "  print(\"Automatic (weak) PCA tags for\", cfg.model_name, \"with operation\", qt.token_to_char(cfg, operation))\n",
        "  perc_threshold = 75\n",
        "\n",
        "  for node in cfg.useful_nodes.nodes:\n",
        "\n",
        "    # Exclude nodes with a (manual) PCA tag - for any answer digit(s)). Exclude MLP neurons.\n",
        "    major_tag = qt.QType.MATH_ADD if operation == qt.MathsToken.PLUS else qt.QType.MATH_SUB # Does not handle NEG case\n",
        "    minor_tag_prefix = qt.MathsBehavior.ADD_PCA_TAG if operation == qt.MathsToken.PLUS else qt.MathsBehavior.SUB_PCA_TAG\n",
        "    if node.is_head and not node.contains_tag(major_tag.value, minor_tag_prefix.value):\n",
        "      print( \"Doing PCA on node\", node.name())\n",
        "\n",
        "      auto_find_pca_node(node, operation, perc_threshold)\n",
        "\n",
        "#if False: # Suppress for speed\n",
        "if use_pca:\n",
        "  if cfg.perc_add() > 0:\n",
        "    auto_find_pca(qt.MathsToken.PLUS)\n",
        "  if cfg.perc_sub > 0:\n",
        "    auto_find_pca(qt.MathsToken.MINUS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcCpfmKwlAH"
      },
      "source": [
        "# Part 20A: Results: Show useful nodes and behaviour tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbzIaqmtwmkH"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.sort_nodes()\n",
        "cfg.useful_nodes.print_node_tags()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVkOJRmPvPms"
      },
      "source": [
        "# Part 20B: Results: Save useful nodes and behaviour tags to json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naD2eCZevOsi"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the useful nodes list to a temporary CoLab file in JSON format\n",
        "print( \"Saving useful node list with behavior tags:\", main_fname_behavior_json)\n",
        "cfg.useful_nodes.save_nodes(main_fname_behavior_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAXc9bD2q0zC"
      },
      "source": [
        "# Part 22 : Results: Search for model algorithm tasks\n",
        "\n",
        "Here we find which model nodes perform which specific algorithm task.\n",
        "- **Automatic searches** for node purposes are preferred, as they applicable to several models, and survive (non-significant, node-reordering) differences between models caused by differences in training.\n",
        "- **Manually written tests** of node purposes, specific to a single model instance are also supported.\n",
        "\n",
        "The qt.search_and_tag searches for a task on useful nodes by:\n",
        "- **filtering** useful nodes, based on \"tag\" pre-requisites, to find the few nodes worth doing investigating. For more detail refer https://github.com/PhilipQuirke/verified_transformers/blob/main/filter.md\n",
        "- **intervention ablation** testing on the interesting nodes:\n",
        "  - The first \"store\" question is run without hooks\n",
        "  - The second \"clean\" question is run with hooks interjecting some data from the \"store\" run. This run gives, not a \"clean\" answer, but an \"intervened\" answer, which mixes the \"store\" answer and the \"clean\" answer. Our beliefs about the nodes algorthmic purpose are baked into the store question, clean question and intervened answer.\n",
        "- An **algorithm tag** is added to all interesting nodes that pass the intervention ablation test(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyVYckFtV-RV"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.reset_node_tags(qt.QType.ALGO.value)\n",
        "acfg.show_test_failures = False\n",
        "acfg.show_test_successes = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgg43Sqe8oF1"
      },
      "source": [
        "## Part 22B: Automated An.SS search\n",
        "\n",
        " Search for addition \"Use Sum 9\" (SS) tasks e.g. 34633+55555=+090188 where D4 and D'4 sum to 9 (4+5), and D3 + D'3 > 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUYf20mk8zls"
      },
      "outputs": [],
      "source": [
        "qt.search_and_tag( cfg, acfg, qt.add_ss_prereqs, qt.add_ss_test, qt.add_ss_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5DMV3I_25ST"
      },
      "source": [
        "## Part 22C: Automated An.SC search\n",
        "\n",
        "Search for addition \"Make Carry 1\" (SC) tasks e.g. 222222+666966=+0889188 where D2 + D'2 > 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvS1eOReZUq1"
      },
      "outputs": [],
      "source": [
        "qt.search_and_tag( cfg, acfg, qt.add_sc_prereqs, qt.add_sc_test, qt.add_sc_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iosx5zE_macF"
      },
      "source": [
        "## Part 22D: Automated An.SA search\n",
        "\n",
        "Search for addition \"Simple Add\" (SA) tasks e.g. 555555+111111=+0666666 where D3 + D'3 < 10\n",
        "\n",
        "The SA tasks is sometimes split/shared over 2 attention heads in the same position and layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIktdaRL-BfP"
      },
      "outputs": [],
      "source": [
        "qt.search_and_tag( cfg, acfg, qt.add_sa_prereqs, qt.add_sa_test, qt.add_sa_tag, do_pair_search = True, allow_impact_mismatch = True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThzFD1FxBXg8"
      },
      "source": [
        "## Part 22E: Automated Dn.ST search\n",
        "\n",
        "Search for D0.ST to D5.ST with impact \"A65432\" to \"A65\" in early tokens.\n",
        "\n",
        "A0 and A1 are simple to calculate and so do NOT use Dn.ST or DN.STm values. So A0 and A1 are excluded from the answer impact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFJV4pfWSwHQ"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.reset_node_tags(qt.QType.ALGO.value, qt.MathsTask.ST_TAG.value)\n",
        "qt.search_and_tag( cfg, acfg, qt.add_st_prereqs, qt.add_st_test, qt.add_st_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jOBIUDzRrGz"
      },
      "source": [
        "## Part 22F: Automated An.MD search\n",
        "\n",
        "Search for positive-answer subtraction \"Difference\" (MD) tasks e.g. 666666-222222=+0444444 where D3 >= D'3\n",
        "\n",
        "The MD task may be split/shared over 2 attention heads in the same position at the same layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKag6sUnVS2N"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.sub_md_prereqs, qt.sub_md_test, qt.sub_md_tag, do_pair_search = True, allow_impact_mismatch = True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVyItdhmhIn8"
      },
      "source": [
        "## Part 22G: Automated An.MB search\n",
        "\n",
        "Search for positive-answer subtraction \"Borrow One\" (MB) tasks e.g. 222222-111311=+0110911 where D2 > D'2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzjlFwEui7K9"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.sub_mb_prereqs, qt.sub_mb_test, qt.sub_mb_tag, do_pair_search = True, allow_impact_mismatch = True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJo37Qg2ZQpJ"
      },
      "source": [
        "## Part 22H: Automated Dn.MT search\n",
        "\n",
        "To accurately predict if the answer sign is + or - the model must calculate if\n",
        "D < D'. To calculate this, the model must calculate Dn < D'n or (Dn = D'n and (Dn-1 < D'n-1 or (Dn-2 = D'n-1 and ( etc. It must predict this before the answer sign is revealed.\n",
        "\n",
        "Aligned to the Addition calculations, we assume this calculation is based on \"TriCase\" data. We search for Dn.MT task nodes which are useful in negative-answer questions, with PCA bigram or trigram outputs, in early token positions, attending to Dn, D'n input pairs.\n",
        "\n",
        "(The combined calculation that gives D < D' is NOT tested here.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOJ4J214g3La"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "    cfg.useful_nodes.reset_node_tags(qt.QType.ALGO.value, qt.MathsTask.MT_TAG.value)\n",
        "    acfg.show_test_failures = True\n",
        "    acfg.show_test_successes = True\n",
        "    qt.search_and_tag( cfg, acfg, qt.sub_mt_prereqs, qt.sub_mt_test, qt.sub_mt_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Agw7np7gZmgP"
      },
      "source": [
        "## Part 22I: Automated OPR search\n",
        "\n",
        "For mixed models that do addition and subtraction the operation token \"+/-\" (in the middle of the question) is key. Find nodes that attend to the question operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0s2ZTMLimIR"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.opr_prereqs, qt.succeed_test, qt.opr_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztfj5n8FjYNt"
      },
      "source": [
        "## Part 22J: Automated SGN search\n",
        "\n",
        "For mixed models that do addition and subtraction, and for our subtraction models, the answer sign token \"+/-\" (at the start of the answer) is important. Find nodes that attend to the answer sign token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8smeZ3vBkIQ3"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, qt.sgn_prereqs, qt.succeed_test, qt.sgn_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOVsZIpoQN_r"
      },
      "source": [
        "## Part 22K: Automated Dn.ND search\n",
        "\n",
        "Search for negative-answer subtraction Difference (ND) tasks e.g. 033333-111111=-077778 where D < D'\n",
        "\n",
        "The ND task may be split/shared over 2 attention heads in the same position at the same layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVvdOBp-Quth"
      },
      "outputs": [],
      "source": [
        "def neg_nd_tag(impact_digit):\n",
        "  return qt.answer_name(impact_digit) + \".\" + qt.MathsTask.ND_TAG.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLHa5fKxQ4Lk"
      },
      "outputs": [],
      "source": [
        "# These rules are prerequisites for (not proof of) a Neg Difference node\n",
        "def neg_nd_prereqs(cfg, position, impact_digit):\n",
        "  # Impacts An and pays attention to Dn and D'n\n",
        "  return qt.math_common_prereqs(cfg, position, impact_digit, impact_digit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYKms08dRANF"
      },
      "outputs": [],
      "source": [
        "def neg_nd_test1(cfg, acfg, alter_digit):\n",
        "  # 033333 - 111111 = -077778. No Dn.NB\n",
        "  store_question = [cfg.repeat_digit(3), cfg.repeat_digit(1)]\n",
        "  store_question[0] = store_question[0] // 10 # Convert 333333 to 033333\n",
        "\n",
        "  # 099999 - 444444 = -344445. No Dn.NB\n",
        "  clean_question = [cfg.repeat_digit(9), cfg.repeat_digit(4)]\n",
        "  clean_question[0] = clean_question[0] // 10 # Convert 999999 to 099999\n",
        "\n",
        "  # When we intervene we expect answer -347445\n",
        "  intervened_answer = clean_question[0] - clean_question[1] - (7-4) * 10 ** alter_digit\n",
        "\n",
        "  # Unit test\n",
        "  if cfg.n_digits == 6 and alter_digit == 3:\n",
        "    assert store_question[0] == 33333\n",
        "    assert clean_question[0] == 99999\n",
        "    assert clean_question[0] - clean_question[1] == -344445\n",
        "    assert intervened_answer == -347445\n",
        "\n",
        "  return store_question, clean_question, intervened_answer\n",
        "\n",
        "\n",
        "def neg_nd_test2(cfg, acfg, alter_digit):\n",
        "  # 066666 - 222222 = -155556. No Dn.NB\n",
        "  store_question = [cfg.repeat_digit(6), cfg.repeat_digit(2)]\n",
        "  store_question[0] = store_question[0] // 10 # Remove top digit\n",
        "\n",
        "  # 099999 - 333333 = -233334. No Dn.NB\n",
        "  clean_question = [cfg.repeat_digit(9), cfg.repeat_digit(3)]\n",
        "  clean_question[0] = clean_question[0] // 10 # Remove top digit\n",
        "\n",
        "  # When we intervene we expect answer -231334\n",
        "  intervened_answer = clean_question[0] - clean_question[1] - (5-3) * 10 ** alter_digit\n",
        "\n",
        "  return store_question, clean_question, intervened_answer\n",
        "\n",
        "\n",
        "def neg_nd_test(cfg, acfg, node_locations, alter_digit, strong):\n",
        "  intervention_impact = qt.answer_name(alter_digit)\n",
        "\n",
        "  store_question, clean_question, intervened_answer = neg_nd_test1(cfg, acfg, alter_digit)\n",
        "  success1, _, impact_success1 = qt.run_strong_intervention(cfg, acfg, node_locations, store_question, clean_question, qt.MathsToken.MINUS, intervention_impact, intervened_answer)\n",
        "\n",
        "  store_question, clean_question, intervened_answer = neg_nd_test2(cfg, acfg, alter_digit)\n",
        "  success2, _, impact_success2 = qt.run_strong_intervention(cfg, acfg, node_locations, store_question, clean_question, qt.MathsToken.MINUS, intervention_impact, intervened_answer)\n",
        "\n",
        "  success = (success1 and success2) if strong else (impact_success1 and impact_success2)\n",
        "\n",
        "  if success:\n",
        "    print( \"Test confirmed\", acfg.node_names(), \"perform A\"+str(alter_digit)+\".ND = (D\"+str(alter_digit)+\" + D'\"+str(alter_digit)+\") % 10 impacting \"+intervention_impact+\" accuracy.\", \"\" if strong else \"Weak\")\n",
        "\n",
        "  return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmBOMTeqRJXf"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  qt.search_and_tag( cfg, acfg, neg_nd_prereqs, neg_nd_test, neg_nd_tag, do_pair_search = True, allow_impact_mismatch = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF4AjvfG2QDy"
      },
      "source": [
        "## Part 22L: Automated Dn.NB search\n",
        "\n",
        "Search for negative-answer subtraction Difference (ND) tasks e.g. 033333-111411=-078078 where D < D' and D2 < D'2\n",
        "\n",
        "The ND task may be split/shared over 2 attention heads in the same position at the same layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsJimFmr31Fx"
      },
      "outputs": [],
      "source": [
        "def neg_nb_tag(impact_digit):\n",
        "  return qt.answer_name(impact_digit) + \".\" + qt.MathsTask.NB_TAG.value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7fi6m3G4Hzp"
      },
      "outputs": [],
      "source": [
        "# Prerequisites for negative-answer subtraction \"Borrow One\" (NB) task\n",
        "def neg_nb_prereqs(cfg, position, impact_digit):\n",
        "    # Pays attention to Dn-1 and D'n-1. Impacts An\n",
        "    return qt.math_common_prereqs(cfg,  position, impact_digit-1, impact_digit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axbZvAFL4T45"
      },
      "outputs": [],
      "source": [
        "# Intervention ablation test for negative-answer subtraction \"Borrow One\" (NB) task\n",
        "def neg_nb_test(cfg, acfg, node_locations, impact_digit, strong):\n",
        "    alter_digit = impact_digit - 1\n",
        "\n",
        "    if alter_digit < 0 or alter_digit >= cfg.n_digits:\n",
        "        acfg.reset_intervention()\n",
        "        return False\n",
        "\n",
        "    intervention_impact = qt.answer_name(impact_digit)\n",
        "\n",
        "    # 022222 - 111311 = -0089089. Has Dn.MB\n",
        "    store_question = [cfg.repeat_digit(2), cfg.repeat_digit(1)]\n",
        "    store_question[0] = store_question[0] // 10 # Convert 222222 to 022222\n",
        "    store_question[1] += (3 - 1) * (10 ** alter_digit)\n",
        "\n",
        "    # 077777 - 444444 = -0366667. No Dn.MB\n",
        "    clean_question = [cfg.repeat_digit(7), cfg.repeat_digit(4)]\n",
        "    clean_question[0] = clean_question[0] // 10 # Convert 777777 to 077777\n",
        "\n",
        "    # When we intervene we expect answer -0366677\n",
        "    intervened_answer = clean_question[0] - clean_question[1] - 10 ** (alter_digit+1)\n",
        "\n",
        "    success, _, _ = qt.run_strong_intervention(cfg, acfg, node_locations, store_question, clean_question,qt. MathsToken.MINUS, intervention_impact, intervened_answer)\n",
        "\n",
        "    if success:\n",
        "        print( \"Test confirmed\", acfg.node_names(), \"perform A\"+str(alter_digit)+\".NB impacting \"+intervention_impact+\" accuracy.\", \"\" if strong else \"Weak\")\n",
        "\n",
        "    return success"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvvtV6ZM48O4"
      },
      "outputs": [],
      "source": [
        "if cfg.perc_sub > 0:\n",
        "  cfg.useful_nodes.reset_node_tags(qt.QType.ALGO.value, qt.MathsTask.NB_TAG.value)\n",
        "  qt.search_and_tag( cfg, acfg, neg_nb_prereqs, neg_nb_test, neg_nb_tag, do_pair_search = True, allow_impact_mismatch = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQLfkdlbVAl_"
      },
      "source": [
        "# Part 23A: Show algorithm quanta map\n",
        "\n",
        "Plot the \"algorithm\" tags generated in previous steps as a quanta map. This is an automatically generated partial explanation of the model algorithm.\n",
        "\n",
        "Nodes with multiple tags were tagged (found) by more than one of the above task searches"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.graph_file_suffix = \"pdf\" # Else pdf"
      ],
      "metadata": {
        "id": "BsuXl_U2MSnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9VDbjTAVGrP"
      },
      "outputs": [],
      "source": [
        "qt.print_algo_purpose_results(cfg)\n",
        "print()\n",
        "\n",
        "show_quanta_map( \"Algorithm Purpose Per Node\", True, 2, None, qt.QType.ALGO, \"\", qt.get_quanta_binary, 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Buqs9f6mNEj"
      },
      "outputs": [],
      "source": [
        "show_quanta_map( \"Attention Behavior Per Head\", True, qt.ATTN_SHADES, None, qt.QType.ATTN, \"\", qt.get_quanta_attention, 9, 3 * cfg.n_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_m3qiWYrjRJ"
      },
      "source": [
        "# Part 23B: Show known quanta per answer digit\n",
        "\n",
        "Each of the late positions are soley focused on calculating one answer digit. Show the data have we collected on late answer digit.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT8zKdHz1-fZ"
      },
      "outputs": [],
      "source": [
        "for position in range(cfg.num_question_positions + 1, cfg.n_ctx() - 1):\n",
        "  print(\"Position:\", position)\n",
        "\n",
        "  # Calculate a table of the known quanta for the specified position for each late token position\n",
        "  qt.calc_maths_quanta_for_position_nodes(cfg, position)\n",
        "\n",
        "  qt.save_plt_to_file(cfg=cfg, full_title=\"Quanta At \"+ qt.position_name(position))\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhheXmLTUfc"
      },
      "source": [
        "# Part 24: Save useful nodes with behaviour and algorithm tags to JSON file\n",
        "\n",
        "Show a list of the nodes that have proved useful in calculations, together with data on the nodes behavior and algorithmic purposes.\n",
        "Save the data to a Colab temporary JSON file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRW6tiM8hDOB"
      },
      "outputs": [],
      "source": [
        "cfg.useful_nodes.print_node_tags(qt.QType.ALGO.value, \"\", False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ktlEftAOyEd"
      },
      "outputs": [],
      "source": [
        "# Serialize and save the useful nodes list with algorithm tags to a temporary CoLab file in JSON format\n",
        "print( \"Saving useful node list with algorithm tags:\", main_fname_algorithm_json)\n",
        "cfg.useful_nodes.save_nodes(main_fname_algorithm_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbvzBDwPvoHw"
      },
      "outputs": [],
      "source": [
        "mixed_model = cfg.model_name.startswith(\"ins1_mix_d6_l3_h4_t40K\") or cfg.model_name.startswith(\"ins2_mix_d6_l4_h4_t40K\") or cfg.model_name.startswith(\"ins3_mix_d6_l4_h3_t40K\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D74GWTY3aKhm"
      },
      "source": [
        "# Part 25 : Results: Test Algorithm - Addition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxGMji2snxax"
      },
      "source": [
        "## Part25A : Model add_d5_l1_h3_t30K. Tasks An.SA, An.SC, An.SS\n",
        "\n",
        "This 1-layer model cant do all addition questions. This hypothesis mirrors Paper 1. 14/15 heads have purpose assigned. 0/6 neurons have purpose assigned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYHKHxh-pHUd"
      },
      "outputs": [],
      "source": [
        "# For answer digits (excluding Amax), a An.SA node is needed before the answer digit is revealed\n",
        "def test_algo_sa(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.add_sa_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))\n",
        "\n",
        "# For answer digits (excluding Amax and A0), a An.SC node is needed before the answer digit is revealed\n",
        "def test_algo_sc(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    if impact_digit > 0:\n",
        "      cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.add_sc_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))\n",
        "\n",
        "# For answer digits (excluding Amax, A1 and A0), a An.SS node is needed before the answer digit is revealed\n",
        "def test_algo_ss(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    if impact_digit > 1:\n",
        "      cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.add_ss_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MC4oY_HNn5_L"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name == \"add_d5_l1_h3_t30K\":\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_sa(algo_nodes)\n",
        "  test_algo_sc(algo_nodes)\n",
        "  test_algo_ss(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZk-BAE2n5kZ"
      },
      "source": [
        "## Part25B : Models add_d5/d6_l2_h3_t15K. Tasks An.SA, An.SC, An.SS, An.AC\n",
        "\n",
        "These 2 and 3-layer models can do addition accurately.\n",
        "\n",
        "- add_d6_l2_h3_t15K: 21/31 heads have purpose assigned. 0/17 neurons have purpose assigned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsmPe8rNzzvy"
      },
      "outputs": [],
      "source": [
        "# Before Amax is revealed (as a 0 or 1), there must be a Dn.C node for every digit pair\n",
        "# For each digit (except A0) there must be either an An.SS or an Dn.C\n",
        "def test_algo_ac_or_ss(model_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    early_ac = qt.FilterAnd(qt.FilterAlgo(qt.add_st_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(cfg.n_digits+1), qt.QCondition.MAX))\n",
        "    late_ac = qt.FilterAnd(qt.FilterAlgo(qt.add_st_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "    any_ss = qt.FilterAnd(qt.FilterAlgo(qt.add_ss_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX))\n",
        "\n",
        "    if cfg.n_layers == 1:\n",
        "      # There must be a Dn.SS node for every answer digit except A0\n",
        "      if impact_digit > 0:\n",
        "        cfg.test_algo_clause(model_nodes, any_ss)\n",
        "    else:\n",
        "      # There must be a Dn.SS node or a Dn.C node for every digit except A0\n",
        "      if impact_digit > 0:\n",
        "        cfg.test_algo_clause(model_nodes, qt.FilterOr(any_ss, late_ac))\n",
        "\n",
        "      # There must a Dn.C node for every digit before the first 1 or 0 digit is calculated\n",
        "      cfg.test_algo_clause(model_nodes, early_ac)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cmjOymxluQe"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name == \"add_d5_l2_h3_t15K\" or cfg.model_name == \"add_d6_l2_h3_t15K\":\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_sa(algo_nodes)\n",
        "  test_algo_sc(algo_nodes)\n",
        "  test_algo_ac_or_ss(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQxhIPzs5K6u"
      },
      "source": [
        "# Part 26: Results: Test Algorithm - Subtraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig0eUEDN5XmG"
      },
      "source": [
        "## Part 26A : Model sub_d6_l2_h3_t30K. Tasks MD, MB, MZ\n",
        "\n",
        "This 2-layer model can do subtraction accurately. TBC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_51OgGF3QURv"
      },
      "outputs": [],
      "source": [
        "# For answer digits (excluding Amax), An.MD and An.MB nodes are needed before the answer digit is revealed\n",
        "def test_algo_md_mb(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.sub_md_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))\n",
        "\n",
        "    cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(qt.sub_mb_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))\n",
        "\n",
        "\n",
        "# For answer digits (excluding Amax), An.MZ nodes are needed before the answer digit is revealed\n",
        "def test_algo_mz(algo_nodes):\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "      pass\n",
        "      #cfg.test_algo_clause(algo_nodes, qt.FilterAnd(qt.FilterAlgo(sub_mz_tag(impact_digit)), qt.FilterPosition(cfg.an_to_position_name(impact_digit+1), qt.QCondition.MAX)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Axer3RNi6RSG"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name == \"sub_d6_l2_h3_t30K\":\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_md_mb(algo_nodes)\n",
        "  test_algo_mz(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aero_LUu3RX"
      },
      "source": [
        "## Part 26B: Test Algorithm - Subtraction - Negative Answer\n",
        "\n",
        "To accurately predict if the answer sign is + or - the model must calculate if\n",
        "D < D'. To calculate this, the model must calculate Dn < D'n or (Dn = D'n and (Dn-1 < D'n-1 or (Dn-2 = D'n-1 and ( etc. It must predict this before the answer sign is revealed.\n",
        "\n",
        "We expect to see nodes useful in negative answer questions, with PCA bigram (or trigram) outputs, attending to these input pairs, evaluated in this order, before the answer sign is revealed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMth-ecxu6NF"
      },
      "outputs": [],
      "source": [
        "# For answer digits (excluding Amax), An.SC is needed before the answer digit is revealed\n",
        "def test_algo_sc(algo_nodes):\n",
        "  sc_locations = {}\n",
        "\n",
        "  sign_position = cfg.an_to_position_name(cfg.n_digits+1)\n",
        "\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    # For answer digits (excluding the +/- answer sign and 0 or 1 first answer digit), An.SC is calculated before the answer sign is revealed\n",
        "    position = cfg.test_algo_clause(algo_nodes,  qt.FilterAnd(\n",
        "      qt.FilterAlgo(qt.sub_mt_tag(impact_digit)),\n",
        "      qt.FilterPosition(sign_position, qt.QCondition.MAX)))\n",
        "    sc_locations[impact_digit] = position\n",
        "\n",
        "  # Check that sc_locations[6] < sc_locations[5] < sc_locations[4] < etc\n",
        "  print(\"SC Locations:\", sc_locations)\n",
        "  for impact_digit in range(cfg.n_digits):\n",
        "    if impact_digit > 0:\n",
        "      sc1 = sc_locations[impact_digit]\n",
        "      sc2 = sc_locations[impact_digit-1]\n",
        "      description = f\"SC Ordering: A{impact_digit}={sc1}, A{impact_digit-1}={sc2}\"\n",
        "      cfg.test_algo_logic(description, sc1 >= 0 and sc2 >= 0 and sc1 < sc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yrAg4sQu9g4"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name.startswith(\"sub_d6_l2_h3_t30K\") or cfg.model_name.startswith('ins1_mix_d6_l3_h4_t40K') :\n",
        "\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_sc(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCkA6qYCq4iS"
      },
      "source": [
        "# Part 27: Test Algorithm - Mixed Addition and Subtraction model\n",
        "\n",
        "What algorithm do mixed models use to perform both addition and subtraction? Our working hypothesis is Hypothesis 2 as described in https://github.com/PhilipQuirke/verified_transformers/blob/main/mixed_model.md\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFvLmWLf2JA3"
      },
      "source": [
        "## Part 27A: Calculating answer digit A2 in token position A3\n",
        "\n",
        "The below graph displays the same (behavior and algorithm) data as the quanta maps. Refer https://github.com/PhilipQuirke/verified_transformers/blob/main/mixed_model.md section 27A for more explanation.\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1TQpYbs2JcZ"
      },
      "outputs": [],
      "source": [
        "qt.calc_maths_quanta_for_position_nodes(cfg, 18)\n",
        "qt.save_plt_to_file(cfg=cfg, full_title=\"Quanta At \"+ qt.position_name(18))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwNJYWeApo_z"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name.startswith(\"ins1_mix_d6_l3_h4_t40K\"):\n",
        "  qt.manual_nodes_pca(cfg, qt.MathsToken.PLUS,\n",
        "    [[ 18, 0, 3, 2 ],\n",
        "    [ 18, 0, 0, 1 ],\n",
        "    [ 18, 1, 0, 2 ],\n",
        "    [ 18, 1, 0, 1 ],\n",
        "    [ 18, 1, 1, 1 ],\n",
        "    [ 18, 1, 2, 1 ],\n",
        "    [ 18, 1, 3, 1 ]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qntH5JOXKqQR"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name == \"ins1_mix_d6_l3_h4_t40K_s372001\":\n",
        "  qt.manual_nodes_pca(cfg, qt.MathsToken.MINUS,\n",
        "    [[ 18, 0, 3, 3 ],\n",
        "    [ 18, 0, 3, 2 ],\n",
        "    [ 18, 0, 0, 1 ],\n",
        "    [ 18, 0, 3, 1 ],\n",
        "    [ 18, 1, 0, 1 ],\n",
        "    [ 18, 1, 1, 1 ],\n",
        "    [ 18, 1, 2, 1 ],\n",
        "    [ 18, 1, 3, 1 ]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgasUyOYMG9E"
      },
      "source": [
        "## Part 27.H3 Calculate whether D > D' (using NG tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClNYGvE6Q5T8"
      },
      "outputs": [],
      "source": [
        "filters = qt.FilterContains(qt.QType.MATH_NEG, \"\")\n",
        "\n",
        "#print(\"NG tagged nodes:\", qt.filter_nodes( cfg.useful_nodes, filters ).get_node_names())\n",
        "\n",
        "show_quanta_map( \"Subtraction Behavior NG Nodes\", False, 2, filters, qt.QType.MATH_SUB, \"\", qt.get_maths_min_complexity, 9, 6)\n",
        "show_quanta_map( \"Attention Behavior Per NG Head\", True, 10, filters, qt.QType.ATTN, \"\", qt.get_quanta_attention, 9, 8)\n",
        "show_quanta_map( \"Algorithm Purpose Per NG Node\", True, 2, filters, qt.QType.ALGO, \"\", qt.get_quanta_binary, 9, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mC4guryMA2k"
      },
      "outputs": [],
      "source": [
        "if mixed_model:\n",
        "  algo_nodes = cfg.start_algorithm_test(acfg)\n",
        "\n",
        "  test_algo_sc(algo_nodes)\n",
        "  cfg.print_algo_clause_results()\n",
        "\n",
        "  cfg.print_algo_purpose_results(algo_nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vxyIj1FP2Hq"
      },
      "source": [
        "# Part 30: Unit Test automated searches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6g2-mZ5UeJZ"
      },
      "outputs": [],
      "source": [
        "def check_algo_tag_exists(node_location_as_str, the_tags ):\n",
        "  node_location = qt.str_to_node_location(node_location_as_str)\n",
        "  node = cfg.useful_nodes.get_node(node_location)\n",
        "  assert node is not None\n",
        "\n",
        "  for the_tag in the_tags:\n",
        "    if not node.contains_tag(qt.QType.ALGO.value, the_tag):\n",
        "      print( \"Node\", node.name(), \"is missing tag\", the_tag, \"It has tags:\", node.tags )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr5SN-tuP1yO"
      },
      "outputs": [],
      "source": [
        "print(cfg.model_name)\n",
        "\n",
        "if cfg.model_name.startswith('add_d6_l2_h3_t15K'):\n",
        "  check_algo_tag_exists('P11L0H0', ['D2.TC'] )\n",
        "  check_algo_tag_exists('P12L0H0', ['D3.TC'] )\n",
        "  check_algo_tag_exists('P14L0H0', ['A5.SS', 'D4.TC'] )\n",
        "  check_algo_tag_exists('P14L0H2', ['A5.SC', 'D5.TC'] )\n",
        "  check_algo_tag_exists('P14L1H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A4.SC'] )\n",
        "  check_algo_tag_exists('P15L0H1', ['A5.SA'] )\n",
        "  check_algo_tag_exists('P15L0H2', ['A5.SA'] )\n",
        "  check_algo_tag_exists('P16L0H0', ['A3.SC'] )\n",
        "  check_algo_tag_exists('P16L0H1', ['A4.SA'] )\n",
        "  check_algo_tag_exists('P16L0H2', ['A4.SA'] )\n",
        "  check_algo_tag_exists('P17L0H0', ['A2.SC'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.SA'] )\n",
        "  check_algo_tag_exists('P17L0H2', ['A3.SA'] )\n",
        "  check_algo_tag_exists('P18L0H0', ['A1.SC'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.SA'] )\n",
        "  check_algo_tag_exists('P18L0H2', ['A2.SA'] )\n",
        "  check_algo_tag_exists('P19L0H0', ['A0.SC'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.SA'] )\n",
        "  check_algo_tag_exists('P19L0H2', ['A1.SA'] )\n",
        "  check_algo_tag_exists('P20L0H1', ['A0.SA'] )\n",
        "  check_algo_tag_exists('P20L0H2', ['A0.SA'] )\n",
        "\n",
        "if cfg.model_name.startswith('mix_d6_l3_h4_t40K'):\n",
        "  check_algo_tag_exists('P8L0H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L2H0', ['A7.NG'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H3', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P16L0H3', ['A4.SA.A4', 'A4.MD.A4'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.NG'] )\n",
        "  check_algo_tag_exists('P17L0H3', ['A3.SA.A3', 'A3.MD.A3'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.NG'] )\n",
        "  check_algo_tag_exists('P18L0H3', ['A2.SA.A2', 'A2.MD.A2'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.NG'] )\n",
        "  check_algo_tag_exists('P19L0H3', ['A1.SA.A1', 'A1.MD.A1'] )\n",
        "  check_algo_tag_exists('P20L0H0', ['A0.SA', 'A0.MD'] )\n",
        "  check_algo_tag_exists('P20L0H3', ['A0.SA', 'A0.MD'] )\n",
        "  check_algo_tag_exists('P20L2H1', ['A0.NG'] )\n",
        "\n",
        "if cfg.model_name.startswith('ins1_mix_d6_l3_h4_t40K'):\n",
        "  check_algo_tag_exists('P6L0H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P9L0H0', ['A4.MT'] )\n",
        "  check_algo_tag_exists('P9L0H1', ['A4.ST'] )\n",
        "  check_algo_tag_exists('P10L0H1', ['A2.MT'] )\n",
        "  check_algo_tag_exists('P10L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P12L0H0', ['A3.MT'] )\n",
        "  check_algo_tag_exists('P12L0H1', ['A3.ST'] )\n",
        "  check_algo_tag_exists('P12L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P12L1H2', ['A1.MT'] )\n",
        "  check_algo_tag_exists('P13L0H3', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L1H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P13L2H0', ['OPR'] )\n",
        "  check_algo_tag_exists('P14L0H0', ['A5.SS', 'OPR'] )\n",
        "  check_algo_tag_exists('P14L0H1', ['OPR'] )\n",
        "  check_algo_tag_exists('P14L0H2', ['A5.SC', 'A5.ST', 'SGN'] )\n",
        "  check_algo_tag_exists('P14L1H2', ['SGN'] )\n",
        "  check_algo_tag_exists('P14L1H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P15L0H0', ['A4.SC'] )\n",
        "  check_algo_tag_exists('P15L0H1', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H2', ['A5.SA', 'A5.MD'] )\n",
        "  check_algo_tag_exists('P15L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L0H0', ['A3.SC'] )\n",
        "  check_algo_tag_exists('P16L0H1', ['A4.SA', 'A4.MD', 'A4.ND'] )\n",
        "  check_algo_tag_exists('P16L0H2', ['A4.SA', 'A4.MD', 'A4.ND'] )\n",
        "  check_algo_tag_exists('P16L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L1H0', ['SGN'] )\n",
        "  check_algo_tag_exists('P16L2H0', ['SGN'] )\n",
        "  check_algo_tag_exists('P17L0H0', ['A2.SC'] )\n",
        "  check_algo_tag_exists('P17L0H1', ['A3.SA', 'A3.MD', 'A3.ND'] )\n",
        "  check_algo_tag_exists('P17L0H2', ['A3.SA', 'A3.MD', 'A3.ND'] )\n",
        "  check_algo_tag_exists('P17L0H3', ['SGN'] )\n",
        "  check_algo_tag_exists('P18L0H0', ['A1.SC'] )\n",
        "  check_algo_tag_exists('P18L0H1', ['A2.SA', 'A2.MD', 'A2.ND'] )\n",
        "  check_algo_tag_exists('P18L0H2', ['A2.SA', 'A2.MD', 'A2.ND'] )\n",
        "  check_algo_tag_exists('P19L0H0', ['A0.MB.A1'] )\n",
        "  check_algo_tag_exists('P19L0H1', ['A1.SA', 'A1.MD', 'A1.ND'] )\n",
        "  check_algo_tag_exists('P19L0H2', ['A1.SA', 'A1.MD', 'A1.ND'] )\n",
        "  check_algo_tag_exists('P20L0H1', ['A0.SA', 'A0.MD', 'A0.ND'] )\n",
        "  check_algo_tag_exists('P20L0H2', ['A0.SA', 'A0.MD', 'A0.ND'] )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "uG2gZSoSJD5C",
        "pTd3nmsMJV5T",
        "F_IIpX2H2tNe",
        "P8RfHXneJw6n",
        "tz6rUaYvjOcE",
        "ZHiJhch4KCej",
        "-KJhCxFtNKfm",
        "I-yFKiDllqEf",
        "D6FwJW0tv4Nf",
        "2PjaQvhhayUL",
        "nXBYdxj-jLZc",
        "ZmsGWUbILYin",
        "904WBkTOLg_5",
        "Rw-Wteh-JBd6",
        "3BmQHiLALp-3",
        "jFcCpfmKwlAH",
        "IVkOJRmPvPms",
        "Iosx5zE_macF",
        "3jOBIUDzRrGz",
        "nVyItdhmhIn8",
        "GOVsZIpoQN_r",
        "D74GWTY3aKhm",
        "dZk-BAE2n5kZ",
        "ig0eUEDN5XmG"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}