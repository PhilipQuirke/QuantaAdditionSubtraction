{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3OoV2Pd-w7g"
      },
      "source": [
        "# Accurate Integer Mathematics in Transformers - Train the Model\n",
        "\n",
        "This CoLab defines and trains a Transformer model that performs integer addition, subtraction and multiplication e.g. 133357+182243=+0315600, 123450-345670=-0123230 and 000345*000823=+283935. Each digit is a separate token. For 6 digit questions, the model is given 14 \"question\" (input) tokens, and must then predict the corresponding 8 \"answer\" (output) tokens.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtVn4muC-5p1"
      },
      "source": [
        "This CoLab trains the model, storing the results to the Colab files. Useful models are manually copied to HuggingFace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWXJvUUb-6in"
      },
      "source": [
        "## Tips for using the Colab\n",
        " * You can run and alter the code in this CoLab notebook yourself in Google CoLab ( https://colab.research.google.com/ ).\n",
        " * To run the notebook, in Google CoLab, **you will need to** go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.\n",
        " * Some graphs are interactive!\n",
        " * Use the table of contents pane in the sidebar to navigate.\n",
        " * Collapse irrelevant sections with the dropdown arrows.\n",
        " * Search the page using the search in the sidebar, not CTRL+F."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5K2kA0L_FHc"
      },
      "source": [
        "# Part 0: Import libraries\n",
        "Imports standard libraries. Do not read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CBOAqd0ZuhAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef99564-c670-4c79-ed99-c70686c3a217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n",
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-1.14.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.23.0 (from transformer_lens)\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0 (from transformer_lens)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.2.28-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.7.1)\n",
            "Requirement already satisfied: torch!=2.0,!=2.1.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.2)\n",
            "Requirement already satisfied: transformers>=4.34 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.38.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.10.0)\n",
            "Collecting wandb>=0.13.5 (from transformer_lens)\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.31.0)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.9.3)\n",
            "Collecting typeguard==2.13.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2023.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch!=2.0,!=2.1.0,>=1.10->transformer_lens)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->transformer_lens) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->transformer_lens) (0.15.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.5/263.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=2.0,!=2.1.0,>=1.10->transformer_lens) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: better-abc, xxhash, typeguard, smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fancy-einsum, einops, docker-pycreds, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, gitdb, nvidia-cusolver-cu12, GitPython, wandb, datasets, accelerate, transformer_lens\n",
            "Successfully installed GitPython-3.1.42 accelerate-0.28.0 beartype-0.14.1 better-abc-0.0.3 datasets-2.18.0 dill-0.3.8 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.11 jaxtyping-0.2.28 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentry-sdk-1.42.0 setproctitle-1.3.3 smmap-5.0.1 transformer_lens-1.14.0 typeguard-2.13.3 wandb-0.16.4 xxhash-3.4.1\n",
            "Collecting circuitsvis\n",
            "  Downloading circuitsvis-1.43.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (7.0.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (1.25.2)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from circuitsvis)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.2.1+cu121)\n",
            "Collecting triton==2.1.0 (from circuitsvis)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->circuitsvis) (12.4.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.1.0->circuitsvis) (3.13.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (2023.6.0)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch>=1.10 (from circuitsvis)\n",
            "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m743.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->circuitsvis) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->circuitsvis) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nccl-cu12, torch, circuitsvis\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed circuitsvis-1.43.2 nvidia-nccl-cu12-2.18.1 torch-2.1.2 triton-2.1.0\n",
            "Collecting torchtyping\n",
            "  Downloading torchtyping-0.1.4-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtyping) (2.1.2)\n",
            "Requirement already satisfied: typeguard>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from torchtyping) (2.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->torchtyping) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7.0->torchtyping) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->torchtyping) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->torchtyping) (1.3.0)\n",
            "Installing collected packages: torchtyping\n",
            "Successfully installed torchtyping-0.1.4\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    !pip install kaleido\n",
        "    !pip install transformer_lens\n",
        "    !pip install circuitsvis\n",
        "    !pip install torchtyping\n",
        "    !pip install transformers\n",
        "\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "295MWK2owFNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88d5265-623c-448c-a457-628987cb3ffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using renderer: colab\n"
          ]
        }
      ],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import kaleido\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_h1MGZnAwHZz"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zJpHPxqhwMeQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import circuitsvis as cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tS-PO-BPwo8f"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jZtQfp_5jQ0"
      },
      "source": [
        "# Part 0B: Import verified_transformers library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-3GyGqsV5e1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "847e0240-ff4f-45e0-82fe-12c953907f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PhilipQuirke/verified_transformers.git\n",
            "  Cloning https://github.com/PhilipQuirke/verified_transformers.git to /tmp/pip-req-build-nhsv_l9k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/PhilipQuirke/verified_transformers.git /tmp/pip-req-build-nhsv_l9k\n",
            "  Resolved https://github.com/PhilipQuirke/verified_transformers.git to commit b54a5295a9f75bf52672f50915dab7abe31cf99f\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from QuantaTools==0.1) (1.25.2)\n",
            "Building wheels for collected packages: QuantaTools\n",
            "  Building wheel for QuantaTools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for QuantaTools: filename=QuantaTools-0.1-py3-none-any.whl size=27018 sha256=aa573a90e2587719ab8bc5e16ec42eadeb16fc591c863d25fd8f7a5d30b8ac12\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mqs5vzqo/wheels/08/5c/b6/f02e46eb3b254e4572204214b92209ffbe2d0d4a5a61d3adb1\n",
            "Successfully built QuantaTools\n",
            "Installing collected packages: QuantaTools\n",
            "Successfully installed QuantaTools-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade git+https://github.com/PhilipQuirke/verified_transformers.git\n",
        "from QuantaTools import ModelConfig, token_to_char, tokens_to_string\n",
        "\n",
        "from QuantaTools import UsefulConfig, position_name, position_name_to_int, row_location_name, location_name, NodeLocation, UsefulNode, UsefulNodeList, str_to_node_location, answer_name\n",
        "\n",
        "from QuantaTools import QuantaFilter, QuantaType, MAX_ATTENTION_TAGS, MIN_ATTENTION_PERC, NO_IMPACT_TAG\n",
        "from QuantaTools import get_answer_impact, get_question_answer_impact, compact_answer_if_sequential, get_quanta_impact\n",
        "\n",
        "from QuantaTools import MathsConfig, MathsTokens, MathsTag, AlgoTag, set_maths_vocabulary\n",
        "from QuantaTools import int_to_answer_str, tokens_to_unsigned_int, tokens_to_answer, insert_question_number, make_a_maths_question, sort_unique_digits\n",
        "from QuantaTools import maths_data_generator, maths_data_generator_core, make_maths_questions, make_maths_test_questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8SVQxjtXqa9"
      },
      "source": [
        "# Part 1A: Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8Z1TVBObuOKF"
      },
      "outputs": [],
      "source": [
        "# Main configuration class for main model creation and training.\n",
        "# Derived from MathsConfig > UsefulConfig > ModelConfig\n",
        "class ColabConfig(MathsConfig):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.main_model = None\n",
        "\n",
        "    self.insert_late: bool = False\n",
        "    self.insert_n_layers: int = 2\n",
        "    self.insert_n_heads: int = 3\n",
        "    self.insert_training_seed: int = 372001\n",
        "    self.insert_n_training_steps: int = 15000\n",
        "\n",
        "    # Save graphs to CoLab temp files as PDF and HTML. Can manually export files for re-use in papers.\n",
        "    self.save_graph_to_file: bool = True\n",
        "\n",
        "\n",
        "  def to_dict(self):\n",
        "    return {\n",
        "      \"n_layers\": self.n_layers,\n",
        "      \"n_heads\": self.n_heads,\n",
        "      \"d_vocab\": self.d_vocab,\n",
        "      \"d_mlp\": self.d_mlp,\n",
        "      \"d_head\": self.d_head,\n",
        "      \"training_seed\": self.training_seed,\n",
        "      \"n_digits\": self.n_digits,\n",
        "      \"n_ctx\": self.n_ctx(),\n",
        "      \"act_fn\": self.act_fn,\n",
        "      \"batch_size\": self.batch_size,\n",
        "      \"n_training_steps\": self.n_training_steps,\n",
        "      \"lr\": self.lr,\n",
        "      \"weight_decay\": self.weight_decay,\n",
        "      \"perc_mult\": self.perc_mult,\n",
        "      \"perc_sub\": self.perc_sub,\n",
        "      \"insert_late\": self.insert_late,\n",
        "      \"insert_mode\": self.insert_mode,\n",
        "      \"insert_n_layers\": self.insert_n_layers,\n",
        "      \"insert_n_heads\": self.insert_n_heads,\n",
        "      \"insert_training_seed\": self.insert_training_seed,\n",
        "      \"insert_n_training_steps\": self.insert_n_training_steps,\n",
        "    }\n",
        "\n",
        "\n",
        "# Singleton class instance\n",
        "cfg = ColabConfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rl41loM_Apt"
      },
      "source": [
        "# Part 1B: Configuration\n",
        "\n",
        "\n",
        "This CoLab can be configured to:\n",
        "- Train a model using traditional approach. For example, add_d6_l2_h3_t15K_s372001.pth is trained from scratch using 100% addition questions to give an \"Addition\" model with a very low loss (9e-9).\n",
        "- Train a \"mixed\" model to do two tasks by inserting a \"known good\" model into the untrained composite model. For example, initialising  ins1_mix_d6_l3_h4_t20K_s372001.pth with  add_d6_l2_h3_dm510_dh170_t15K_s372001, and then training it on 80% subtraction questions and 20% addition questions.\n",
        "\n",
        "If we are inserting existing model weightings they are loaded from HuggingFace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mdad0Np8kSC9"
      },
      "outputs": [],
      "source": [
        "# Which model do we want to train?\n",
        "# cfg.model_name = \"\" # Use configuration specified in Part 1A\n",
        "cfg.model_name = \"add_d5_l1_h3_t10K\"  # 5 digit addition model. Inaccurate as only has one layer. Can predict S0, S1 and S2 complexity questions\n",
        "#cfg.model_name = \"add_d5_l2_h3_t15K\"  # 5 digit addition model\n",
        "#cfg.model_name = \"add_d6_l2_h3_t15K\"  # 6 digit addition model\n",
        "#cfg.model_name = \"sub_d6_l2_h3_t30K\"  # 6 digit subtraction model\n",
        "#cfg.model_name = \"mix_d6_l3_h4_t40K\"  # 6 digit addition and subtraction model\n",
        "#cfg.model_name = \"ins1_mix_d6_l3_h4_t40K\"  # 6 digit addition / subtraction model. Initialise with addition model.\n",
        "#cfg.model_name = \"ins2_mix_d6_l4_h4_t40K\"  # 6 digit addition / subtraction model. Initialised with addition model. Reset useful heads every 100 epochs\n",
        "#cfg.model_name = \"ins3_mix_d6_l4_h3_t40K\"  # 6 digit addition / subtraction model. Initialised with addition model. Reset useful heads & MLPs every 100 epochs\n",
        "#cfg.model_name = \"ins3_mix_d6_l4_h3_t60K\"  # 6 digit addition / subtraction model. Initialised with addition model. Reset useful heads & MLPs every 100 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue-HriK4imsU"
      },
      "source": [
        "# Part 1C: Configuration: Input and Output file names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2g1bk4bekm5g"
      },
      "outputs": [],
      "source": [
        "if cfg.model_name != \"\":\n",
        "\n",
        "  # Update cfg member data n_digits, n_layers, n_heads, n_training_steps from cfg.model_name\n",
        "  cfg.parse_model_name()\n",
        "\n",
        "  cfg.perc_sub = 0\n",
        "  if cfg.model_name.startswith(\"sub_\") :\n",
        "    cfg.perc_sub = 100\n",
        "\n",
        "  elif cfg.model_name == \"mix_d6_l3_h4_t40K\" :\n",
        "    cfg.perc_sub = 66 # Train on 66% subtraction and 33% addition question batches\n",
        "\n",
        "  elif cfg.model_name == \"ins1_mix_d6_l3_h4_t40K\" :\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "    # Initialise with add_d6_l2_h3_t15K.pth.\n",
        "\n",
        "  elif cfg.model_name == \"ins2_mix_d6_l4_h4_t40K\" :\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "    # Initialise with add_d6_l2_h3_t15K.pth. Train & reset useful heads every 100 epochs\n",
        "\n",
        "  elif cfg.model_name == \"ins3_mix_d6_l4_h3_t40K\" :\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "    # Initialise with add_d6_l2_h3_t15K.pth. Trained & reset useful heads & MLPs every 100 epochs\n",
        "\n",
        "  elif cfg.model_name == \"ins3_mix_d6_l4_h3_t60K\" :\n",
        "    cfg.perc_sub = 80 # Train on 80% subtraction and 20% addition question batches\n",
        "    # Initialise with add_d6_l2_h3_t15K.pth. Trained & reset useful heads & MLPs every 100 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HKgiXwaFiBj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3069f1-326b-4888-9333-97337f214bd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "%Mult= 0 %Sub= 0 %Add= 100 File= add_d5_l1_h3_t10K_s372001\n",
            "Main model will save to Colab temporary file add_d5_l1_h3_t10K_s372001.pth\n",
            "Main model config etc will save to Colab temporary file add_d5_l1_h3_t10K_s372001_train.json\n"
          ]
        }
      ],
      "source": [
        "main_fname = cfg.file_config_prefix()\n",
        "main_fname_pth = main_fname + '.pth'\n",
        "main_fname_json = main_fname + '_train.json'\n",
        "\n",
        "\n",
        "def print_config():\n",
        "  print(\"%Mult=\", cfg.perc_mult, \"%Sub=\", cfg.perc_sub, \"%Add=\", cfg.perc_add(), \"File=\", main_fname)\n",
        "\n",
        "print_config()\n",
        "print('Main model will save to Colab temporary file', main_fname_pth)\n",
        "print('Main model config etc will save to Colab temporary file', main_fname_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tExv4rk_L0C"
      },
      "source": [
        "# Part 3: Create main_model\n",
        "This section defines the token embedding / unembedding and creates the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CqGmiutQwp22"
      },
      "outputs": [],
      "source": [
        "# Vocabulary dictionary: Mapping from character (key) to token (value)\n",
        "set_maths_vocabulary(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Dg6uwYzew4u5"
      },
      "outputs": [],
      "source": [
        "# Transformer creation\n",
        "\n",
        "# Structure is documented at https://neelnanda-io.github.io/TransformerLens/transformer_lens.html#transformer_lens.HookedTransformerConfig.HookedTransformerConfig\n",
        "ht_cfg = HookedTransformerConfig(\n",
        "    n_layers = cfg.n_layers,\n",
        "    n_heads = cfg.n_heads,\n",
        "    d_model = cfg.d_model,\n",
        "    d_head = cfg.d_head,\n",
        "    d_mlp = cfg.d_mlp(),\n",
        "    act_fn = cfg.act_fn,\n",
        "    normalization_type = 'LN',\n",
        "    d_vocab = cfg.d_vocab,\n",
        "    d_vocab_out = cfg.d_vocab,\n",
        "    n_ctx = cfg.n_ctx(),\n",
        "    init_weights = True,\n",
        "    device = \"cuda\",\n",
        "    seed = cfg.training_seed,\n",
        ")\n",
        "\n",
        "main_model = HookedTransformer(ht_cfg)\n",
        "\n",
        "optimizer = optim.AdamW(main_model.parameters(),\n",
        "                        lr = cfg.lr,\n",
        "                        weight_decay = cfg.weight_decay,\n",
        "                        betas = (0.9, 0.98))\n",
        "\n",
        "max_iter = cfg.n_training_steps\n",
        "warmup_iter = max_iter // 5\n",
        "scheduler1 = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=int(warmup_iter))\n",
        "scheduler2 = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=int(np.ceil((max_iter-warmup_iter))))\n",
        "scheduler  = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[scheduler1, scheduler2], milestones=[int(warmup_iter)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg267eav_QSl"
      },
      "source": [
        "# Part 4: Loss Function & Data Generator\n",
        "This section defines the loss function and the training/testing data generator.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OIVxDpq0w7WY"
      },
      "outputs": [],
      "source": [
        "# Loss functions\n",
        "\n",
        "# Calculate the per-token probability by comparing a batch of prediction \"logits\" to answer \"tokens\"\n",
        "def logits_to_tokens_loss(logits, tokens):\n",
        "  # Addition answer can have one extra digit than question. Answer also has a +/- sign\n",
        "  n_answer_digits = cfg.n_digits+2\n",
        "\n",
        "  # The addition answer digit token probabilities\n",
        "  ans_logits = logits[:, -(n_answer_digits+1):-1]\n",
        "\n",
        "  # Convert raw score (logits) vector into a probability distribution.\n",
        "  # Emphasize the largest scores and suppress the smaller ones, to make them more distinguishable.\n",
        "  ans_probs = F.log_softmax(ans_logits.to(torch.float64), dim=-1)\n",
        "\n",
        "  max_prob_tokens = torch.argmax(ans_probs, dim=-1)\n",
        "\n",
        "  # The addition answer digit tokens\n",
        "  ans_tokens = tokens[:, -(n_answer_digits):]\n",
        "\n",
        "  # Extract values from the ans_probs tensor, based on indices from the ans_tokens tensor\n",
        "  ans_loss = torch.gather(ans_probs, -1, ans_tokens[:, :, None])[..., 0]\n",
        "\n",
        "  return ans_loss, max_prob_tokens\n",
        "\n",
        "\n",
        "# Calculate loss as negative of average per-token mean probability\n",
        "def loss_fn(ans_loss):\n",
        "  return -ans_loss.mean(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IH_rXfA2xAIG"
      },
      "outputs": [],
      "source": [
        "# Define \"iterator\" maths \"questions\" data generator function. Invoked using next().\n",
        "ds = maths_data_generator( cfg )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "V6c62sGVxVhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9ad783-8e1e-4363-c0a8-9d5a8432589a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4,  9,  7,  0,  1, 10,  1,  7,  5,  4,  6, 12, 10,  0,  6,  7,  2,  4,\n",
            "          7],\n",
            "        [ 8,  9,  2,  8,  9, 10,  5,  6,  9,  0,  6, 12, 10,  1,  4,  6,  1,  9,\n",
            "          5],\n",
            "        [ 9,  4,  5,  8,  9, 10,  1,  5,  9,  1,  6, 12, 10,  1,  1,  0,  5,  0,\n",
            "          5]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Test data generator\n",
        "tokens = next(ds)\n",
        "print(tokens[:3,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvijaDhSjn0B"
      },
      "source": [
        "# Part 5: Read insert_model from HuggingFace (optional)\n",
        "\n",
        "If we are initialising the untrained model with an existing model,\n",
        "then we load the existing model from HuggingFace.\n",
        "We load both the model weights and a json file stating which nodes in the model are actually doing useful calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ioCE99sOl-Gt"
      },
      "outputs": [],
      "source": [
        "insert_base_name = \"\"\n",
        "insert_weights_fname = \"\"\n",
        "insert_nodes_fname = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LonIqn6KjpTe"
      },
      "outputs": [],
      "source": [
        "# Read insert_model weights from HuggingFace\n",
        "if cfg.insert_mode >= 1:\n",
        "  train_str = str(cfg.insert_n_training_steps//1000) + \"K\"\n",
        "  insert_base_name = 'add_d{}_l{}_h{}_t{}_s{}'.format(cfg.n_digits, cfg.insert_n_layers, cfg.insert_n_heads, train_str, cfg.insert_training_seed)\n",
        "\n",
        "  insert_weights_fname = insert_base_name + \".pth\"\n",
        "\n",
        "  ht_cfg = HookedTransformerConfig(\n",
        "      n_layers = cfg.insert_n_layers,\n",
        "      n_heads = cfg.insert_n_heads,\n",
        "      d_model = cfg.d_model, # Assume constant\n",
        "      d_head = cfg.d_head, # Assume constant\n",
        "      d_mlp = cfg.d_mlp, # Assume constant\n",
        "      act_fn = cfg.act_fn, # Assume constant\n",
        "      normalization_type = 'LN',\n",
        "      d_vocab = cfg.d_vocab, # Assume constant\n",
        "      d_vocab_out = cfg.d_vocab, # Assume constant\n",
        "      n_ctx = cfg.n_ctx(), # Assume constant\n",
        "      init_weights = True, # Assume constant\n",
        "      device = \"cuda\",\n",
        "      seed = cfg.insert_training_seed,\n",
        "  )\n",
        "\n",
        "  insert_model = HookedTransformer(ht_cfg)\n",
        "\n",
        "  print('Loading insertion model from', insert_weights_fname)\n",
        "  insert_model.load_state_dict(utils.download_file_from_hf(repo_name=\"PhilipQuirke/Accurate6DigitSubtraction\", file_name=insert_weights_fname, force_is_torch=True))\n",
        "  insert_model.eval()\n",
        "\n",
        "  print(\"Loaded insert model\", insert_weights_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HXw7-a1E025H"
      },
      "outputs": [],
      "source": [
        "if cfg.insert_mode >= 1:\n",
        "  # Read insert_model useful node information from HuggingFace\n",
        "  huggingface_directory_url = 'https://huggingface.co/PhilipQuirke/VerifiedArithmetic/raw/main/'\n",
        "  insert_nodes_fname = huggingface_directory_url + insert_base_name + '_behavior.json'\n",
        "  print(insert_nodes_fname)\n",
        "\n",
        "  # Download the file\n",
        "  response = requests.get(insert_nodes_fname)\n",
        "\n",
        "  # Ensure the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Load the JSON data\n",
        "      json_data = json.loads(response.content.decode('utf-8'))\n",
        "\n",
        "      useful_cells = [UsefulNode.from_dict(item) for item in json_data]\n",
        "\n",
        "      print( \"Loaded:\", len(useful_cells), \"Sample:\", useful_cells[0].tags)\n",
        "  else:\n",
        "      print( \"Failed to download the file:\", response.status_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fW5galHlQqA"
      },
      "source": [
        "# Part 6B: Transfer all of insert_model into main_model (optional)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "iKe3LUst8veJ"
      },
      "outputs": [],
      "source": [
        "# Transfer all attention heads weights from the small to the main model, updating the right-most small.n_heads of main_model\n",
        "def transfer_all_heads(small_model, small_cfg, start_layer, end_layer, large_model):\n",
        "  for small_layer_no, large_layer_no in enumerate(range(start_layer, end_layer+1)):\n",
        "    large_model.blocks[large_layer_no].attn.W_Q.data[:small_cfg[\"n_heads\"]] = small_model.blocks[small_layer_no].attn.W_Q.clone().data\n",
        "    large_model.blocks[large_layer_no].attn.W_K.data[:small_cfg[\"n_heads\"]] = small_model.blocks[small_layer_no].attn.W_K.clone().data\n",
        "    large_model.blocks[large_layer_no].attn.W_V.data[:small_cfg[\"n_heads\"]] = small_model.blocks[small_layer_no].attn.W_V.clone().data\n",
        "\n",
        "    large_model.blocks[large_layer_no].attn.b_Q.data[:small_cfg[\"n_heads\"]] = small_model.blocks[small_layer_no].attn.b_Q.clone().data\n",
        "    large_model.blocks[large_layer_no].attn.b_K.data[:small_cfg[\"n_heads\"]] = small_model.blocks[small_layer_no].attn.b_K.clone().data\n",
        "    large_model.blocks[large_layer_no].attn.b_V.data[:small_cfg[\"n_heads\"]] = small_model.blocks[small_layer_no].attn.b_V.clone().data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DcaxqmJC8vsa"
      },
      "outputs": [],
      "source": [
        "# Transfer all MLP layer weights from the small to the main model, updating the right-most small.d_mlp of main_model\n",
        "def transfer_all_mlps(small_model, small_cfg, start_layer, end_layer, large_model):\n",
        "  for small_layer_no, large_layer_no in enumerate(range(start_layer, end_layer+1)):\n",
        "    large_model.blocks[large_layer_no].mlp.W_in.data[:, :small_cfg[\"d_mlp\"]] = small_model.blocks[small_layer_no].mlp.W_in.clone().data\n",
        "    large_model.blocks[large_layer_no].mlp.b_in.data[:small_cfg[\"d_mlp\"]] = small_model.blocks[small_layer_no].mlp.b_in.clone().data\n",
        "    large_model.blocks[large_layer_no].mlp.W_out.data[:small_cfg[\"d_mlp\"],] = small_model.blocks[small_layer_no].mlp.W_out.clone().data\n",
        "    large_model.blocks[large_layer_no].mlp.b_out.data = small_model.blocks[small_layer_no].mlp.b_out.clone().data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-UsGFC-b9oVC"
      },
      "outputs": [],
      "source": [
        "def transfer_all_ln(small_model, start_layer, end_layer, large_model):\n",
        "  for small_layer_no, large_layer_no in enumerate(range(start_layer, end_layer+1)):\n",
        "    large_model.blocks[large_layer_no].ln1.w.data = small_model.blocks[small_layer_no].ln1.w.clone().data\n",
        "    large_model.blocks[large_layer_no].ln1.b.data = small_model.blocks[small_layer_no].ln1.b.clone().data\n",
        "\n",
        "  large_model.ln_final.w.data = small_model.ln_final.w.clone().data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "BYpItGeX9-jq"
      },
      "outputs": [],
      "source": [
        "def transfer_all_embeds(small_model, large_model):\n",
        "  large_model.embed.W_E.data = small_model.embed.W_E.clone().data\n",
        "  large_model.pos_embed.W_pos.data = small_model.pos_embed.W_pos.clone().data\n",
        "  large_model.unembed.W_U.data = small_model.unembed.W_U.clone().data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WnkU3fYKlQAk"
      },
      "outputs": [],
      "source": [
        "small_cfg = {}\n",
        "large_cfg = {}\n",
        "\n",
        "# Insert the small model weights into the large model\n",
        "def transfer_full_model(small_model, large_model, start_layer, end_layer, transfer_ln=True, transfer_embeds=True):\n",
        "  \"\"\"Args:\n",
        "  small_model: The model to transfer weights from\n",
        "  large_model: The model to transfer weights to\n",
        "  start_layer: The first layer to transfer weights to\n",
        "  end_layer: The last layer to transfer weights to (Note that this is end-inclusive!)\n",
        "  \"\"\"\n",
        "  global small_cfg\n",
        "  global large_cfg\n",
        "\n",
        "  small_cfg = {k: v for k,v in small_model.cfg.__dict__.items() if k in [\"d_head\", \"d_mlp\", \"d_model\", \"n_heads\", \"n_layers\"]}\n",
        "  large_cfg = {k: v for k,v in large_model.cfg.__dict__.items() if k in [\"d_head\", \"d_mlp\", \"d_model\", \"n_heads\", \"n_layers\"]}\n",
        "\n",
        "  # Sanity checks for large model > small model\n",
        "  assert small_cfg[\"d_model\"] == large_cfg[\"d_model\"]\n",
        "  assert small_cfg[\"d_head\"] == large_cfg[\"d_head\"]\n",
        "  assert small_cfg[\"n_layers\"] <= large_cfg[\"n_layers\"]\n",
        "  assert small_cfg[\"n_heads\"] <= large_cfg[\"n_heads\"]\n",
        "  assert small_cfg[\"d_mlp\"] <= large_cfg[\"d_mlp\"]\n",
        "\n",
        "  assert 0 <= start_layer < end_layer <= large_cfg[\"n_layers\"] # Make sure start_layer and end_layer are valid\n",
        "  assert end_layer - start_layer + 1 == small_cfg[\"n_layers\"] # Make sure the number of layers to transfer is correct\n",
        "\n",
        "  transfer_all_heads(small_model, small_cfg, start_layer, end_layer, large_model)\n",
        "  transfer_all_mlps(small_model, small_cfg, start_layer, end_layer, large_model)\n",
        "  if transfer_ln:\n",
        "    transfer_all_ln(small_model, start_layer, end_layer, large_model)\n",
        "  if transfer_embeds:\n",
        "    transfer_all_embeds(small_model, large_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "_Rd7d5Gjmrd7"
      },
      "outputs": [],
      "source": [
        "def insert_existing_model( first_time ):\n",
        "  if cfg.insert_mode >= 1 :\n",
        "    # Is the destination the first few or last few layers of the main_model?\n",
        "    start_layer = cfg.n_layers - cfg.insert_n_layers if cfg.insert_late else 0\n",
        "    end_layer = start_layer + cfg.insert_n_layers-1\n",
        "\n",
        "    if first_time:\n",
        "      print( \"Inserting trained small_model\", insert_weights_fname)\n",
        "      print( \"into larger, untrained main_model\", main_fname)\n",
        "      print( \"destination layers:\", start_layer, end_layer)\n",
        "\n",
        "    transfer_full_model(insert_model, main_model, start_layer, end_layer, first_time, first_time)\n",
        "\n",
        "\n",
        "insert_existing_model( True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IppYbJCP_Ubj"
      },
      "source": [
        "# Part 6C: Transfer useful heads of insert_model into main_model (optional)\n",
        "\n",
        "Transfer just the useful attention heads from insert_model into main_model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5nvucMtl_8tt"
      },
      "outputs": [],
      "source": [
        "# Transfer one attention head's weights from the small to the main model.\n",
        "# The right-most small.n_heads of main_model are updated\n",
        "def transfer_one_head(small_model, small_layer_no, small_head_no, large_model, start_layer):\n",
        "  large_layer_no = start_layer + small_layer_no\n",
        "  large_head_no = large_cfg[\"n_heads\"] - small_cfg[\"n_heads\"] + small_head_no\n",
        "\n",
        "  large_model.blocks[large_layer_no].attn.W_Q.data[large_head_no] = small_model.blocks[small_layer_no].attn.W_Q.clone().data[small_head_no]\n",
        "  large_model.blocks[large_layer_no].attn.W_K.data[large_head_no] = small_model.blocks[small_layer_no].attn.W_K.clone().data[small_head_no]\n",
        "  large_model.blocks[large_layer_no].attn.W_V.data[large_head_no] = small_model.blocks[small_layer_no].attn.W_V.clone().data[small_head_no]\n",
        "\n",
        "  large_model.blocks[large_layer_no].attn.b_Q.data[large_head_no] = small_model.blocks[small_layer_no].attn.b_Q.clone().data[small_head_no]\n",
        "  large_model.blocks[large_layer_no].attn.b_K.data[large_head_no] = small_model.blocks[small_layer_no].attn.b_K.clone().data[small_head_no]\n",
        "  large_model.blocks[large_layer_no].attn.b_V.data[large_head_no] = small_model.blocks[small_layer_no].attn.b_V.clone().data[small_head_no]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "iefg8KGG_flE"
      },
      "outputs": [],
      "source": [
        "def transfer_useful_heads(small_model, large_model):\n",
        "  if cfg.insert_mode >= 2 and len(useful_cells) > 0:\n",
        "    # Is the destination the first few or last few layers of the main_model?\n",
        "    start_layer = cfg.n_layers - cfg.insert_n_layers if cfg.insert_late else 0\n",
        "\n",
        "    # TODO: Somewhat inefficent loop as a given head may exist in the list multiple times (with different use_cell.position and use_cell.tags values)\n",
        "    for use_cell in useful_cells:\n",
        "      if use_cell.is_head():\n",
        "        transfer_one_head(small_model, use_cell.layer, use_cell.head, large_model, start_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JDY_Fqa_Wfb"
      },
      "source": [
        "# Part 7: Train add/sub/mult main_model with Infinite Data\n",
        "Train main_model for n_training_steps, storing train_losses per epoch.\n",
        "\n",
        "Each training step (of n_training_steps) new training data (a batch of batch_size tokens) is generated and the model is trained and loss calculated on it. No separate \"testing\" data is needed, as the training data is unique each step. Memorisation of past training data by the model (if any) is minimally beneficial. For 6 digit addition or subtraction there are 1000 billion possible questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "d730f7262a4c40509e44c10896c08942",
            "788048a5012a4711afc5ed6fc9ea87b5",
            "e5d135760d544ae29acb072e76634571",
            "2ffab9a1210040d99e6cb83034744ca0",
            "deec26283781460fa4f78a9fbf6476bf",
            "9d779cf24bdb4e158566df619ab5205e",
            "f76cc60244144de5872bf2aa94331198",
            "246544e51b094d9c9ac08a0fd5d04123",
            "f730eaa28d0d44b8b5bbd9532fa1bde6",
            "6498628ebded49ffb03183a708485d88",
            "9dddde4913df42aa85365cc25803794e"
          ]
        },
        "id": "UJ61_nfKxI9c",
        "outputId": "cf179c00-ea63-4ddb-a383-b5fa016a2223"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d730f7262a4c40509e44c10896c08942"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 2.8254929279254344\n",
            "100 1.4848478458820749\n",
            "200 1.8139735693758432\n",
            "300 1.8749987636086616\n",
            "400 1.638507355911063\n",
            "500 1.7846645221781765\n",
            "600 1.7529652237622761\n",
            "700 1.6774959331961035\n",
            "800 1.587883153139031\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "train_losses_list = []\n",
        "per_token_train_losses_list = []\n",
        "\n",
        "for epoch in tqdm.tqdm(range(cfg.n_training_steps)):\n",
        "\n",
        "  tokens = next(ds)\n",
        "  logits = main_model(tokens)\n",
        "\n",
        "  per_token_train_losses_raw, _ = logits_to_tokens_loss(logits, tokens)\n",
        "  per_token_train_losses = loss_fn(per_token_train_losses_raw)\n",
        "  per_token_train_losses_list.append(utils.to_numpy(per_token_train_losses))\n",
        "\n",
        "  train_loss = per_token_train_losses.mean()\n",
        "  train_loss.backward()\n",
        "  train_losses_list.append(train_loss.item())\n",
        "\n",
        "  optimizer.step()\n",
        "  scheduler.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(epoch, train_loss.item())\n",
        "    if cfg.insert_mode == 2:\n",
        "      # Freeze the useful attention heads from insert_model\n",
        "      transfer_useful_heads(insert_model, main_model)\n",
        "    if cfg.insert_mode == 3:\n",
        "      # Freeze the useful attention heads and MLP layers from insert_model\n",
        "      insert_existing_model( False )\n",
        "\n",
        "print(epoch, train_loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwJBrnSJ23eb"
      },
      "outputs": [],
      "source": [
        "final_training_loss = round((train_losses_list[-5]+train_losses_list[-4]+train_losses_list[-3]+train_losses_list[-2]+train_losses_list[-1])/5,9)\n",
        "\n",
        "print( \"AvgFinalLoss\", final_training_loss)\n",
        "print( \"Final loss\", train_losses_list[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgzjamSn2y4j"
      },
      "outputs": [],
      "source": [
        "# These temporary Colab files can be manually downloaded from the Colab \"Files\" tab (at left).\n",
        "# The download can be manually loaded into HuggingFace so the \"Accurate Math - Analyse\" Colab can access it.\n",
        "\n",
        "print(\"Saving main model to temporary Colab file\", main_fname_pth)\n",
        "torch.save(main_model.state_dict(), main_fname_pth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aygOXqmalo71"
      },
      "outputs": [],
      "source": [
        "extra_data = {\n",
        "    \"Config\": cfg.to_dict(),\n",
        "    \"AvgFinalLoss\": final_training_loss,\n",
        "    \"FinalLoss\": train_losses_list[-1],\n",
        "    \"TrainingLoss\": train_losses_list\n",
        "}\n",
        "\n",
        "print( \"Saving main model config etc to temporary Colab file:\", main_fname_json)\n",
        "save_cfg = cfg.to_dict()\n",
        "with open(main_fname_json, 'w') as file:\n",
        "    json.dump(extra_data, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzIMC7iEksnz"
      },
      "source": [
        "# Part 8: Training Loss - Addition and Subtraction\n",
        "\n",
        "On 26Jan24 ran several runs:\n",
        "\n",
        "Addition:\n",
        "- 28Jan24: add_d5_l1_h3_t30K_s372001. AvgFinalLoss=0.001389\n",
        "- 26Jan24: add_d5_l2_h3_t15K_s372001. AvgFinalLoss=1.6e-08. Handles 1m Qs\n",
        "- 26Jan24: add_d6_l2_h3_t15K_s372001. AvgFinalLoss=1.7e-08. Handles 1m Qs\n",
        "\n",
        "Subtraction:\n",
        "- 26Jan24: sub_d6_l2_h3_t20K_s372001. AvgFinalLoss=9.8-05. Fails 1m Qs\n",
        "- 26Jan24: sub_d6_l2_h3_t30K_s372001. AvgFinalLoss=5.8e-06. Fails 1m Qs\n",
        "\n",
        "Mixed:\n",
        "- 26Jan24: sub_d6_l3_h4_t20K_s372001. AvgFinalLoss=5e-09. Fails 1m Qs\n",
        "\n",
        "Mixed+Insert (add_d6_l2_h3_t15K_s372001 inserted):\n",
        "- 26Jan24: ins1_mix_d6_l3_h4_t40K_s372001. AvgFinalLoss=8e-09. Handles 1m Qs for Add and Sub\n",
        "- 26Jan24: ins2_mix_d6_l4_h4_t40K_s372001. AvgFinalLoss=7e-09. Fails 1m Qs\n",
        "- 26Jan24: ins3_mix_d6_l4_h3_t40K_s372001. AvgFinalLoss=2.6e-06. Fails 1m Qs\n",
        "- ??Jan24: ins3_mix_d6_l4_h3_t60K_s372001. AvgFinalLoss=????"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiOdvQFD_fxZ"
      },
      "source": [
        "# Part 9: Line Graphs\n",
        "\n",
        "This section analyses the training loss by graphing it at a high level.\n",
        "\n",
        "The loss curve for all digits show visible inflection points (bumps), but is too high level to help understand the algorithm.\n",
        "\n",
        "When this graph is decomposed into 'per digit' graphs, the interesting distinct 'per digit' curves appear, showing each digit is being refined semi-independently, with the model algorithm refining each digit separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmyT2TFd29at"
      },
      "outputs": [],
      "source": [
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "# Helper function to plot multiple lines\n",
        "def lines(raw_lines_list, x=None, mode='lines', labels=None, xaxis='Epoch', yaxis='Loss', title = '', log_y=False, hover=None, **kwargs):\n",
        "\n",
        "    lines_list = raw_lines_list\n",
        "    log_suffix = '' if log_y==False else ' (Log)'\n",
        "    full_title = title + log_suffix\n",
        "\n",
        "    if type(lines_list)==torch.Tensor:\n",
        "        lines_list = [lines_list[i] for i in range(lines_list.shape[0])]\n",
        "    if x is None:\n",
        "        x=np.arange(len(lines_list[0]))\n",
        "    if cfg.save_graph_to_file :\n",
        "      fig = go.Figure(layout={})\n",
        "      print(full_title)\n",
        "    else:\n",
        "      fig = go.Figure(layout={'title':full_title})\n",
        "\n",
        "    fig.update_xaxes(\n",
        "        title=xaxis,\n",
        "        showgrid=False)\n",
        "    fig.update_yaxes(\n",
        "        title=yaxis + log_suffix,\n",
        "        showgrid=False)\n",
        "\n",
        "    for c, line in enumerate(lines_list):\n",
        "        if type(line)==torch.Tensor:\n",
        "            line = utils.to_numpy(line)\n",
        "        if labels is not None:\n",
        "            label = labels[c]\n",
        "        else:\n",
        "            label = c\n",
        "        fig.add_trace(go.Scatter(x=x, y=line, mode=mode, name=label, hovertext=hover, **kwargs))\n",
        "    if log_y:\n",
        "        fig.update_layout(yaxis_type=\"log\")\n",
        "    else:\n",
        "        # Calculate the max y-value rounded up to the nearest integer\n",
        "        y_max = 1\n",
        "        for k in range(len(lines_list)):\n",
        "            y_max = max(y_max, math.ceil(max(lines_list[k])) )\n",
        "        y_max = 3 # manual override if necessary\n",
        "\n",
        "        # Update layout to set the y-axis min to 0 and max to the calculated y_max\n",
        "        fig.update_layout(\n",
        "          yaxis=dict(range=[0, y_max])\n",
        "        )\n",
        "\n",
        "    # Update x-axis ticks\n",
        "    x_ticks = x[0::100]  # Start from index 0 and pick every 100th element\n",
        "    x_ticks = x_ticks[1:] # Exclude the first tick (0)\n",
        "    fig.update_xaxes(\n",
        "        tickmode='array',\n",
        "        tickvals=x_ticks,\n",
        "        ticktext=[str(tick) for tick in x_ticks]\n",
        "    )\n",
        "\n",
        "    if cfg.save_graph_to_file:\n",
        "        # fig.update_layout(margin=dict(l=10, r=10, t=10, b=10),width=1200,height=300)\n",
        "        # Update layout for legend positioning inside the graph\n",
        "        fig.update_layout(\n",
        "            margin=dict(l=10, r=10, t=10, b=10),\n",
        "            width=1200,height=300,\n",
        "            legend=dict(\n",
        "                x=0.9,  # Adjust this value to move the legend left or right\n",
        "                y=0.9,  # Adjust this value to move the legend up or down\n",
        "                traceorder=\"normal\",\n",
        "                font=dict(\n",
        "                    family=\"sans-serif\",\n",
        "                    size=12,\n",
        "                    color=\"black\"\n",
        "                ),\n",
        "                bgcolor=\"White\",  # Adjust background color for visibility\n",
        "                bordercolor=\"Black\",\n",
        "                borderwidth=2\n",
        "            )\n",
        "\n",
        "    fig.update_xaxes(showgrid=False)\n",
        "    fig.update_yaxes(showgrid=False)\n",
        "    fig.show(bbox_inches=\"tight\")\n",
        "\n",
        "    if cfg.save_graph_to_file:\n",
        "        filename = full_title.replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"&\", \"\").replace(\",\", \"\").replace(\"%\", \"\")   +'.pdf'\n",
        "        pio.write_image(fig, filename)\n",
        "\n",
        "\n",
        "title_suffix = 'Digit Loss Curves ' + main_fname\n",
        "per_token_losses = np.stack(per_token_train_losses_list, axis=0)\n",
        "\n",
        "line(train_losses_list,\n",
        "    title=title_suffix)\n",
        "\n",
        "lines([per_token_losses[:, i] for i in range(1+cfg.n_digits)]+[train_losses_list],\n",
        "      labels = [f'digit {i}' for i in range(1+cfg.n_digits)]+['all_digits'],\n",
        "      title='Per digit'+title_suffix, log_y=False)\n",
        "\n",
        "lines([per_token_losses[:, i] for i in range(1+cfg.n_digits)]+[train_losses_list],\n",
        "      labels = [f'digit {i}' for i in range(1+cfg.n_digits)]+['all_digits'],\n",
        "      title='Per digit'+title_suffix, log_y=True)\n",
        "\n",
        "for i in range(1+cfg.n_digits):\n",
        "  print('Final Loss for digit ' + str(i) + ' is ', per_token_losses[-1, i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgk8m02A_lxB"
      },
      "source": [
        "# Part 10: Questions Set Up\n",
        "\n",
        "Create sets of sample questions (by task) to ask the model to predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BpOcko53GrI"
      },
      "outputs": [],
      "source": [
        "def make_varied_questions():\n",
        "  q0 = next(ds)\n",
        "  q1 = next(ds)\n",
        "  q2 = next(ds)\n",
        "  q3 = next(ds)\n",
        "\n",
        "  questions = torch.vstack((q0.cuda(), q1.cuda(), q2.cuda(), q3.cuda()))\n",
        "\n",
        "  return questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4bqJ5C23M-A"
      },
      "outputs": [],
      "source": [
        "verbose = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJayaDiR3PgJ"
      },
      "outputs": [],
      "source": [
        "# Build a test batch of random questions\n",
        "varied_questions = make_varied_questions();\n",
        "\n",
        "\n",
        "# Run the sample batch, gather the cache\n",
        "main_model.reset_hooks()\n",
        "main_model.set_use_attn_result(True)\n",
        "sample_logits, sample_cache = main_model.run_with_cache(varied_questions.cuda())\n",
        "print(sample_cache) # Gives names of datasets in the cache\n",
        "sample_losses_raw, sample_max_prob_tokens = logits_to_tokens_loss(sample_logits, varied_questions.cuda())\n",
        "sample_loss_mean = utils.to_numpy(loss_fn(sample_losses_raw).mean())\n",
        "print(\"Sample Mean Loss\", sample_loss_mean)\n",
        "\n",
        "\n",
        "# attn.hook_z is the \"attention head output\" hook point name (at a specified layer)\n",
        "l_attn_hook_z_name = [utils.get_act_name('z', 0, 'a'),utils.get_act_name('z', 1, 'a')] # 'blocks.0.attn.hook_z' etc\n",
        "sample_attn_z = sample_cache[l_attn_hook_z_name[0]]\n",
        "print(\"Sample\", l_attn_hook_z_name[0], sample_attn_z.shape) # gives [239, 18, 3, 170] = num_questions, cfg.n_ctx, n_heads, d_head\n",
        "mean_attn_z = torch.mean(sample_attn_z, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_attn_hook_z_name[0], mean_attn_z.shape) # gives [1, 18, 3, 170] = 1, cfg.n_ctx, n_heads, d_head\n",
        "\n",
        "\n",
        "# hook_resid_pre is the \"pre residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_pre_name = ['blocks.0.hook_resid_pre','blocks.1.hook_resid_pre']\n",
        "\n",
        "\n",
        "# hook_resid_post is the \"post residual memory update\" hook point name (at a specified layer)\n",
        "l_hook_resid_post_name = ['blocks.0.hook_resid_post','blocks.1.hook_resid_post']\n",
        "sample_resid_post = sample_cache[l_hook_resid_post_name[0]]\n",
        "print(\"Sample\", l_hook_resid_post_name[0], sample_resid_post.shape) # gives [239, 18, 510] = num_questions, cfg.n_ctx, d_model\n",
        "mean_resid_post = torch.mean(sample_resid_post, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_hook_resid_post_name[0], mean_resid_post.shape) # gives [1, 18, 510] = 1, cfg.n_ctx, d_model\n",
        "\n",
        "\n",
        "# mlp.hook_post is the \"MLP layer\" hook point name (at a specified layer)\n",
        "l_mlp_hook_post_name = [utils.get_act_name('post', 0),utils.get_act_name('post', 1)] # 'blocks.0.mlp.hook_post' etc\n",
        "sample_mlp_hook_post = sample_cache[l_mlp_hook_post_name[0]]\n",
        "print(\"Sample\", l_mlp_hook_post_name[0], sample_mlp_hook_post.shape) # gives [239, 18, 2040] = num_questions, cfg.n_ctx, d_model*4\n",
        "mean_mlp_hook_post = torch.mean(sample_mlp_hook_post, dim=0, keepdim=True)\n",
        "print(\"Mean\", l_mlp_hook_post_name[0], mean_mlp_hook_post.shape) # gives [1, 18, 2040] = 1, cfg.n_ctx, d_model*4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deGhK1OC_1mD"
      },
      "source": [
        "# Part 11: Attention Patterns\n",
        "Attention patterns show which token(s) the model's attention heads are paying attention to in each token position of the prediction calculation.\n",
        "\n",
        "For the default CoLab set up, the  model has 3 attention heads, and performs 5 digit addition. The attention pattern is 18 by 18 squares (as 54321+77779=132100 is 18 tokens). Time proceeds vertically downwards, with one additional token being revealed horizontally at each token position, giving the overall triangle shape. This visualisation provided insights. After the question is fully revealed (at token position 11), each head starts attending to pairs of question digits from left to right (i.e. high-value digits before lower-value digits) giving the “double staircase\" shape. The three heads attend to a given digit pair in three different token position, giving a time ordering of heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiVCSBSE3Xpk"
      },
      "outputs": [],
      "source": [
        "def show_token_attention_patterns(index, layer, token_at_index, use_case):\n",
        "\n",
        "  the_tokens = [str(token) for token in token_at_index.tolist()]\n",
        "  if layer == 0:\n",
        "    tokens_str = tokens_to_string(token_at_index)\n",
        "    print(\"Attention patterns for\", tokens_str)\n",
        "\n",
        "  attention_pattern=sample_cache[\"pattern\", layer, \"attn\"][index]\n",
        "  display(cv.attention.attention_patterns(\n",
        "      tokens=the_tokens,\n",
        "      attention=attention_pattern,\n",
        "      #attention_head_names=[f\"L{layer}H{i}\" for i in range(cfg.n_heads)],\n",
        "  ))\n",
        "\n",
        "\n",
        "sample_size = 3\n",
        "\n",
        "# Show attention patterns for some randomly chosen tokens\n",
        "for i in range(sample_size):\n",
        "  for layer in range(cfg.n_layers):\n",
        "    show_token_attention_patterns(i, layer, tokens[i], \"Misc\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUCXw1k93a20"
      },
      "outputs": [],
      "source": [
        "if cfg.save_graph_to_file:\n",
        "\n",
        "  tokens_str = []\n",
        "  for i in range(cfg.n_heads):\n",
        "    one_token_str = []\n",
        "    for j in tokens[i]:\n",
        "      one_token_str.append(str(utils.to_numpy(j)))\n",
        "    tokens_str.append(one_token_str)\n",
        "\n",
        "  # Refer https://github.com/callummcdougall/CircuitsVis/blob/main/python/circuitsvis/circuitsvis_demo.ipynb\n",
        "\n",
        "  # html_object = cv.attention.from_cache(\n",
        "  #    cache = sample_cache,\n",
        "  #    tokens = tokens_str, # list of list of strings\n",
        "  #    return_mode = \"html\",\n",
        "  #)\n",
        "\n",
        "  # Create a CoLab file containing the attention pattern(s) in HTML\n",
        "  #filename = \"AttentionPattern\" + str(cfg.n_digits) + \"Digits\" + str(cfg.n_heads) + \"Heads.html\"\n",
        "  #with open(filename, \"w\") as f:\n",
        "  #    f.write(html_object.data)\n",
        "\n",
        "  # Manually download the CoLab \"html\" file and open in your local browser.\n",
        "  # Install and use the Edge extension \"FireShot\" to save a portion of the HTML page as a PDF"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "F5K2kA0L_FHc",
        "_jZtQfp_5jQ0",
        "Y8SVQxjtXqa9",
        "Ue-HriK4imsU",
        "3tExv4rk_L0C",
        "Pg267eav_QSl",
        "NvijaDhSjn0B",
        "1fW5galHlQqA",
        "IppYbJCP_Ubj"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d730f7262a4c40509e44c10896c08942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_788048a5012a4711afc5ed6fc9ea87b5",
              "IPY_MODEL_e5d135760d544ae29acb072e76634571",
              "IPY_MODEL_2ffab9a1210040d99e6cb83034744ca0"
            ],
            "layout": "IPY_MODEL_deec26283781460fa4f78a9fbf6476bf"
          }
        },
        "788048a5012a4711afc5ed6fc9ea87b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d779cf24bdb4e158566df619ab5205e",
            "placeholder": "​",
            "style": "IPY_MODEL_f76cc60244144de5872bf2aa94331198",
            "value": "  8%"
          }
        },
        "e5d135760d544ae29acb072e76634571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_246544e51b094d9c9ac08a0fd5d04123",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f730eaa28d0d44b8b5bbd9532fa1bde6",
            "value": 829
          }
        },
        "2ffab9a1210040d99e6cb83034744ca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6498628ebded49ffb03183a708485d88",
            "placeholder": "​",
            "style": "IPY_MODEL_9dddde4913df42aa85365cc25803794e",
            "value": " 829/10000 [02:04&lt;21:53,  6.98it/s]"
          }
        },
        "deec26283781460fa4f78a9fbf6476bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d779cf24bdb4e158566df619ab5205e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f76cc60244144de5872bf2aa94331198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "246544e51b094d9c9ac08a0fd5d04123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f730eaa28d0d44b8b5bbd9532fa1bde6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6498628ebded49ffb03183a708485d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dddde4913df42aa85365cc25803794e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}